{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】公式Exampleを分担して実行\n",
    "TensorFLowの公式Exampleを分担して実行してください。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "research\n",
    "\n",
    "定番のモデルから最新のモデルまで多様なコードが公開されています。\n",
    "\n",
    "models/research at master · tensorflow/models\n",
    "\n",
    "tutorials\n",
    "\n",
    "TensorFLowのチュートリアルとして用意された簡単なモデルが含まれています。\n",
    "\n",
    "models/tutorials at master · tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 異なるフレームワークへの書き換え\n",
    "Sprint14で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "* Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "* Iris（3種類全ての目的変数を使用して多値分類）\n",
    "* House Prices\n",
    "* MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】Iris（2値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜データ準備＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(4,)) #４つの特徴量を入力\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data) #50ノードの層\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x) #１００ノードの層\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x) #最終的な分類は３クラスなので、アウトプットは３クラス\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 4ms/sample - loss: 0.7977 - acc: 0.5469\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6359 - acc: 0.7188\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 991us/sample - loss: 0.5762 - acc: 0.6094\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3989 - acc: 0.8438\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3340 - acc: 0.8438\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 939us/sample - loss: 0.3422 - acc: 0.8594\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 925us/sample - loss: 0.2417 - acc: 0.9219\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 972us/sample - loss: 0.2005 - acc: 0.9062\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 987us/sample - loss: 0.3417 - acc: 0.8906\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1951 - acc: 0.9375\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 983us/sample - loss: 0.2715 - acc: 0.9219\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1567 - acc: 0.9375\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4432 - acc: 0.7812 0s - loss: 0.3849 - acc: 0.822\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2233 - acc: 0.8906\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1841 - acc: 0.9531\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 994us/sample - loss: 0.1611 - acc: 0.9219\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 952us/sample - loss: 0.3692 - acc: 0.8281\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 963us/sample - loss: 0.1891 - acc: 0.9531\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 961us/sample - loss: 0.2292 - acc: 0.9062\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1435 - acc: 0.9531\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 966us/sample - loss: 0.1641 - acc: 0.9375\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1335 - acc: 0.9531\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1586 - acc: 0.9375\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1065 - acc: 0.9531\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2308 - acc: 0.8750\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1661 - acc: 0.9375\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1503 - acc: 0.9531\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0670 - acc: 0.9844\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1786 - acc: 0.9531\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0894 - acc: 0.9531\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0930 - acc: 0.9531\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 974us/sample - loss: 0.1647 - acc: 0.9375\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 950us/sample - loss: 0.0793 - acc: 0.9531\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2259 - acc: 0.9062\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0515 - acc: 0.9844\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1744 - acc: 0.9062\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1603 - acc: 0.9375\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1514 - acc: 0.9375\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0823 - acc: 0.9844\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1470 - acc: 0.9531\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 997us/sample - loss: 0.1867 - acc: 0.9219\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1454 - acc: 0.9219\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1347 - acc: 0.9375\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1410 - acc: 0.9062\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0887 - acc: 0.9844\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1157 - acc: 0.9531\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0799 - acc: 0.9688\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1999 - acc: 0.9219\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 939us/sample - loss: 0.0951 - acc: 0.9531\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1172 - acc: 0.9531\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1190 - acc: 0.9531\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0718 - acc: 0.9531\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2250 - acc: 0.8750\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 987us/sample - loss: 0.2545 - acc: 0.8750\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 978us/sample - loss: 0.0714 - acc: 0.9531\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0635 - acc: 0.9844\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1455 - acc: 0.9375\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 991us/sample - loss: 0.1556 - acc: 0.9219\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 932us/sample - loss: 0.0688 - acc: 0.9688\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 942us/sample - loss: 0.1121 - acc: 0.9219\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0872 - acc: 0.9688\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1412 - acc: 0.9062\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2522 - acc: 0.8906\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0903 - acc: 0.9688\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 991us/sample - loss: 0.1147 - acc: 0.9375\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0777 - acc: 0.9844\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2382 - acc: 0.9219\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1446 - acc: 0.9375\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0744 - acc: 0.9688\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 947us/sample - loss: 0.1489 - acc: 0.9375\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 985us/sample - loss: 0.1173 - acc: 0.9688\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 993us/sample - loss: 0.0956 - acc: 0.9688\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0761 - acc: 0.9844\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1121 - acc: 0.9375\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 984us/sample - loss: 0.0745 - acc: 0.9375\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0650 - acc: 0.9844\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 988us/sample - loss: 0.1847 - acc: 0.9219\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 930us/sample - loss: 0.0797 - acc: 0.9688\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 907us/sample - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 890us/sample - loss: 0.0983 - acc: 0.9531\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 900us/sample - loss: 0.0763 - acc: 0.9844\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 920us/sample - loss: 0.1452 - acc: 0.9375\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 893us/sample - loss: 0.0663 - acc: 0.9688\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 908us/sample - loss: 0.1003 - acc: 0.9531\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 887us/sample - loss: 0.1313 - acc: 0.9531\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 959us/sample - loss: 0.1119 - acc: 0.9375\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 970us/sample - loss: 0.0594 - acc: 0.9844\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0900 - acc: 0.9844\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0617 - acc: 0.9688\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 944us/sample - loss: 0.0422 - acc: 0.9844\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 912us/sample - loss: 0.1301 - acc: 0.9375\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 938us/sample - loss: 0.1154 - acc: 0.9688\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 880us/sample - loss: 0.0909 - acc: 0.9531\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.1638 - acc: 0.9375\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 950us/sample - loss: 0.2099 - acc: 0.9062\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 999us/sample - loss: 0.0722 - acc: 0.9688\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 990us/sample - loss: 0.0558 - acc: 0.9844\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 943us/sample - loss: 0.0885 - acc: 0.9531\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0535 - acc: 0.9844\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Iris（多値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜データ準備＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "\n",
    "#y = y.astype(np.int)[:, np.newaxis]　必要ないので失敗。\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################\n",
    "#ワンホットエンコーディングを実施\n",
    "########################\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "y_train = y_train_one_hot\n",
    "y_test = y_test_one_hot \n",
    "\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜モデル作成＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(4,)) #４つの特徴量を入力\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data) #50ノードの層\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x) #１００ノードの層\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(x) #最終的な分類は３クラスなので、アウトプットは３クラス\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜学習＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.5419 - acc: 0.7604\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.2563 - acc: 0.9167\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 895us/sample - loss: 0.2773 - acc: 0.8542\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 846us/sample - loss: 0.1861 - acc: 0.9479\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 867us/sample - loss: 0.2075 - acc: 0.9271\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 873us/sample - loss: 0.1725 - acc: 0.9375\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 936us/sample - loss: 0.1807 - acc: 0.9062\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 894us/sample - loss: 0.2069 - acc: 0.9271\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 867us/sample - loss: 0.1574 - acc: 0.9062\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 976us/sample - loss: 0.1396 - acc: 0.9688\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 993us/sample - loss: 0.0853 - acc: 0.9479\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 961us/sample - loss: 0.1243 - acc: 0.9479\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 861us/sample - loss: 0.1333 - acc: 0.9375\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 863us/sample - loss: 0.1564 - acc: 0.9375\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 925us/sample - loss: 0.1666 - acc: 0.9583\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 904us/sample - loss: 0.1129 - acc: 0.9479\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 968us/sample - loss: 0.1205 - acc: 0.9583\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 936us/sample - loss: 0.1122 - acc: 0.9688\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 938us/sample - loss: 0.1033 - acc: 0.9479\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 900us/sample - loss: 0.0756 - acc: 0.9792\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 893us/sample - loss: 0.1967 - acc: 0.9375\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 898us/sample - loss: 0.1414 - acc: 0.9479\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 912us/sample - loss: 0.1388 - acc: 0.9271\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 890us/sample - loss: 0.2658 - acc: 0.9271\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 964us/sample - loss: 0.1454 - acc: 0.9583\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 908us/sample - loss: 0.1099 - acc: 0.9583\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 892us/sample - loss: 0.2582 - acc: 0.8750\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 872us/sample - loss: 0.2206 - acc: 0.9375\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 881us/sample - loss: 0.1241 - acc: 0.9583\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 868us/sample - loss: 0.1796 - acc: 0.9479\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 873us/sample - loss: 0.1199 - acc: 0.9792\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1090 - acc: 0.9583\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1022 - acc: 0.9688\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 950us/sample - loss: 0.0863 - acc: 0.9792\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 879us/sample - loss: 0.1150 - acc: 0.9479\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 889us/sample - loss: 0.0695 - acc: 0.9583\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 978us/sample - loss: 0.0975 - acc: 0.9688\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.0628 - acc: 0.9792\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 952us/sample - loss: 0.1014 - acc: 0.9375\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 859us/sample - loss: 0.0444 - acc: 0.9896\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.2120 - acc: 0.9375\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.0645 - acc: 0.9792\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.2804 - acc: 0.8646\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 977us/sample - loss: 0.1058 - acc: 0.9271\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 935us/sample - loss: 0.1219 - acc: 0.9375\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 875us/sample - loss: 0.0972 - acc: 0.9583\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 926us/sample - loss: 0.0818 - acc: 0.9688\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 893us/sample - loss: 0.0924 - acc: 0.9688\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 872us/sample - loss: 0.0936 - acc: 0.9479\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 840us/sample - loss: 0.1336 - acc: 0.9479\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 849us/sample - loss: 0.0376 - acc: 0.9792\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 856us/sample - loss: 0.1001 - acc: 0.9479\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 863us/sample - loss: 0.1190 - acc: 0.9479\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 844us/sample - loss: 0.0808 - acc: 0.9688\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 982us/sample - loss: 0.0471 - acc: 0.9896\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 966us/sample - loss: 0.9115 - acc: 0.7708\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.4645 - acc: 0.8646\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 923us/sample - loss: 0.0972 - acc: 0.9896\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.0746 - acc: 0.9896\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 967us/sample - loss: 0.0826 - acc: 0.9688\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.0967 - acc: 0.9688\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 999us/sample - loss: 0.1108 - acc: 0.9479\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 922us/sample - loss: 0.0463 - acc: 0.9792\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 872us/sample - loss: 0.0867 - acc: 0.9583\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1009 - acc: 0.9583\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 936us/sample - loss: 0.0637 - acc: 0.9792\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 901us/sample - loss: 0.0931 - acc: 0.9583\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 927us/sample - loss: 0.0406 - acc: 0.9792\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 942us/sample - loss: 0.0675 - acc: 0.9583\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 934us/sample - loss: 0.1008 - acc: 0.9375\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 907us/sample - loss: 0.0369 - acc: 0.9896\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 979us/sample - loss: 0.0671 - acc: 0.9688\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 982us/sample - loss: 0.0279 - acc: 0.9792\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 909us/sample - loss: 0.0414 - acc: 0.9792\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 966us/sample - loss: 0.1094 - acc: 0.9479\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 870us/sample - loss: 0.0674 - acc: 0.9792\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 851us/sample - loss: 0.0545 - acc: 0.9792\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 897us/sample - loss: 0.1226 - acc: 0.9583\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 857us/sample - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 889us/sample - loss: 0.0651 - acc: 0.9792\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1611 - acc: 0.9479\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 868us/sample - loss: 0.0883 - acc: 0.9583\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 874us/sample - loss: 0.1121 - acc: 0.9688\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 884us/sample - loss: 0.0363 - acc: 0.9896\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 857us/sample - loss: 0.0506 - acc: 0.9896\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 861us/sample - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 847us/sample - loss: 0.0748 - acc: 0.9688\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 898us/sample - loss: 0.0830 - acc: 0.9688\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 903us/sample - loss: 0.1081 - acc: 0.9583\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 941us/sample - loss: 0.0867 - acc: 0.9688\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 878us/sample - loss: 0.1093 - acc: 0.9583\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 881us/sample - loss: 0.0742 - acc: 0.9688\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 836us/sample - loss: 0.0602 - acc: 0.9688\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 851us/sample - loss: 0.0702 - acc: 0.9792\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 927us/sample - loss: 0.0446 - acc: 0.9792\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 895us/sample - loss: 0.0960 - acc: 0.9375\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 866us/sample - loss: 0.1044 - acc: 0.9688\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 880us/sample - loss: 0.0990 - acc: 0.9375\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 866us/sample - loss: 0.0649 - acc: 0.9688\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 865us/sample - loss: 0.0701 - acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】House PricesをKerasで学習\n",
    "Sprint14で作成したHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path_hp =\"datasets/house_price_dataset_train.csv\"\n",
    "df_house_price = pd.read_csv(dataset_path_hp)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path_hp =\"datasets/house_price_dataset_train.csv\"\n",
    "df_house_price = pd.read_csv(dataset_path_hp)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df_house_price[\"SalePrice\"]\n",
    "X = df_house_price.loc[:, ['GrLivArea','YearBuilt','LotArea']]\n",
    "y = np.array(y)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1710,  2003,  8450],\n",
       "       [ 1262,  1976,  9600],\n",
       "       [ 1786,  2001, 11250],\n",
       "       ...,\n",
       "       [ 2340,  1941,  9042],\n",
       "       [ 1078,  1950,  9717],\n",
       "       [ 1256,  1965,  9937]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜モデル作成＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(3,)) #3つの特徴量を入力\n",
    "x = tf.keras.layers.Dense(2, activation=tf.nn.relu)(input_data) #50ノードの層\n",
    "x = tf.keras.layers.Dense(1, activation=tf.nn.relu)(x) #１００ノードの層\n",
    "model = tf.keras.Model(inputs=input_data, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜学習＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1460/1460 [==============================] - 1s 823us/sample - loss: 3179301081.6201 - mean_absolute_error: 37615.4375\n",
      "Epoch 2/50\n",
      "1460/1460 [==============================] - 1s 699us/sample - loss: 3162589635.3015 - mean_absolute_error: 37918.6680\n",
      "Epoch 3/50\n",
      "1460/1460 [==============================] - 1s 693us/sample - loss: 3189540303.2858 - mean_absolute_error: 37722.0508\n",
      "Epoch 4/50\n",
      "1460/1460 [==============================] - 1s 691us/sample - loss: 3169431919.2503 - mean_absolute_error: 37888.4805\n",
      "Epoch 5/50\n",
      "1460/1460 [==============================] - 1s 698us/sample - loss: 3149248110.9769 - mean_absolute_error: 37391.1133\n",
      "Epoch 6/50\n",
      "1460/1460 [==============================] - 1s 696us/sample - loss: 3170117186.0452 - mean_absolute_error: 37543.3945\n",
      "Epoch 7/50\n",
      "1460/1460 [==============================] - 1s 741us/sample - loss: 3132277567.9976 - mean_absolute_error: 37808.7461\n",
      "Epoch 8/50\n",
      "1460/1460 [==============================] - 1s 700us/sample - loss: 3159659110.8482 - mean_absolute_error: 37483.3359\n",
      "Epoch 9/50\n",
      "1460/1460 [==============================] - 1s 736us/sample - loss: 3169925142.1814 - mean_absolute_error: 37835.5469\n",
      "Epoch 10/50\n",
      "1460/1460 [==============================] - 1s 708us/sample - loss: 3188365858.9929 - mean_absolute_error: 37709.8398\n",
      "Epoch 11/50\n",
      "1460/1460 [==============================] - 1s 742us/sample - loss: 3147813917.9988 - mean_absolute_error: 37702.6953\n",
      "Epoch 12/50\n",
      "1460/1460 [==============================] - 1s 755us/sample - loss: 3166509621.1513 - mean_absolute_error: 37447.3398\n",
      "Epoch 13/50\n",
      "1460/1460 [==============================] - 1s 699us/sample - loss: 3152361944.9939 - mean_absolute_error: 37897.5273\n",
      "Epoch 14/50\n",
      "1460/1460 [==============================] - 1s 719us/sample - loss: 3148555431.5828 - mean_absolute_error: 38216.8320\n",
      "Epoch 15/50\n",
      "1460/1460 [==============================] - 1s 721us/sample - loss: 3181421914.4472 - mean_absolute_error: 37742.9258\n",
      "Epoch 16/50\n",
      "1460/1460 [==============================] - 1s 857us/sample - loss: 3166531191.1122 - mean_absolute_error: 37750.0898\n",
      "Epoch 17/50\n",
      "1460/1460 [==============================] - 1s 760us/sample - loss: 3148395168.0127 - mean_absolute_error: 37658.7695\n",
      "Epoch 18/50\n",
      "1460/1460 [==============================] - 1s 750us/sample - loss: 3177947629.9279 - mean_absolute_error: 37762.1836\n",
      "Epoch 19/50\n",
      "1460/1460 [==============================] - 1s 741us/sample - loss: 3155252458.6547 - mean_absolute_error: 37676.9492\n",
      "Epoch 20/50\n",
      "1460/1460 [==============================] - 1s 709us/sample - loss: 3178535276.1384 - mean_absolute_error: 37842.5703\n",
      "Epoch 21/50\n",
      "1460/1460 [==============================] - 1s 708us/sample - loss: 3149721975.2211 - mean_absolute_error: 37804.0000\n",
      "Epoch 22/50\n",
      "1460/1460 [==============================] - 1s 841us/sample - loss: 3178641488.8325 - mean_absolute_error: 37481.3438\n",
      "Epoch 23/50\n",
      "1460/1460 [==============================] - 1s 782us/sample - loss: 3191102927.1653 - mean_absolute_error: 37870.0820\n",
      "Epoch 24/50\n",
      "1460/1460 [==============================] - 1s 836us/sample - loss: 3165627511.8826 - mean_absolute_error: 37701.2852\n",
      "Epoch 25/50\n",
      "1460/1460 [==============================] - 1s 775us/sample - loss: 3165575149.2072 - mean_absolute_error: 37521.3398\n",
      "Epoch 26/50\n",
      "1460/1460 [==============================] - 1s 721us/sample - loss: 3194505542.4982 - mean_absolute_error: 37703.0820\n",
      "Epoch 27/50\n",
      "1460/1460 [==============================] - 1s 780us/sample - loss: 3154409264.1325 - mean_absolute_error: 37757.0430\n",
      "Epoch 28/50\n",
      "1460/1460 [==============================] - 1s 845us/sample - loss: 3170185407.4954 - mean_absolute_error: 37608.8125\n",
      "Epoch 29/50\n",
      "1460/1460 [==============================] - 1s 750us/sample - loss: 3133952314.8232 - mean_absolute_error: 37865.9844\n",
      "Epoch 30/50\n",
      "1460/1460 [==============================] - 1s 713us/sample - loss: 3141091407.1163 - mean_absolute_error: 37915.6914\n",
      "Epoch 31/50\n",
      "1460/1460 [==============================] - 1s 719us/sample - loss: 3154184604.0749 - mean_absolute_error: 37725.1602\n",
      "Epoch 32/50\n",
      "1460/1460 [==============================] - 1s 727us/sample - loss: 3155432474.5828 - mean_absolute_error: 37730.5469\n",
      "Epoch 33/50\n",
      "1460/1460 [==============================] - 1s 752us/sample - loss: 3136068579.0759 - mean_absolute_error: 37332.3633\n",
      "Epoch 34/50\n",
      "1460/1460 [==============================] - 1s 727us/sample - loss: 3161004370.9671 - mean_absolute_error: 37708.3359\n",
      "Epoch 35/50\n",
      "1460/1460 [==============================] - 1s 728us/sample - loss: 3164755976.4586 - mean_absolute_error: 37901.0156\n",
      "Epoch 36/50\n",
      "1460/1460 [==============================] - 1s 721us/sample - loss: 3139769549.2366 - mean_absolute_error: 37497.9258\n",
      "Epoch 37/50\n",
      "1460/1460 [==============================] - 1s 756us/sample - loss: 3177013364.7057 - mean_absolute_error: 37575.8594\n",
      "Epoch 38/50\n",
      "1460/1460 [==============================] - 1s 780us/sample - loss: 3174130852.8328 - mean_absolute_error: 37618.5039\n",
      "Epoch 39/50\n",
      "1460/1460 [==============================] - 1s 754us/sample - loss: 3168415673.6622 - mean_absolute_error: 37746.9414\n",
      "Epoch 40/50\n",
      "1460/1460 [==============================] - 1s 719us/sample - loss: 3166170059.2000 - mean_absolute_error: 37899.5469\n",
      "Epoch 41/50\n",
      "1460/1460 [==============================] - 1s 746us/sample - loss: 3190679116.8313 - mean_absolute_error: 37578.8555\n",
      "Epoch 42/50\n",
      "1460/1460 [==============================] - 1s 806us/sample - loss: 3182886255.0529 - mean_absolute_error: 37970.3828\n",
      "Epoch 43/50\n",
      "1460/1460 [==============================] - 1s 766us/sample - loss: 3154149641.8252 - mean_absolute_error: 37593.5742\n",
      "Epoch 44/50\n",
      "1460/1460 [==============================] - 1s 781us/sample - loss: 3164128419.0838 - mean_absolute_error: 37629.0586\n",
      "Epoch 45/50\n",
      "1460/1460 [==============================] - 1s 753us/sample - loss: 3161335595.1618 - mean_absolute_error: 37577.2266\n",
      "Epoch 46/50\n",
      "1460/1460 [==============================] - 1s 714us/sample - loss: 3187157409.1332 - mean_absolute_error: 37569.4531\n",
      "Epoch 47/50\n",
      "1460/1460 [==============================] - 1s 718us/sample - loss: 3222010273.9040 - mean_absolute_error: 37840.8672\n",
      "Epoch 48/50\n",
      "1460/1460 [==============================] - 1s 719us/sample - loss: 3148439862.4752 - mean_absolute_error: 37553.0469\n",
      "Epoch 49/50\n",
      "1460/1460 [==============================] - 1s 806us/sample - loss: 3160632643.5059 - mean_absolute_error: 37968.0156\n",
      "Epoch 50/50\n",
      "1460/1460 [==============================] - 1s 783us/sample - loss: 3150569734.4641 - mean_absolute_error: 37594.8750\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['mae'])\n",
    "history = model.fit(X, y,\n",
    "                    batch_size=1,\n",
    "                    epochs=50,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】MNISTをKerasで学習\n",
    "Sprint14で作成したMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train =  X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "#########################\n",
    "#ワンホットエンコーディングを実施\n",
    "########################\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "y_train = y_train_one_hot\n",
    "y_test = y_test_one_hot \n",
    "\n",
    "\n",
    "#########################\n",
    "#　画像データの正規化\n",
    "#########################\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜モデル作成＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(784,)) #3つの特徴量を入力\n",
    "x = tf.keras.layers.Dense(400, activation=tf.nn.relu)(input_data) #50ノードの層\n",
    "x = tf.keras.layers.Dense(200, activation=tf.nn.relu)(x) #１００ノードの層\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x) #最終的な分類は３クラスなので、アウトプットは３クラス\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜学習＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 396,210\n",
      "Trainable params: 396,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.9298 - acc: 0.9392\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8236 - acc: 0.9464\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8145 - acc: 0.9465\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.7924 - acc: 0.9483\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8159 - acc: 0.9472\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.7898 - acc: 0.9490\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.8132 - acc: 0.9476\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.8791 - acc: 0.9438\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8036 - acc: 0.9486\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.9104 - acc: 0.9420\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.8560 - acc: 0.9454\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8359 - acc: 0.9467\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.8230 - acc: 0.9479\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8728 - acc: 0.9447\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.8182 - acc: 0.9484\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 2s 31us/sample - loss: 0.8566 - acc: 0.9460\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.9123 - acc: 0.9425\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 1s 30us/sample - loss: 0.8846 - acc: 0.9445\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.9120 - acc: 0.9426\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.8845 - acc: 0.9444\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.9569 - acc: 0.9400\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.8486 - acc: 0.9466\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.8208 - acc: 0.9485\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.9550 - acc: 0.9401\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 2s 31us/sample - loss: 0.8994 - acc: 0.9436\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.8841 - acc: 0.9445\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.8090 - acc: 0.9494\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.9149 - acc: 0.9427\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 2s 31us/sample - loss: 0.8856 - acc: 0.9446\n",
      "Epoch 30/30\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.9491 - acc: 0.9406\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=30,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）フレームワークの比較\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "\n",
    "興味がある場合はTensorFlow、Keras、PyTorch以外にも触れてみましょう。\n",
    "\n",
    "視点例\n",
    "\n",
    "計算速度\n",
    "コードの行数・可読性\n",
    "用意されている機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
