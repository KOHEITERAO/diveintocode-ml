{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "03-models_pretrained_and_more.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVzJnxLw9raW",
        "colab_type": "text"
      },
      "source": [
        "# マウントとカレントディレクトリの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrw18m00TVTb",
        "colab_type": "code",
        "outputId": "b35f4913-e9e5-4c15-8dff-cf9eed5ce0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b3FDKhnzwok",
        "colab_type": "code",
        "outputId": "45a00308-d539-49b3-a7a2-ef4e70cdee5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "624rhkOKPXFv",
        "colab_type": "code",
        "outputId": "5ea747ec-04b2-46c1-9371-87c892ae3f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cowrn2XZO_5X",
        "colab_type": "code",
        "outputId": "9216b8dd-4891-4bf5-a287-d1fbabd24234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/datasets/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkCD1SC7SVlh",
        "colab_type": "text"
      },
      "source": [
        "## Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfSojpxSVlj",
        "colab_type": "code",
        "outputId": "8bf6bb92-83e7-4ea8-d8db-9078ba524544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al0Tj__hSVlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64jcxyneSVlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9azLYL7SVls",
        "colab_type": "text"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRguq1f_SVls",
        "colab_type": "code",
        "outputId": "d74d8ea6-b41b-4ace-de73-b124d222ed80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('sample_submission.csv')\n",
        "depth = pd.read_csv('depths.csv')\n",
        "\n",
        "train_src = '/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hDYsR7LSVlv",
        "colab_type": "text"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGVXQoVSVlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f6b494a-696a-4a87-9cdb-f2becf2613ad"
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KmVh-YhqSVly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "65d61928-4aee-448a-868f-363e94983d86"
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f49701d7940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEhPe7IaSVl0",
        "colab_type": "text"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QINS3ApISVl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ER0q7bHSVl2",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Ka-ermSVl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "334b174d-9c5e-457a-c829-53882c10fa22"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "# チャネル特徴量を追加している\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "#ResNETイメージのデフォルトサイズである(224,224)にリサイズ\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKsfiZmXSVl5",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbY6ip8-SVl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YAg5xAbSVl7",
        "colab_type": "text"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "\n",
        "レズネットではどのブロックもプーリングレイヤーで終わっている。  \n",
        "そのため、プーリングを行う前に特徴を抽出することができる。  \n",
        "最初のレイヤーに追加の抽出用機器を取り付ければ、５つのレイヤーから特徴量を抽出できる。  \n",
        "デフォルトのインプットサイズは(224,224,3)であり、それに続くレイヤーの形は次の通り。\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "\n",
        "念頭におくべきは、毎回同じTFセッションにおいて、モデルが作られることである。  \n",
        "レイヤー名はその度に変更され、レイヤー名は最初のモデル作成と一致する。  \n",
        "セッションをリセットするには、`K.clear_session()`を呼び出す。\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLVw9JtcSVl8",
        "colab_type": "raw"
      },
      "source": [
        "#ベースモデルはResNet５０\n",
        "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DSlRALBSVl8",
        "colab_type": "text"
      },
      "source": [
        "### デコーダーのブロック\n",
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure.\n",
        "ResNet50からの特徴はセグメンテーションモデルのエンコーダー部分のためのベースとして機能し、デコーダーパートが必要になる。  \n",
        "このパートでは、自身のモデルを作成しなくてはならない。  \n",
        "極めてベーシックなブロックと、二つ目のブロックを作成し、それらによってより入り組んだ構造を作成してゆく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyufZp8-SVl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "# 畳み込み、BN、PRELU活性化関数を用いている基本的なデコーダーブロック\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "# ボトルネック構造を用いたデコーダーブロックであり、表現を圧出するためにはミドル畳み込み層は最初と最後のサイズの半分になる。\n",
        "# このタイプの構造は最も有用な情報を保持している。\n",
        "\n",
        "\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2yoVhHpSVl-",
        "colab_type": "text"
      },
      "source": [
        "### モデルを定義する\n",
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model.  \n",
        "エンコーダーとデコーダーのブロックを結合し、最終的なセグメンテーションモデルを作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvk-obELSVl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# デコーダーブロックタイプの容易な変更を可能にできるようにモデルはパラメータ設定されており、\n",
        "# デコーダーブロックシンプルのように、関数を与えられるような議論のものである。\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    # ベースとなるエンコーダーモデル\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights) #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # エンコーダーパートにおける特徴抽出の層\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    # センターブロック\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    # デコーダーパート\n",
        "    # どのデコーダーブロックも、エンコーダーとデコーダー部分からの結合されたアウトプットを前に進めている。\n",
        "    # そして、デコーダーのアウトプットはエンコーダのアウトプット部分と同じディメンションにアップサンプルされる。\n",
        "    \n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOfV3iutSVmA",
        "colab_type": "text"
      },
      "source": [
        "### Inspect created model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d5fOSQBkSVmB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26d3968c-0ea3-4f3c-c1e3-c59da4d9a1f7"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet') #事前学習されたメージネットの重みを読み込んでいる。\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 19:43:32.189238 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0730 19:43:32.191520 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0730 19:43:32.249541 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 19:43:32.250679 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 19:43:32.259581 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0730 19:43:35.330417 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0730 19:43:35.405618 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0730 19:43:44.753995 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0730 19:43:45.158156 140185121314688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 19:43:45.186494 140185121314688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0730 19:43:45.203934 140185121314688 deprecation.py:323] From <ipython-input-11-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWDSmBxWSVmD",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dGIYUNTbSVmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79d28c5d-dbd0-4788-f46d-5700ec1565d2"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "# 最適な学習ポイントで結果を保存する\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 1  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0730 19:43:53.167312 140185121314688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/1\n",
            "3196/3196 [==============================] - 144s 45ms/step - loss: 0.7258 - my_iou_metric: 0.3373 - val_loss: 2.9257 - val_my_iou_metric: 0.1022\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.10224, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YOp0cG0SVmG",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeEiZ9XFSVmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOUmwZagSVmK",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzHHeAPeSVmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2OxfeEKSVmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "034eada7-5f59-4523-83e3-957cbfb9cb51"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:36<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48e3WixvSVmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "bbcf1488-4894-44f7-a6d2-11a4e1f9fdfe"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.1641 at threshold: 0.200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.129563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.012772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.118159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.120398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.123010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.135634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.164055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.129563\n",
              "std     0.204939   0.012772\n",
              "min     0.200000   0.118159\n",
              "25%     0.370000   0.120398\n",
              "50%     0.540000   0.123010\n",
              "75%     0.710000   0.135634\n",
              "max     0.880000   0.164055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcewlVBnSVma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "057df8d9-e21e-4b3d-cbd6-711dc68ae0ef"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7e7bfe5278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8luXd/vHjzN4J2YFsVhI2hLBx\ngYJarYpWUHFjq1itta3a9mnr0z5W7VCrdVtcCGpxT8AFIiMJO2EmgQRCCAkhIXtcvz+I/BARAiS5\n7vF5v168IPd93fd98Ifm4Mx5Xl9jWZYAAAAAHJuH3QEAAAAAR0ZhBgAAAI6DwgwAAAAcB4UZAAAA\nOA4KMwAAAHAcFGYAAADgOCjMAAAAwHFQmAEAAIDjoDADAAAAx0FhBgAAAI7Dy+4AR4uMjLSSk5Pt\njgEAAAAXl5OTs8+yrKgTXedwhTk5OVnZ2dl2xwAAAICLM8bs6Mh1bMkAAAAAjoPCDAAAABwHhRkA\nAAA4DofbwwwAAADH0NzcrJKSEjU0NNgd5bT4+fkpPj5e3t7ep/R6CjMAAACOqaSkRMHBwUpOTpYx\nxu44p8SyLFVUVKikpEQpKSmn9B5syQAAAMAxNTQ0KCIiwmnLsiQZYxQREXFaq+QUZgAAAPwgZy7L\n3zrdvwOFGQAAAA5r7NixdkegMAMAAMBxLVu2zO4IFGYAAAA4rqCgIEmHDu/96le/0sCBAzVo0CDN\nnz9fkvTFF1/owgsvPHz97NmzNWfOnE7NwF0yAAAAcEJ/em+j8nZXd+p7ZvQM0R9+NKBD1y5YsEBr\n1qzR2rVrtW/fPo0cOVITJ07s1Dw/hBVmAAAAOLylS5dq+vTp8vT0VExMjM444wytWrWqWz6bFWYA\nAACcUEdXgrubl5eX2traDn/dFUNWWGEGAACAw5swYYLmz5+v1tZWlZeX66uvvlJWVpaSkpKUl5en\nxsZGVVVVafHixZ3+2awwAwAAwOFdcskl+uabbzRkyBAZY/TQQw8pNjZWknTFFVdo4MCBSklJ0bBh\nwzr9s41lWZ3+pqcjMzPTys7OtjsGAACA28vPz1d6errdMTrFsf4uxpgcy7IyT/RatmQAAAAAx0Fh\nBgAAAI7D4Qpzm4NtEQEAAIB7c7jCnFdarcJ9tXbHAAAAgA5N2HN2p/t3cLjCLEv6z9eFdqcAAABw\ne35+fqqoqHDq0mxZlioqKuTn53fK7+Fwt5ULC/DRG9kl+uXk/goN8LY7DgAAgNuKj49XSUmJysvL\n7Y5yWvz8/BQfH3/Kr3e4whwZ5KODza16bdVO/fSM3nbHAQAAcFve3t5KSUmxO4btHG5Lhp+3p8b2\njtCLy4rU3Np24hcAAAAAXcjhCrMk3Tg+RaUHGvTRhj12RwEAAICbc8jCfFb/aKVGBur5JQVOvckc\nAAAAzs8hC7OHh9H145K1tuSAcnbstzsOAAAA3JhDFmZJumxEvEL9vfX8Um4xBwAAAPs4bGEO8PHS\n9KxEfbJxj4or6+yOAwAAADflsIVZkq4dmyQPYzRnWZHdUQAAAOCmHLowx4X66/xBcZq/qlg1Dc12\nxwEAAIAbcujCLB26xdzBxha9nl1idxQAAAC4IYcvzEMSwpSZ1ENzlhWqtY1bzAEAAKB7OXxhlg6t\nMhdX1mthHoNMAAAA0L2cojCfOyBW8T38ucUcAAAAup1TFGZPD6PrxiZrVdF+rSupsjsOAAAA3IhT\nFGZJ+snIBAX5erHKDAAAgG7lNIU52M9bPxmZoA/WlWrPgQa74wAAAMBNOE1hlqTrxiarzbL04jdF\ndkcBAACAm3CqwpwQHqDzBsRq7oqdqmtqsTsOAAAA3IBTFWbp0C3mDtQ367+5u+yOAgAAADfgdIV5\nRFIPDYkP1X+WFqqNQSYAAADoYk5XmI0xumF8igr21eqLLXvtjgMAAAAX53SFWZLOHxSnuFA/bjEH\nAACALueUhdnb00MzxyTr620Vyi+ttjsOAAAAXJhTFmZJmpGVKH9vT1aZAQAA0KWctjCHBnhr2oh4\nvbtmt/bWMMgEAAAAXcNpC7MkXT8uWU2tbXpl+U67owAAAMBFOXVhTo0K0jlp0Xp1+Q41NLfaHQcA\nAAAuyKkLs3RokElFbZPeWcMgEwAAAHQ+py/MY3pHKC02WM8vLZRlMcgEAAAAncvpC7MxRjeOT9GW\nsoNaum2f3XEAAADgYpy+MEvSRUN7KjLIl1vMAQAAoNO5RGH29fLUzDFJ+mJzubbtrbE7DgAAAFyI\nSxRmSbpqVKJ8vDz0wtdFdkcBAACAC+lQYTbGTDHGbDbGbDPG3HOM5ycaY3KNMS3GmGlHPZdojPnU\nGJNvjMkzxiR3TvTvigjy1aXDemlBbon21zZ1xUcAAADADZ2wMBtjPCU9IWmqpAxJ040xGUddtlPS\ndZLmHuMtXpL0sGVZ6ZKyJO09ncDHc8P4FDU0t2nuSgaZAAAAoHN0ZIU5S9I2y7IKLMtqkjRP0sVH\nXmBZVpFlWesktR35eHux9rIsa2H7dQcty6rrnOjf1y8mWBP6RurFZUVqamk78QsAAACAE+hIYe4l\nqfiIr0vaH+uIfpKqjDELjDGrjTEPt69Yd5kbx6dob02jPli/uys/BgAAAG6iqw/9eUmaIOluSSMl\nperQ1o3vMMbMMsZkG2Oyy8vLT+sDz+gXpT7RQQwyAQAAQKfoSGHeJSnhiK/j2x/riBJJa9q3c7RI\nelvS8KMvsizrGcuyMi3LyoyKiurgWx+bMUY3jEvRhl3VWllYeVrvBQAAAHSkMK+S1NcYk2KM8ZF0\npaR3O/j+qySFGWO+bcFnS8o7+Zgn59LhvdQjwJtBJgAAADhtJyzM7SvDsyV9Iilf0uuWZW00xtxv\njLlIkowxI40xJZIul/S0MWZj+2tbdWg7xmJjzHpJRtKzXfNX+f/8vD111agkLcwv046K2q7+OAAA\nALgw42j7fDMzM63s7OzTfp+91Q0a9+BnumpUkv540YBOSAYAAABXYozJsSwr80TXucykv6NFh/jp\nR4N76o3sYtU2ttgdBwAAAE7KZQuzJF01Okm1Ta16by23mAMAAMCpcenCPDwxTP1jgvUak/8AAABw\nily6MBtjND0rQWtLDmjDrgN2xwEAAIATcunCLEmXDIuXr5eH5q1ilRkAAAAnz+ULc2iAty4YHKe3\nV+9WXROH/wAAAHByXL4wS9KMrEQdbGzR+2tL7Y4CAAAAJ+MWhXlEUg/1jQ7SXA7/AQAA4CS5RWE+\ndPgvUWuKq5S3u9ruOAAAAHAiblGYJenS4b3kw+E/AAAAnCS3KcxhAT66YFCc3srdpfqmVrvjAAAA\nwEm4TWGWpOlZiappbNH765j8BwAAgI5xq8I8MrmHekcFMvkPAAAAHeZWhfnbw3+5O6u0aQ+H/wAA\nAHBiblWYJemy4fHy8fTQvJXFdkcBAACAE3C7wtwj0EdTB8VqQW4Jh/8AAABwQm5XmKVDh/+qG1r0\n4Xom/wEAAOD43LIwj0oJV2okh/8AAABwYm5ZmL89/Je9Y7+2lNXYHQcAAAAOzC0LsyRdNuLQ4T9W\nmQEAAHA8bluYwwN9dN7AWC3I3aWGZg7/AQAA4NjctjBL0vSsBB2ob9ZHGzj8BwAAgGNz68I8JjVC\nyREBem0F92QGAADAsbl1Yf728N/Kokpt28vhPwAAAHyfWxdm6dDhP29Po7msMgMAAOAY3L4wRwb5\n6twBsfpvbgmH/wAAAPA9bl+YJWlGVqIO1Dfr4w177I4CAAAAB0Nh1qHDf0kRAZrLPZkBAABwFAqz\nJA8PoytHJmplYaW27T1odxwAAAA4EApzu2kj4uXlYTSPVWYAAAAcgcLcLirYV+cOiOHwHwAAAL6D\nwnyE6VmJ2l/XrE82cvgPAAAAh1CYjzCud6QSwv31GtsyAAAA0I7CfIRvD/8tL6hUQTmH/wAAAEBh\n/p7LM9sP/61i8h8AAAAozN8THeynSekxejOnRI0tHP4DAABwdxTmY5g+KlGVtU36dGOZ3VEAAABg\nMwrzMUzoE6leYRz+AwAAAIX5mDw8jKZnJWjZ9goV7qu1Ow4AAABsRGH+AZdnJsjTw2jeKlaZAQAA\n3BmF+QfEhPjpnLRovZldoqaWNrvjAAAAwCYU5uOYPipRFbVNWpjH4T8AAAB3RWE+jol9ozj8BwAA\n4OYozMfh6WH0k5EJWrptn3ZUcPgPAADAHVGYT+CKzAR5GDH5DwAAwE1RmE8gNtRPZ6fF6I3sYg7/\nAQAAuCEKcwfMGJWgfQebtDifw38AAADuhsLcAWf0i1ZcqJ/mcvgPAADA7VCYO+Dbw39Ltu5TcWWd\n3XEAAADQjSjMHfTt4b+Xl++wOwoAAAC6EYW5g3qG+etHQ3rqxWVFKj1Qb3ccAAAAdBMK80m4+9z+\nsizpnwu32B0FAAAA3YTCfBISwgN0zZgkvZlTos17auyOAwAAgG5AYT5Js8/qo0BfLz348Sa7owAA\nAKAbUJhPUo9AH916Zh99tmmvlhdU2B0HAAAAXYzCfAquH5esuFA/PfBhvizLsjsOAAAAuhCF+RT4\neXvqF5P7aW3JAX2wvtTuOAAAAOhCFOZTdNnwePWPCdbDn2xWU0ub3XEAAADQRSjMp8jTw+ieqWna\nUVGnuSsYZgIAAOCqKMyn4cz+URqTGqHHPtummoZmu+MAAACgC1CYT4MxRveen6bK2iY981WB3XEA\nAADQBSjMp2lwfJguHBynZ5cUqKy6we44AAAA6GQU5k7wq/P6q7XN0iOLGJkNAADgaijMnSApIlBX\njUrS/FXF2lrGyGwAAABXQmHuJLef3UeBPl568OPNdkcBAABAJ6Iwd5KIIF/99MzeWpRfppWFlXbH\nAQAAQCehMHeiG8alKCbEVw98xMhsAAAAV0Fh7kT+Pp66a3I/rd5ZpY837LE7DgAAADoBhbmTXTY8\nXn2jg/TQJ5vV3MrIbAAAAGdHYe5kXp4eumdqmgr31Wreyp12xwEAAMBpojB3gbPTopWVEq5HFm3V\nwcYWu+MAAADgNFCYu4AxRvedn64KRmYDAAA4PQpzFxmaEKYLBsXpuSUF2svIbAAAAKdFYe5Cvzqv\nv5pa2vTI4q12RwEAAMApojB3oeTIQF01KlHzVxVr296DdscBAADAKaAwd7Hbz+krPy8PPfTxJruj\nAAAA4BRQmLtYZJCvfnpGb32aV6bsIkZmAwAAOBsKcze4cUKKooN99X8fMjIbAADA2VCYu0GAj5fu\nnNRPuTur9MnGMrvjAAAA4CRQmLvJFZnx6h0VqIc+3sTIbAAAACdCYe4mXp4e+s2UNBXsq9X8VcV2\nxwEAAEAHUZi70eSMGI1M7qFHFm1VLSOzAQAAnAKFuRsZY3TP1HTtO9ioZ5cwMhsAAMAZUJi72Yik\nHpoyIFbPfFWg8ppGu+MAAADgBCjMNvj1lP5qbGnTY4zMBgAAcHgUZhukRgVpelaC5q7cqYJyRmYD\nAAA4MgqzTe44p598PD30KKvMAAAADo3CbJOoYF/NHJukd9fu1tayGrvjAAAA4Ad0qDAbY6YYYzYb\nY7YZY+45xvMTjTG5xpgWY8y0o55rNcasaf/1bmcFdwW3TOytAG9PPbKIVWYAAABHdcLCbIzxlPSE\npKmSMiRNN8ZkHHXZTknXSZp7jLeotyxraPuvi04zr0sJD/TR9eNS9MH6UuXtrrY7DgAAAI6hIyvM\nWZK2WZZVYFlWk6R5ki4+8gLLsoosy1oniZnPJ+nmCakK9vPSPxdtsTsKAAAAjqEjhbmXpCNnOZe0\nP9ZRfsaYbGPMcmPMj08qnRsIDfDWTeNTtTCvTOtLDtgdBwAAAEfpjkN/SZZlZUqaIekRY0zvoy8w\nxsxqL9XZ5eXl3RDJsdwwPlmh/t76x8LNdkcBAADAUTpSmHdJSjji6/j2xzrEsqxd7b8XSPpC0rBj\nXPOMZVmZlmVlRkVFdfStXUawn7dmTUzV55vLlbNjv91xAAAAcISOFOZVkvoaY1KMMT6SrpTUobtd\nGGN6GGN82/8cKWmcpLxTDevKrhubrIhAH/1zIXuZAQAAHMkJC7NlWS2SZkv6RFK+pNcty9pojLnf\nGHORJBljRhpjSiRdLulpY8zG9penS8o2xqyV9Lmkv1qWRWE+hkBfL/30jN5aum2fVhRU2B0HAAAA\n7YxlWXZn+I7MzEwrOzvb7hi2qG9q1cSHP1dqZKDmzRotY4zdkQAAAFyWMSan/azdcTHpz4H4+3jq\n1jN7a0VhpZZtZ5UZAADAEVCYHcz0rETFhfrpHwu3yNFW/wEAANwRhdnB+Hl76raz+ihnx359ucX9\nbrEHAADgaCjMDuiKzAT1CvNnlRkAAMABUJgdkI+Xh35+Th+tKzmgRfl77Y4DAADg1ijMDurS4fFK\nigjQPxZuUVsbq8wAAAB2oTA7KG9PD91xTl/ll1brk4177I4DAADgtijMDuziob2UGhWofy7aolZW\nmQEAAGxBYXZgnh5Gd07qpy1lB/X+ut12xwEAAHBLFGYHd+GgOPWPCdaji7aqpbXN7jgAAABuh8Ls\n4Dw8jH4xua8K9tXqnTWsMgMAAHQ3CrMTODcjVhlxIXp08VY1s8oMAADQrSjMTsDDw+iuyf20s7JO\nC3JL7I4DAADgVijMTuKc9GgNSQjTY4u3qamFVWYAAIDuQmF2EsYcWmXeVVWv+dnFdscBAABwGxRm\nJzKxb6RGJPXQE59tU0Nzq91xAAAA3AKF2YkYY/TLyf20p7pBr63caXccAAAAt0BhdjJj+0RqdGq4\nnvh8u+qbWGUGAADoahRmJ3TX5P7ad7BRLy8vsjsKAACAy6MwO6GslHBN6Bupp74s0MHGFrvjAAAA\nuDQKs5O6a3I/VdY26cVlRXZHAQAAcGkUZic1LLGHzk6L1jNfFai6odnuOAAAAC6LwuzEfjGpnw7U\nN+uFpYV2RwEAAHBZFGYnNig+VOdmxOj5JYU6UMcqMwAAQFegMDu5X0zup5rGFj27pMDuKAAAAC6J\nwuzk0uNCdMHgOP3n60JV1jbZHQcAAMDlUJhdwJ3n9FVdc6ue/nK73VEAAABcDoXZBfSNCdbFQ3pq\nzrIibd5TY3ccAAAAl0JhdhH3XZCuYD8vzZ6bq7omhpkAAAB0Fgqzi4gO9tMjPxmmbeUH9cd3N9od\nBwAAwGVQmF3I+L6Ruu3MPno9u0RvrS6xOw4AAIBLoDC7mDsn9VVWcrh++9YGbS8/aHccAAAAp0dh\ndjFenh56dPpQ+Xp56LZXc9XQ3Gp3JAAAAKdGYXZBcaH++vsVQ7RpT43+/EGe3XEAAACcGoXZRZ2d\nFqNZE1P1yvKd+mBdqd1xAAAAnBaF2YXdfW5/DU0I0z3/XaedFXV2xwEAAHBKFGYX5uPloX9NHyYZ\nafZruWpqabM7EgAAgNOhMLu4hPAAPTxtsNaVHNCDH2+yOw4AAIDToTC7gSkD43TtmCQ9v7RQC/PK\n7I4DAADgVCjMbuK+C9I1sFeI7n5jrXZV1dsdBwAAwGlQmN2Er5enHp8+XK1tln7+2mo1t7KfGQAA\noCMozG4kOTJQ/3fpIOXs2K9/LNxidxwAAACnQGF2MxcN6anpWQl68ovt+nJLud1xAAAAHB6F2Q39\nz4UD1D8mWHfNX6Oy6ga74wAAADg0CrMb8vfx1OMzhqmuqVV3zFut1jbL7kgAAAAOi8LspvrGBOv+\niwdoeUGl/vXZVrvjAAAAOCwKsxu7PDNBlw7vpUcXb9Wy7fvsjgMAAOCQKMxu7n8vHqiUyEDdOW+N\n9h1stDsOAACAw6Ewu7lAXy89MWO4quqbddfra9XGfmYAAIDvoDBD6XEh+sOPMvTVlnI99dV2u+MA\nAAA4FAozJEkzshJ1weA4/f3TLcouqrQ7DgAAgMOgMEOSZIzRA5cOUq8wf/38tdXaX9tkdyQAAACH\nQGHGYSF+3np8xjCVH2zUr95cK8tiPzMAAACFGd8xOD5M952frkX5e/X80kK74wAAANiOwozvuW5s\nss4bEKMHPtqkpVu5PzMAAHBvFGZ8jzFGf79iqHpHBeq2ubkq2ldrdyQAAADbUJhxTEG+Xnpu5kgZ\nI938UrZqGprtjgQAAGALCjN+UGJEgP49Y7gK9tXqF/PXMNQEAAC4JQozjmtsn0j9z4UZWpS/V/9Y\nuMXuOAAAAN3Oy+4AcHwzxyQpv7Raj3++TWlxwbpwcE+7IwEAAHQbVphxQsYY3X/xQGUm9dDdb6zV\nhl0H7I4EAADQbSjM6BAfLw89efUIhQf4aNZL2SqvabQ7EgAAQLegMKPDooJ99czMTFXWNelnr+So\nqaXN7kgAAABdjsKMkzKwV6genjZE2Tv26w/vbmB8NgAAcHkc+sNJ+9GQntq0p1pPfL5d6XEhmjkm\n2e5IAAAAXYYVZpySX07ur0np0frTe3latp3x2QAAwHVRmHFKPDyM/vmToUqNDNRtr+aquLLO7kgA\nAABdgsKMUxbs561nZ2aqzTo0Pru2scXuSAAAAJ2OwozTkhwZqMdnDNOWshrd9TrjswEAgOuhMOO0\nTegbpd9ekKFPNpbp0cVb7Y4DAADQqbhLBjrFDeOSlV9arUcXb1VabLCmDoqzOxIAAECnYIUZncIY\no79cMlDDE8N01+trlbe72u5IAAAAnYLCjE7j6+Wpp64ZoVB/b938UrYqDjI+GwAAOD8KMzpVdLCf\nnpk5QvsONurWV3PV3Mr4bAAA4NwozOh0g+PD9NC0wVpRWKk/vbfR7jgAAACnhUN/6BIXD+2lvNJq\nPf1lgdLjQnTVqCS7IwEAAJwSVpjRZX59XprO6h+lP7yzUSsKKuyOAwAAcEoozOgynh5Gj04fpsSI\nAP3s1VztqKi1OxIAAMBJozCjS4X4eeu5mZlqsyxd+cxyFe2jNAMAAOdCYUaXS40K0tybRquxpU1X\nPP2NtpcftDsSAABAh1GY0S0yeobotZtHq82y9JOnl2trWY3dkQAAADqEwoxu0z82WPNmjZYx0pXP\nLFd+KdMAAQCA46Mwo1v1iQ7W/Fmj5e3poRnPLteGXQfsjgQAAHBcFGZ0u9SoIM2/ZbQCfLw049nl\nWldSZXckAACAH0Rhhi2SIgI1b9Zohfh766pnVyh35367IwEAABwThRm2SQgP0Ou3jFF4kI9mPr9S\n2UWVdkcCAAD4HgozbNUzzF/zZ41RdLCvZr6wUsuZCAgAABwMhRm2iw3107xbRqtnmL+u+89Kfb1t\nn92RAAAADutQYTbGTDHGbDbGbDPG3HOM5ycaY3KNMS3GmGnHeD7EGFNijHm8M0LD9UQH+2nerNFK\njgjUDXNW6cst5XZHAgAAkNSBwmyM8ZT0hKSpkjIkTTfGZBx12U5J10ma+wNv87+Svjr1mHAHkUG+\nmnvzaPWOCtLNL2brs01ldkcCAADo0ApzlqRtlmUVWJbVJGmepIuPvMCyrCLLstZJajv6xcaYEZJi\nJH3aCXnh4sIDfTT35lHqHxusW17O0acb99gdCQAAuLmOFOZekoqP+Lqk/bETMsZ4SPq7pLtPPhrc\nVViAj165aZQG9AzVra/m6qP1pXZHAgAAbqyrD/3dKulDy7JKjneRMWaWMSbbGJNdXs7eVUih/t56\n+cYsDUkI0+zXVuu9tbvtjgQAANxURwrzLkkJR3wd3/5YR4yRNNsYUyTpb5JmGmP+evRFlmU9Y1lW\npmVZmVFRUR18a7i6YD9vvXhDlkYk9dAd81brrdXH/XcXAABAl+hIYV4lqa8xJsUY4yPpSknvduTN\nLcu6yrKsRMuyknVoW8ZLlmV97y4bwA8J8vXSnOtHanRqhO56fa1ezy4+8YsAAAA60QkLs2VZLZJm\nS/pEUr6k1y3L2miMud8Yc5EkGWNGGmNKJF0u6WljzMauDA33EuDjpeevHanxfSL16zfXae6KnXZH\nAgAAbsRYlmV3hu/IzMy0srOz7Y4BB9TQ3KqfvZKjzzeX6/6LB2jmmGS7IwEAACdmjMmxLCvzRNcx\n6Q9Ow8/bU09dM0KT0mP0P+9s5O4ZAACgW1CY4VR8vTz1+IxhGpYYprteX6u83dV2RwIAAC6Owgyn\n4+ftqaevHqFQf2/d/FK2Kg422h0JAAC4MAoznFJ0iJ+evmaEyg826tZXc9Xc+r0hkwAAAJ2Cwgyn\nNSQhTA9dNlgrCiv1p/e4MQsAAOgaXnYHAE7Hj4f1Un5ptZ7+qkDpcSG6alSS3ZEAAICLYYUZTu/X\nU9J0Zv8o/eGdjVpRUGF3HAAA4GIozHB6nh5Gj145TIkRAfrZq7kq2V9ndyQAAOBCKMxwCaH+3np2\nZqaaW9t004vZqmtqsTsSAABwERRmuIzeUUH61/Rh2lJWo7vfWCtHm2IJAACcE4UZLuXM/tG6Z2qa\nPly/R//6bJvdcQAAgAvgLhlwOTdPSFV+aY3+sXCL+scG67wBsXZHAgAATowVZrgcY4weuHSQhsSH\n6q75a7R5T43dkQAAgBOjMMMl+Xl76ulrMhXo66WbXlql/bVNdkcCAABOisIMlxUb6qenrhmhsgON\num0u47MBAMCpoTDDpQ1P7KH/u3SQlm2v0F8+yLc7DgAAcEIc+oPLmzYiXptKq/Xc0kKlxQbryqxE\nuyMBAAAnwgoz3MI9U9M0oW+kfv/OBq0qqrQ7DgAAcCIUZrgFL08PPT59uOJ7BOhnr+RoV1W93ZEA\nAICToDDDbYQGeOvZmSPU0NymWS9lq76p1e5IAADACVCY4Vb6RAfrselDlVdarV+9yfhsAABwYhRm\nuJ2z02L0q/P66/11pfr3F9vtjgMAABwchRlu6Wdn9NZFQ3rqb59u1qK8MrvjAAAAB0Zhhlsyxuih\naYM1sGeo7py/RlvLGJ8NAACOjcIMt+Xn7alnZo6Qn7enbn4pW9UNzXZHAgAADojCDLcWF+qvf181\nXMX763X36xwCBAAA30dhhtvLSgnXvVPT9GlemZ76ssDuOAAAwMFQmAFJN45P0QWD4/TwJ5u0bNs+\nu+MAAAAHQmEG1H4I8LLBSo0K0u2vrVbpASYBAgCAQyjMQLtAXy89dfUINTS36tZXc9XU0mZ3JAAA\n4AAozMAR+kQH6eHLh2j1zir9+YM8u+MAAAAHQGEGjnL+oDjdND5FL32zQ2+v3mV3HAAAYDMKM3AM\nv5mapqyUcN2zYJ027am2Ow7rO+z9AAAgAElEQVQAALARhRk4Bm9PDz0+Y5hC/Lz105dzGGoCAIAb\nozADPyA62E9PXDVcJfvr9cvX16qtjaEmAAC4IwozcBwjk8N17/npWphXpqe+2m53HAAAYAMKM3AC\nN4xL1oWD4/S3Tzbra4aaAADgdijMwAkYY/Rg+1CTnzPUBAAAt0NhBjqAoSYAALgvCjPQQQw1AQDA\nPVGYgZNw/qA43Tzh0FCTt1aX2B0HAAB0AwozcJJ+M+XQUJN7F6xXfilDTQAAcHUUZuAkeR0x1ORn\nr+ToQD1DTQAAcGUUZuAURAf76d/tQ03ufoOhJgAAuDIKM3CKMpPDdR9DTQAAcHkUZuA0XM9QEwAA\nXB6FGTgN3w416d0+1GR3FUNNAABwNRRm4DQF+nrpyatHqLGlTbe+mqvGlla7IwEAgE5EYQY6QZ/o\nID08bbDWFFfpz+/n2x0HAAB0Igoz0EmmDorTrImpenn5Dr2RXWx3HAAA0EkozEAn+vV5/TW+T6Tu\ne2u9lm3nECAAAK6Awgx0Ii9PDz1x1XAlRwTqpy/naNveg3ZHAgAAp4nCDHSyUH9vvXDdSPl4eej6\nOStVcbDR7kgAAOA0UJiBLpAQHqDnrh2pvdWNuumlbDU0c+cMAACcFYUZ6CJDE8L0yE+Gak1xlX75\nOuOzAQBwVhRmoAtNHRSne6em6YP1pXr40812xwEAAKfAy+4AgKu7eUKqdlTU6ckvtispPEBXZiXa\nHQkAAJwECjPQxYwx+tNFA1Syv16/fXuDevXw14S+UXbHAgAAHcSWDKAbeHl66PEZw9Q3Oki3vpKr\nLWU1dkcCAAAdRGEGukmw36Hbzfn7eOr6/6zS3poGuyMBAIAOoDAD3ahnmL+ev3akKmubdNOL2apv\n4nZzAAA4Ogoz0M0GxYfqsenDtH7XAd05f7Vaud0cAAAOjcIM2GByRox+f0GGPtlYpr9+lG93HAAA\ncBzcJQOwyQ3jU7Szsk7PLilUYkSgrhmdZHckAABwDBRmwEa/vzBDxZV1+sM7GxTfw19n9Y+2OxIA\nADgKWzIAG3l6GD02fZjS40I0+9Vc5e2utjsSAAA4CoUZsFmgr5eev3akgv28dcOcVdpzgNvNAQDg\nSCjMgAOIDfXTC9eNVE1Ds258cZVqG1vsjgQAANpRmAEHkdEzRI/PGK780mr9/DVuNwcAgKOgMAMO\n5Ky0aP3pogFavGmv/vf9PLvjAAAAcZcMwOFcMyZZRRV1en5poZIiAnT9uBS7IwEA4NYozIADuu/8\ndBVX1un+9/MU3yNAkzNi7I4EAIDbYksG4IA8PYweuXKoBvUK1ey5ufrDOxu0vfyg3bEAAHBLFGbA\nQQX4HLrd3AWD4jR35U6d8/cvde0LK/X5pr1q40AgAADdxliWY33jzczMtLKzs+2OATiU8ppGvbZy\np15ZvkN7axqVEhmomWOSNG1EvIL9vO2OBwCAUzLG5FiWlXnC6yjMgPNoamnTRxtK9eKyIuXurFKg\nj6emjYjXzLHJ6h0VZHc8AACcCoUZcHFri6v04rIivb+uVE2tbTqjX5SuG5usM/pFycPD2B0PAACH\nR2EG3ATbNQAAODUUZsDNNLW06eONezTn60K2awAA0AEUZsCNrSup0pxlRXp/Lds1AAD4IRRmAMfc\nrnHnpL66eGgvu6MBAGC7jhZm7sMMuLCoYF/9/Jy+Wvqbs/XY9GEK8vXSnfPXaFFemd3RAABwGhRm\nwA34eHnooiE99cZPx2hgz1DdOX+NtpbV2B0LAACnQGEG3Iift6eemTlCft6euumlbFXVNdkdCQAA\nh0dhBtxMXKi/nr5mhEqrGjR77mq1tLbZHQkAAIdGYQbc0IikHvrzJQO1dNs+/eXDfLvjAADg0Lzs\nDgDAHldkJii/tFr/+bpI6XEhuiIzwe5IAAA4JFaYATf22/PTNb5PpH731gbl7NhvdxwAABxShwqz\nMWaKMWazMWabMeaeYzw/0RiTa4xpMcZMO+LxpPbH1xhjNhpjftqZ4QGcHi9PDz0+Y5jiwvx0y8s5\nKj1Qb3ckAAAczgkLszHGU9ITkqZKypA03RiTcdRlOyVdJ2nuUY+XShpjWdZQSaMk3WOM6Xm6oQF0\nnrAAHz07M1P1TS2a9VKOGppb7Y4EAIBD6cgKc5akbZZlFViW1SRpnqSLj7zAsqwiy7LWSWo76vEm\ny7Ia27/07eDnAehm/WKC9eiVw7Rh9wH95r/r5GgTQAEAsFNHCmwvScVHfF3S/liHGGMSjDHr2t/j\nQcuydp9cRADdYVJGjO4+t7/eWbNbT39VYHccAAAcRpev+FqWVWxZ1mBJfSRda4yJOfoaY8wsY0y2\nMSa7vLy8qyMB+AG3ntlbFw6O04Mfb9JnmxifDQCA1LHCvEvSkfebim9/7KS0ryxvkDThGM89Y1lW\npmVZmVFRUSf71gA6iTFGD08booy4EN3x2hpt28v4bAAAOlKYV0nqa4xJMcb4SLpS0rsdeXNjTLwx\nxr/9zz0kjZe0+VTDAuh6/j6eemZmpny9PXTzSzk6UNdsdyQAAGx1wsJsWVaLpNmSPpGUL+l1y7I2\nGmPuN8ZcJEnGmJHGmBJJl0t62hizsf3l6ZJWGGPWSvpS0t8sy1rfFX8RAJ2nV5i/nrx6hEr21+n2\neavV2sYhQACA+zKOdho+MzPTys7OtjsGAEmvrdypexes180TUvTbC46+myQAAM7NGJNjWVbmia5j\nNDaAHzQ9K1H5pdV6dkmh0mJDdNmIeLsjAQDQ7bgvMoDj+v2FGRqTGqF731qv1TsZnw0AcD8UZgDH\n5e3poX9fNVwxIb665eUclVU32B0JAIBuRWEGcEI9Ag+Nzz7Y2KJZLzM+GwDgXijMADokLTZE/7hi\nqNYWV+m+BesZnw0AcBsUZgAdNmVgrH4xqZ8WrN6l55YU2h0HAIBuQWEGcFJuP7uPpg6M1QMf5evL\nLYyyBwC4PgozgJPi4WH0t8uHqF9MsGbPzdXyggq2ZwAAXBqFGcBJC/T10rMzM+Xr5akrn1mus/72\nhR5bvFXFlXV2RwMAoNMx6Q/AKatpaNZHG/ZoQW6JlhdUSpKyUsJ12fBemjooTiF+3jYnBADgh3V0\n0h+FGUCnKNlfp7dX79KC3F0q2FcrXy8PnTsgVpcO76UJfSLl5ckPtAAAjoXCDMAWlmVpTXGVFuTu\n0rtrd+tAfbOign3146E9denweKXHhdgdEQAASRRmAA6gsaVVn28q14LcEn2+ea+aWy2lx4XosuG9\ndNHQnooO9rM7IgDAjVGYATiUytomvb9ut/6bu0tri6vkYaSJ/aJ06fB4nZsRIz9vT7sjAgDcDIUZ\ngMPatveg3lpdordyd2n3gQYF+3rp/EFxmpYZr5HJ4XbHAwC4CQozAIfX1mZpeWGFFuTu0kfrS1Xb\n1KrpWYn640UZ8vVixRkA0LUozACcSl1Tix5bvE1PfbldwxLD9NTVIxQTwh5nAEDX6Whh5j5PABxC\ngI+X7pmapidmDNfmPTW68F9LlV1UaXcsAAAozAAcywWD4/TWreMU6HNoiuDL3xQxehsAYCsKMwCH\n0z82WO/MHq8JfSP1+3c26tdvrlNDc6vdsQAAborCDMAhhfp76/lrR+rnZ/fRGzkluuLpb7S7qt7u\nWAAAN0RhBuCwPDyM7jq3v56+ZoQKymv1o38t1TfbK+yOBQBwMxRmAA7vvAGxevu2cQoN8NbVz6/Q\nC0sL2dcMAOg2FGYATqFPdJDeuW2czk6L1v3v5+kX89eovol9zQCArkdhBuA0gv289fTVI3TX5H56\nZ+1uXfbkMhVX1tkdCwDg4ijMAJyKh4fRz8/pq+evzVTx/jr96PGlWrK13O5YAAAXRmEG4JTOTovR\nu7PHKzrYV9e+sFJPfbmdfc0AgC5BYQbgtFIiA/XWreM0ZWCs/vrRJs1+bbXqmlrsjgUAcDEUZgBO\nLdDXS0/MGK7fTEnTR+tLdckTy1S0r9buWAAAF0JhBuD0jDH62Zm9Nef6LO2pbtBFjy/V55v32h0L\nAOAiKMwAXMbEflF6b/Z49eoRoBvmrNIDH+Zra1kNe5sBAKfFONo3kszMTCs7O9vuGACcWH1Tq377\n1notWL1LkpQUEaDJ6TGalBGjzKQe8vJkrQAAIBljcizLyjzhdRRmAK6q9EC9Fufv1cK8Mn2zvUJN\nrW0KC/DW2f2jNSkjRhP7RSnI18vumAAAm1CYAeAIBxtbtGRLuRbmlemzzXtVVdcsH08Pje4dockZ\nMZqUHq24UH+7YwIAuhGFGQB+QEtrm3J27NfCvDItzC/TjopD0wIH9QrVpPQYTcqIVkZciIwxNicF\nAHQlCjMAdIBlWdpeflCf5pVpUV6ZVhdXybKkXmH+mpR+aOvGqJQI+Xix7xkAXA2FGQBOQXlNoz7b\nVKaFeXu1dFu5GprbFOzrpTP6R+n6cckakRRud0QAQCehMAPAaapvatXSbfu0KK9Mi/LLtL+uSXdO\n6qfbzuojTw+2awCAs+toYeZ4OAD8AH8fT03OiNHkjBjVNDTrd29v0D8WbtE32yv0yJVDFRPiZ3dE\nAEA3YFMeAHRAsJ+3HvnJUD08bbDWFFdp6qNL9PkmpgkCgDugMANABxljdHlmgt67fbyig311/ZxV\n+ssHeWpqabM7GgCgC1GYAeAk9YkO0tu3jdM1o5P07JJCTXtqmXZU1NodCwDQRSjMAHAK/Lw99b8/\nHqinrh6hon21uuCxpXp37W67YwEAugCFGQBOw5SBsfrwjgnqHxusn7+2Wr95c53qmlrsjgUA6EQU\nZgA4TfE9AjR/1mjNPquPXs8p1kWPf61Ne6rtjgUA6CQUZgDoBF6eHrr7vP565cZROlDfrIsf/1qv\nLN8hR7vXPQDg5FGYAaATjesTqY/umKBRqRH63dsbdOuruTpQ32x3LADAaaAwA0Aniwzy1ZzrRure\nqWlamFem8x9dopwd++2OBQA4RRRmAOgCHh5Gt5zRW2/8dIyMka54+hv9+4ttamtjiwYAOBsKMwB0\noWGJPfThHRM0ZUCsHvp4s2a+sFJ7axrsjgUAOAkUZgDoYiF+3np8xjA9cOkgrSqq1PmPLtFXW8rt\njgUA6CAKMwB0A2OMpmcl6r3bxys80EczX1ipu+av0a6qerujAQBOgMIMAN2oX0yw3rltvH56Rm+9\nv75UZ/3tCz348SZVN3AnDQBwVBRmAOhm/j6eumdqmj6/+0xdOChOT36xXWc+/IXmfF2oppY2u+MB\nAI5CYQYAm/QK89c/fjJU798+Xulxwfrje3k6959f6sP1pQw8AQAHQmEGAJsN7BWqV24cpf9cP1K+\nXp669dVcXfbkMuXsqLQ7GgBAFGYAcAjGGJ3VP1of3jFBD142SCX763XZk9/oZ6/kqHBfrd3xAMCt\nGUf7sV9mZqaVnZ1tdwwAsFVdU4ueW1Kop77crqaWNl09Okk/P6evwgN97I4GAC7DGJNjWVbmCa+j\nMAOA4yqvadQji7Zo3qpiBXh76mdn9dYN41Lk5+1pdzQAcHodLcxsyQAABxYV7Ku/XDJIn9w5QaNS\nI/TQx5t11t++0Js5JYzZBoBuQmEGACfQJzpYz12bqXmzRis62Fd3v7FWF/5rqZZu3Wd3NABweRRm\nAHAio1Mj9Nat4/TY9GGqbmjW1c+v0LUvrNSmPdV2RwMAl0VhBgAn4+FhdNGQnlr8yzP0uwvStaa4\nSuc/ukR/em+japgYCACdjsIMAE7K18tTN01I1Ze/OlMzRiVqzrIiTfrHl3p/3W4GnwBAJ6IwA4CT\nCwvw0Z9/PEhv3TpOUcG+mj13tWa+sJL7NwNAJ6EwA4CLGJoQpnduG68/XTRAa3ZW6bxHvtI/F25R\nQ3Or3dEAwKlRmAHAhXh6GF07NlmLf3mGpgyI1aOLt+q8R77Sl1vK7Y4GAE6LwgwALig6xE+PTR+m\nV24cJU9jdO0LK3Xrqznac6DB7mgA4HQozADgwsb3jdRHd07QLyf30+L8vTrn71/ouSUFamltszsa\nADgNCjMAuDhfL0/dfk5fLfzFGcpKCdefP8jXhf9aqpwdlXZHAwCnQGEGADeRGBGgF64bqaeuHq4D\n9c267MlvdM9/12l/bZPd0QDAoXnZHQAA0H2MMZoyME4T+kbpkUVb9MLXRfpk4x7dOzVd00bEy8PD\n2B0RAL6nuLJOKwsrtWlPtdpsuM08hRkA3FCgr5d+e0GGLhsRr9+9tUG//u86vZ5drD9fMlBpsSF2\nxwPgxizLUlFFnVYUVGhFYaVWFlZqV1W9JMnXy0Pent2/QcI42jSozMxMKzs72+4YAOA22tosvZlb\nogc+zFd1Q4tuGJesOyb1U5AvayoAup5lWdq696BWFFZqRUGFVhZWam9NoyQpMshHo1IilJUSrlGp\n4eoXHdypPwkzxuRYlpV5ouv4vyEAuDkPD6MrMhM0OT1GD368Sc8uKdTba3brrsn9dPmIeHnZsJoD\nwHW1tVnK31OtFQWHVo9XFlWqsv0sRWyIn8b0bi/IKRHqHRUoY+zfKsYKMwDgO3J37tef389T7s4q\n9Y0O0r3np+ms/tEO8U0LgPNpaW3Txt3VWlFYoRUFlVpVVKnqhhZJUnwPf41KidCo1HCNSglXYnhA\nt/6/pqMrzBRmAMD3WJaljzfs0YMfb1JRRZ3GpEbovvPTNSg+1O5oAJxEQflBPfDRJi3btk+1Ta2S\npNTIwMPbK7JSItQrzN/WjBRmAMBpa2pp09wVO/To4q3aX9esHw/tqV+e218J4QF2RwPgoNraLP1n\nWZEe+niTfL08dNHQnodWkVPCFR3iZ3e876AwAwA6TXVDs578YrteWFooS9L1Y5N161l9FOrvbXc0\nAA5kR0WtfvXGOq0sqtTZadF64NJBinGwknwkCjMAoNPtrqrX3z7drLdW71Kov7duP7uvrhmdJB8v\nDgYC7qytzdKrK3bo/z7cJC8Po//5UYamjYh3+LMPFGYAQJfZuPuAHvhwk5Zu26fE8AD9ekp/XTAo\nzuG/OQLofMWVdfrNf9dp2fYKTewXpb9eOkg9bd6b3FEUZgBAl7IsS19uKddfP9qkTXtqNDQhTL+9\nIF0jk8PtjgYH19jSqq1lB5VfWq380hrll1areH+d0mJDNDo1XFkp4cqIC+GWhg7OsizNW1WsP7+f\nJ0n63YUZunJkglP9w5nCDADoFq1tlv6bU6K/L9yssupGnZsRo99MTVPvqCC7o8EBlNc0thfj6sMF\neXv5QbW0zzf28/ZQ/9gQxffw18ZdB1RUUSdJCvL1UmZyj8P34x0cH2rLhDcc2+6qet2zYL2+2lKu\nsb0j9NC0wYrv4XyHgSnMAIBuVdfUoueXFOqpL7eroaVNM7ISdcekvooM8rU7GrpBc2ubCsprDxfj\nvPZyvO9g4+Fr4kL9lB4XovS44PbfQ5QcESjPIya37TnQoJVFlYfHIm/be1CS5O/tqeFJYYfvtjAk\nIUx+3p7d/vd0d5Zl6c2cEt3/Xp5a2izdd36arhqV1KnT97oThRkAYIvymkY9uniLXltZLH9vT90y\nMVXnD477XjGCc9u8p0ZLt+07XJC3lh1UU2ubJMnH00N9Y4IOl+L0uGClx4aoR6DPSX/OvoONWlVY\neWhscmGlNu2plmVJPl4eGpoQptEp4RqVGqFhiWEK8GGAcVcqq27QfQvWa/GmvcpKCdfD0wYrKSLQ\n7linhcIMALDVtr0H9eDHm7Qwr0zS///Re8YRq4tpscEK9uPWdM5mVVGlZjy7XM2tliKDfJUeF6yM\nw+U4RKlRgV22faKqrkmrivZrZeGhFegNuw6ozZK8PIwGx4dqVOqhscojk8MV5EuB7gyWZemdNbv1\nh3c3qrGlVb8+L03XjU122lXlI1GYAQAOYWtZjdYUVx0+3JW/p1pVdc2Hn08I91d67P8vWxlxh/az\nusI3Y1e0q6peFz++VEG+Xnr15tG2T2qraWhW9o79Wll4aBvHupIDammz5O1pNDo1QpMzYnROeozt\nOZ1VeU2jfvf2en2ysUzDE8P0t8uHKNWFzidQmAEADsmyLO2pbjh8ACyv/Uf6hftq9e23pCBfL6XF\nBn/nR/r9Y4P5kbvN6ptaNe2pZdpRUae3bxurPtHBdkf6nrqmFq3eWaWvtpRrYX6ZCsprJUkZcSGa\nnBGjyRkxGtAzxKnu5GCX99ft1u/f3qDaplbdfW4/3Tg+1eW2VXVqYTbGTJH0qCRPSc9ZlvXXo56f\nKOkRSYMlXWlZ1pvtjw+V9KSkEEmtkv5iWdb8430WhRkA3FN9U6s2l9V8544Km0prVNPYIkkyRkqO\nCNSQ+FBdmZWoUSnhlJ5uZFmWbn9ttT5YX6rnr83U2WkxdkfqkO3lB7Uor0yL8suUs2O/2qxDhw/P\nSY/W5IxYjU4Nl68XhwePVFnbpN+/s0EfrCvVkPhQ/f2KIQ75j6PO0GmF2RjjKWmLpMmSSiStkjTd\nsqy8I65J1qFSfLekd48ozP0kWZZlbTXG9JSUIyndsqyqH/o8CjMA4FuWZalkf/3hVej80mqtKKxU\nVV2z0mKDdd3YZF08tJf8fSg8Xe2Jz7fp4U8269dT+uvWM/vYHeeUVBxs1Geb9mpRfpm+2rJP9c2t\nCvL10hn9ojQpI1pn9Y9WWMDJH0x0dtUNzdq1v1679tercF+tnv5quw7UN+vOSf10y8RUl74fdmcW\n5jGS/mhZ1nntX98rSZZlPXCMa+dIev/bwnyM59dKmmZZ1tYf+jwKMwDgeBqaW/XOml36z9dF2rSn\nRmEB3rpyZKKuGZPEPtUusiivTDe/nK0fDe6pR68c6hIr+w3NrVq2fZ8W5h0q0OU1jfL0MMpM6nF4\n64az3wFCOvSPzv11zSrZX3eoFFfVq2T/oV+7quq1a3+dqhtavvOaQb1C9fDlg5UWG2JT6u7TmYV5\nmqQplmXd1P71NZJGWZY1+xjXztEPFGZjTJakFyUNsCyr7Yc+j8IMAOgIy7K0srBSc5YV6ZONeyRJ\n52bE6tqxyRqdynaNzrK1rEaX/HuZkiMD9MYtY11yNb+tzdK6XQe0MG+PFuXt1eayGklS3+ggTc6I\n0aSMGA3uFeqQK61tbZbKDzYeLsBHF+Nd++tV39z6ndcE+XqpV5i/4nv4q1eP9t/DAg7/OSLQx23+\n+3GowmyMiZP0haRrLctafozXzZI0S5ISExNH7Nix40S5AQA4bFdVvV7+ZofmrdrJdo1OVFXXpIuf\n+Fq1ja16d/Y49XSTFfydFXVamF+mRXllWllUqdY2S54eRrEhfodLZXzYt2UzQL3C/BUX5tcle6Fb\nWtu0p7pBu76zKlyvkqpDxXh3VcPh+19/KyzA+/+1d+9BcpVlHse/T66TSWaSmVxIyJ1UwAAil1wg\n1q6oi1ioLLsUSrysWW+FilbtqqVbuhbl3kSrdrdKWUvYwsuugIJyE1i1EERTkkAkgiYksAQlJCHZ\n3CWZXCbP/tEnQyeGTkdnujvd308VNT2Hc7qfmadO9y/vvOe8LwXiMe19wXjymBFM7Wqnc8SQlgnE\nx9IwUzIiopNSWP7nl5uqUc4RZknSH+po0zXeNm8q7zp/+gm5bG89Heg9yOKvPcLStVu45QPnc970\n7nqXVBfbd+/jJ2s2s+aFXYeF1o07eyiPUBEwoWN4EVTb+wLqlLIR3KP9423vgV42bO85bHR4Xdno\n8MadPfQePDyrjRs1/CjB/aVRYu8/Xb3+DMxDKF3093rgeUoX/b09M399lH2/TllgjohhwH3A3Zn5\n79UUbmCWJP2xjjZd46LTT2LxwplO16jS5+5eyY1L1vKFy8/irfOm1ruchrPvwEE27ujpG+k9cvR3\nw/YeDhwRdMeOHMbkrhFM6Ghj64t7eX77Hjbt2ntY8B4U9I1kHxm+D311SfD+09+3lbuE0m3jBgM3\nZuY/RcTngEcz866ImAfcDnQBPcDGzDwjIt4JfA0oD9eLM3PFy72WgVmS1J+e376H/374N9y87KXp\nGu9eOIPLnK7xsm599Dk+cdvjLF44g2suPaPe5ZyQeg8mm3b19I0UHxpBXrdtD5t27qW7CM9TyoLx\nlK4RTBzdNmCrJOr3uXCJJElljpyuMXrEUK6cN5Ur5k5h1vhRjjoXlv9mG4uuf5h5M7v4xl/Pb8gL\n3aT+YmCWJOkojpyucTBLc0IXzOxmwSndLJg5ltkTRrXk0twbduzhLV9aQvuwwdz54VfTNbL17kms\n1lJtYHZWuCSppUQEC04Zy4JTxrJ++x4eXL2ZZWu3sHTtVu55YgMAXe1DmTeju7TfzG7mTOpsuiWB\nj9Szv5cPfHM5e/Yd4Kb3LzAsS2UMzJKklnXymBG8fcE03r5gGpnJc1v3sLQIz0vXbuGHK18AoKNt\nSClAz+xm/sxuzpw8uqnmmWYmn/zu4/xq/Q6uf9dcTj2pOZdBlv5QBmZJkiiNPE8b2860se1cMbd0\nV4j12/ewrAjPS9du5cdPbgKgfdhgzpvexfmnjGX+zG7OmjJ6QO7BWytffegZ7lyxno+/4VQuOv2k\nepcjNRznMEuSVKVNu3p4ZO22UoB+ZmvfinDDhwzi3GldzJ/ZzaumjmbOpE4mdradEBcSPvDkJt7z\njUe45JWT+PKic06ImqX+4kV/kiQNsG0v7mPZs1tZ+sxWlj27hZXrd3Lo1rtj2ocyZ2IncyZ1MmdS\nB3MmdTL7pFENNRL99Kbf8RfXLWFqdzu3ffAC2of5h2e1Fi/6kyRpgHWNHMbFZ0zk4jMmArCrZz9P\nbtzFqg07WbVhJys37OKmZb+hZ39p6eIhg4JZ40f1BehD/43vGF7z2nfs3s8Hvvkow4YM4oZ3zzUs\nSxV4dkiS1E862kp315g346VlpHsPJs9uebEvRK/asIula7dyx4r1ffuMGzWcOZM6OL0sRJ8yfuSA\nXVjYezD5yC2P8dy23XzrfeczecyIAXkdqVkYmCVJGkCDi1HlWeNH8eazTu7bvu3FfazaWArQh8L0\n15Y8y77e0mj0sMGDmGPvWRQAAAjcSURBVH3SqLKR6FKgHtP+x9/u7fP3reKhNZv5l798JfNndh/7\nAKnFGZglSaqDrpHDWDhrHAtnjevbtr/3IM9sfrFsSsdOHly9mduWr+vbZ9LotsPmRc+Z1MmMsSOr\nvk/0d5ev44afruWvLpjOovnT+v3nkpqRgVmSpAYxdPAgTpvYwWkTO7jsnMl92zft6jlsJHrVhp38\nZM1meosrDNuGDuK0iZ2cXhaiXzGxg462oYc9/4rntvN3tz/BBaeM5e/ffHpNfzbpRGZgliSpwU3o\naGNCRxuvOXV837ae/b08vel3rCwL0fc+sZGblz3Xt8/U7hF9d+qYNWEU//j9lUzoGM517zi3qRZe\nkQaagVmSpBNQ29DBnDl5NGdOHt23LTPZsKPnsAsMV23YyY9WvUBmacGV7713Id0uey0dFwOzJElN\nIiI4ecwITh4zgtfPeWnFvt37DrB64y5O6mzjZO+IIR03A7MkSU2ufdgQzpnWVe8ypBOWE5gkSZKk\nCgzMkiRJUgUGZkmSJKkCA7MkSZJUgYFZkiRJqsDALEmSJFVgYJYkSZIqMDBLkiRJFRiYJUmSpAoM\nzJIkSVIFBmZJkiSpAgOzJEmSVIGBWZIkSarAwCxJkiRVYGCWJEmSKjAwS5IkSRUYmCVJkqQKDMyS\nJElSBQZmSZIkqQIDsyRJklRBZGa9azhMROwCVte7DgEwDvi/ehch+9BA7EVjsA+Nw140Bvvwh5ue\nmeOPtdOQWlRynFZn5tx6FyGIiEftRf3Zh8ZhLxqDfWgc9qIx2IeB55QMSZIkqQIDsyRJklRBIwbm\n6+tdgPrYi8ZgHxqHvWgM9qFx2IvGYB8GWMNd9CdJkiQ1kkYcYZYkSZIaRt0Cc0S8MSJWR8TTEfGp\no/z/v42IlRHxeETcHxHT61FnK6iiF1dFxBMRsSIifhYRp9ejzmZ3rD6U7Xd5RGREeEX0AKninFgc\nEZuLc2JFRLyvHnU2u2rOiYh4a/FZ8euIuKnWNbaCKs6Hfys7F9ZExPZ61NkKqujFtIh4ICIeK/LT\nJfWosxnVZUpGRAwG1gAXAeuAR4BFmbmybJ/XAkszc3dEfBC4MDPfVvNim1yVvejMzJ3F40uBD2Xm\nG+tRb7Oqpg/Ffh3APcAw4OrMfLTWtTa7Ks+JxcDczLy6LkW2gCr7MBv4DvC6zNwWERMyc1NdCm5S\n1b43le3/EeCczHxP7apsDVWeE9cDj2XmV4rBrXszc0Y96m029Rphng88nZnPZOY+4Bbgz8t3yMwH\nMnN38e3DwJQa19gqqunFzrJvRwJOfO9/x+xD4R+Aa4GeWhbXYqrthQZWNX14P3BdZm4DMCwPiOM9\nHxYBN9ekstZTTS8S6CwejwbW17C+plavwDwZeK7s+3XFtpfzXuC+Aa2odVXVi4j4cET8L/AF4KM1\nqq2VHLMPEXEuMDUz76llYS2o2veny4s/ed4WEVNrU1pLqaYPpwKnRsSSiHg4IvzLV/+r+vO6mDo5\nE/hxDepqRdX04hrgnRGxDrgX+EhtSmt+DX/RX0S8E5gLfLHetbSyzLwuM2cBnwQ+U+96Wk1EDAL+\nFfhYvWsRAHcDMzLzLOBHwDfqXE+rGgLMBi6kNLJ5Q0SMqWtFre1K4LbM7K13IS1sEfD1zJwCXAL8\nV/H5oT9SvX6JzwPlIzJTim2HiYg/Az4NXJqZe2tUW6upqhdlbgEuG9CKWtOx+tABnAk8GBHPAucD\nd3nh34A45jmRmVvK3pP+EzivRrW1kmrem9YBd2Xm/sxcS2l+5+wa1dcqjucz4kqcjjGQqunFeynN\n6yczfw60AeNqUl2Tq1dgfgSYHREzI2IYpZPsrvIdIuIc4KuUwrLz0gZONb0o/wB6E/BUDetrFRX7\nkJk7MnNcZs4oLuB4mNK54UV//a+ac2JS2beXAqtqWF+rOGYfgDsojS4TEeMoTdF4ppZFtoBq+kBE\nvALoAn5e4/paSTW9+C3weoCImEMpMG+uaZVNakg9XjQzD0TE1cAPgMHAjZn564j4HPBoZt5FaQrG\nKODWiAD4bWZeWo96m1mVvbi6GO3fD2wD3l2/iptTlX1QDVTZi48Wd4w5AGwFFtet4CZVZR9+ALwh\nIlYCvcAnMnNL/apuPsfx3nQlcEu6GtqAqbIXH6M0NelvKF0AuNie9A9X+pMkSZIqcCK4JEmSVIGB\nWZIkSarAwCxJkiRVYGCWJEmSKjAwS5IkSRUYmCWpRiJiTER8qHh8YUR8fwBeY3FEfPk4j3m2uI/x\nkduviYiP9191knRiMjBLUu2MAT50PAdExOABqkWSVCUDsyTVzueBWRGxgmJxpoi4LSKejIhvRbFK\nUzHie21E/AK4IiJmRcT/RMTyiPhpsaoaEXFFRPwqIn4ZEQ+Vvc7Jxf5PRcQXDm2MiEUR8URxzLVH\nKzAiPh0RayLiZ8BpA/WLkKQTSV1W+pOkFvUp4MzMPDsiLgTuBM4A1gNLgFcDPyv23ZKZ5wJExP3A\nVZn5VEQsAP4DeB3wWeDizHw+IsaUvc7ZwDnAXmB1RHyJ0kp41wLnUVqx84cRcVlm3nHooIg4j9KK\nbWdT+nz4BbC8/38NknRiMTBLUv0sy8x1AMWo8wxeCszfLraPAhYCtxYD0ADDi69LgK9HxHeA75U9\n7/2ZuaM4fiUwHRgLPJiZm4vt3wL+FLij7Lg/AW7PzN3FPi7JLkkYmCWpnvaWPe7l8PfkF4uvg4Dt\nmXn2kQdn5lXFiPObgOXFCPGxnleSdJycwyxJtbML6DieAzJzJ7A2Iq4AiJJXFY9nZebSzPwssBmY\nWuGplgGviYhxxYWEi4CfHLHPQ8BlETEiIjqAtxxPrZLUrBx1kKQaycwtEbEkIn4F7AFeqPLQdwBf\niYjPAEOBW4BfAl+MiNlAAPcX235vJLp47Q0R8SnggWL/ezLzziP2+UVEfLt4nk3AI8f7M0pSM4rM\nrHcNkiRJUsNySoYkSZJUgYFZkiRJqsDALEmSJFVgYJYkSZIqMDBLkiRJFRiYJUmSpAoMzJIkSVIF\nBmZJkiSpgv8HW8ltF3KYvUYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGP_ddYeSVmc",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o83HfSMLSVmd",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi7W_qMeSVmd",
        "colab_type": "text"
      },
      "source": [
        "# 【問題1】コードレビュー\n",
        "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
        "\n",
        "＜視点例＞\n",
        "\n",
        "* Sprint20で使用した実装とはどのように違うのか\n",
        "* 転移学習をどのように行っているか"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9b8O2IuSVmd",
        "colab_type": "text"
      },
      "source": [
        "以下のように、weights='imagenet'と事前学習した重みを引数にとって活用している。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIUmyppVSVme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# デコーダーブロックタイプの容易な変更を可能にできるようにモデルはパラメータ設定されており、\n",
        "# デコーダーブロックシンプルのように、関数を与えられるような議論のものである。\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    # ベースとなるエンコーダーモデル\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights) #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # エンコーダーパートにおける特徴抽出の層\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    # センターブロック\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    # デコーダーパート\n",
        "    # どのデコーダーブロックも、エンコーダーとデコーダー部分からの結合されたアウトプットを前に進めている。\n",
        "    # そして、デコーダーのアウトプットはエンコーダのアウトプット部分と同じディメンションにアップサンプルされる。\n",
        "    \n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjnfKmTISVmf",
        "colab_type": "text"
      },
      "source": [
        "# 【問題2】コードの書き換え\n",
        "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC2SgYbUSVmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# デコーダーブロックタイプの容易な変更を可能にできるようにモデルはパラメータ設定されており、\n",
        "# デコーダーブロックシンプルのように、関数を与えられるような議論のものである。\n",
        "def unet_VGG16(input_size, decoder_block,\n",
        "                weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    # ベースとなるエンコーダーモデル\n",
        "    base_model = VGG16(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "     \n",
        "    #base_model = ResNet50(\n",
        "    #    input_shape=input_size, \n",
        "    #    include_top=False,\n",
        "    #    weights=weights) #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # エンコーダーパートにおける特徴抽出の層\n",
        "    encoder1 = base_model.get_layer('block1_conv2').output\n",
        "    encoder2 = base_model.get_layer('block2_conv2').output\n",
        "    encoder3 = base_model.get_layer('block3_conv3').output\n",
        "    encoder4 = base_model.get_layer('block4_conv3').output\n",
        "    encoder5 = base_model.get_layer('block5_conv3').output\n",
        "    encoder6 = base_model.get_layer('block5_pool').output\n",
        "\n",
        "    # Center block\n",
        "    # センターブロック\n",
        "    center = decoder_block(\n",
        "        encoder6, 'center', num_filters=512)\n",
        "    concat6 = concatenate([center, encoder6], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    # デコーダーパート\n",
        "    # どのデコーダーブロックも、エンコーダーとデコーダー部分からの結合されたアウトプットを前に進めている。\n",
        "    # そして、デコーダーのアウトプットはエンコーダのアウトプット部分と同じディメンションにアップサンプルされる。\n",
        "    \n",
        "    decoder5 = decoder_block(\n",
        "        concat6, 'decoder5', num_filters=512)\n",
        "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
        "\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=512)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=256)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=128)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = decoder_block(\n",
        "        concat1, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Jq9VuVGYWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "\n",
        "model = unet_vgg(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMOaax9JSVmh",
        "colab_type": "text"
      },
      "source": [
        "# 【問題3】学習・推定\n",
        "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxbmfg8xmUWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR8gtBvhmPZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJX3GGFNSVmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aYZb1nNmIr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ed26a1c9-ec6b-4f19-92dc-841d967fbdfd"
      },
      "source": [
        "train = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./sample_submission.csv')\n",
        "depth = pd.read_csv('./depths.csv')\n",
        "\n",
        "train_src = '../train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0B4OzYGmIud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f8f85d0-f77e-4dea-b4e5-5913c810270e"
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T5SxVsI53nU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "c7721282-78a7-4d85-943b-8ce5a16eb3c3"
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b85d61b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3V2sZed93/ffw5d5JzkvpKjhm6na\ncgIhQGqDcGS4KAwrQWU3iHphGHaDVDEU6MZpnBcgktsLtRcFYiCI4wCBUCJ2pBaGHVcxIkEwkriK\nhKIXVU3Whi2JVsTatUyKEmfE9yE9Q2pWL87Zi7/Z3r+9/s9Z+8zsc873Awh6zp61137WWvssbe3n\nd/7/NgyDAAAAAGS33eoJAAAAANuOD80AAADABD40AwAAABP40AwAAABM4EMzAAAAMIEPzQAAAMAE\nPjQDAAAAE/blQ3Nr7f2tta+21p5urX10P14DALA53LcBYL226eYmrbXbJf1HSX9F0jOSflvSTw3D\n8JWNvhAAYCO4bwPAtDv2YZ8/IOnpYRj+UJJaa78m6QOS4s33zJkzw4ULF8ov4B/007iy/Rytta7H\n5+xzv/S+XuW8944rr5Xs9/mq7N+3qbwnbrvttpWPp7FvX5lbenwv53xT13W/t0/PTSrnrue99fLL\nL+v111+/ub+8m9d137733nuHRx999ObNDgA26Mknn7w8DMN9vc/bjw/ND0r6E/v5GUl/ad0TLly4\noI9+dGc1MP2P1fXr18fxd77znXH81ltvTY59ex/7PtP/OKcPMLfffvvKbdLjc8Zu+fHeDwl+DOkD\nnEvn/c033xzH165dW/l45dr4/tP1SDZ1TpPKB1y/3nfcccfK8Z133jmOjx07No6PHz++8nEf+3N9\nn/66vdfRz206/1K+ZunaV6535fcybeOvm+a9fAyrpN/jdH7TtV+cx0984hOTr3kAdN23H330UT3x\nxBP7PikA2A+ttT/ey/Nu2R8CttY+3Fp7orX2xGuvvXarpgEAKPB79qVLl271dADgptuPb5qflfSw\n/fzQ7mM3GIbhcUmPS9IjjzwyLL5dSt+KVr4V3nQ+e1nl2+ibbdU3X3t5biVC4Px6+Dd0+xHP6D2u\nyrJ/5Zr5N57pXKVv4tOKRu83vmns18jPf7p2e4ktpG/Ue69N5X1Wec85/9Y5ncf0eGXVoPJN/mL/\nlW+3D4DJ+7bfsx977LH9vdkCwBbaj2+af1vSu1tr72qtHZP0k5I+sw+vAwDYDO7bADBh4980D8Pw\nVmvtb0v6d5Jul/TLwzB8edOvAwDYDO7bADBtP+IZGobhNyX9Zsf243KrL4umZc/eP+ab81f36fG0\n3DsntpFea90ye+8fD/ZGMlL1hhQb8GszZ0l/UxGc3us6J+KS4kSVP3CsHK+fW/8DwRTbqPwhY5rD\nssofxO7HH6X64x7JSNIfDlae61I8Y9Xvw37Hwm6W3vs2ABw1dAQEAAAAJvChGQAAAJiwL/GMXsMw\n6OrVq5LyX7Avb7/QW691Uw0S0hJ6im1syrp9bqr+c2X7FKOpVNKoVDJIsQS3HxGcypyTdE4q78XK\n63okw89JpX7zVMRgr9J+0++uz7sS1UgVTFyKp6TtU51w1xMjOSTVMwAAE/imGQAAAJjAh2YAAABg\nwlbEM65fvz62403xjMpf/O9HpYS09Dtn6b5SYaNS5WLddnMaSqTjrCzF91aNSMv1leok6bm974lK\nNKLyXvH5pO297XRFmk9qpJJ+fyrNOtY1N9lUE5O0fSVKkuZTafXu26c23ZXqNavmc1iqZwAA1uOb\nZgAAAGACH5oBAACACVsRz/DqGZVKAJWqFL3Lyb1RjU2pLF1Xqlmse37va6Rt3JyoRlJpFJLiImmJ\nPkU+3H43THE+n0pliEqlmN54RrVxR+W9lq5Nb1TDVeIZLkUv/F5SqbyRohpTFWSIZwDA0cA3zQAA\nAMAEPjQDAAAAE7YmnrFYVk3L0ZUl5d5IQ1pWrUQJ5kQ1fD6pccfUX+xP/VulKUlvJKMyvxTVSEvo\nKT6RqpZUGqNUIhmV6hxz9MYqeiNH6Xdjzng5OtEbjahULfH9VJoXVd7Tfh6PHTs2jr16Rop9pQob\nld/LxfbEMwDgaOCbZgAAAGACH5oBAACACVsdz9iPhgpzpCXbSlSjt6FJsrxN5Xz1Vs/onWulMUVa\niveoRooKVKIam4o9zLk2lfdrpSlHbyWNOdUz0nh5HpUYUG9MoTdOVPn987FHLxbVeaQc1Uj7n/od\nI54BAEcD3zQDAAAAE/jQDAAAAEzYiniGq1QdSHGDFAdIS8iVv/CfM880txQH2Msyb6pQ4VKlhcrx\n956jtKSfzrsvladtKo0pUjWMtOTu5sQqXLXxzNT+PbJSmYOf50pUw8/5uvduJXaTzGnaU/n9Tu9R\nP34/jx7VSNukRi37cb0BAAcP3zQDAAAAE/jQDAAAAEzYunhGRVrKrTZtWPAl2LTEnZb6e5ubzIlk\nrIuUpOX13khGZa6VbeYsv/fGM3qbnrjexyvzqejdf6oukuIZ6Zykc7sunlFpKJQiE+n3I1VRqezT\n9UZ2/DxWfo97fu+JaQDA0cA3zQAAAMAEPjQDAAAAE7YintFau+Ev+hcqS8IpnpEaGLgUz6g0cqg0\nQtiUdfGMylJ7Zfl4TgOUpLfZTKWySW81j3Qt0/Xba4OLdY/36q0EUvnd8H2miiXL0QP/txTxSb9D\nlWtfie+kfVbiV64SVUlz8MobxDMA4Ojim2YAAABgAh+aAQAAgAlbE89YFaGoLNmmZdoU1UhLqf7X\n9ZW/3k/SMrCr7LNShWL5NSoVEtJrpIohSWVJvLeqRnpuUonXVKpqVMa957Yy597HK9ukqhqViNKq\niNSq7SpRjd6KLb2/664S56jMofK6/nuy2CfxDAA4GvimGQAAAJjAh2YAAABgwlbEM6TVS69pibS3\nuUnlL+39cY9qzFl6rcQi0uPVOEOlyUOl6UTvPHpjCZVKCZUogkvPTfufc94rMZjeiEU6h737TyqN\nTubqjV5UrpOP77zzznGc7gG+z0rMqvI+SPNZ1eikElUCABx83O0BAACACXxoBgAAACZsRTyjt3pG\nWqad0yxhTvON3iX63hjGuohBb2OH3rjJnPlVGo70Rlgq83SV8572k+Iom4pY9DbL6Y159FawWNZb\nwSRJTXfScytVLFIljdTUqPIerbzWtWvXxvHiWKieAQBHA980AwAAABP40AwAAABM2Ip4hrQ6ZjCn\nOUZSeW5a1k7LzJUl58pSdJrDunhG73nZVJSkUoWkYlNL273xjPRcj0lUqk/0xicqUZlKo5nKey5F\nPnyfe6kUk5qYVKI2lcYortKwKFVRSVGNNLdKpMv3uTh3VM8AgKOBuz0AAAAwgQ/NAAAAwIStiGe0\n1ibjGXOqW6Ql8co+K3/JX6msUFn6TpGMvcQzXG+coLfiRGU+vTGM3qYZlehF2mfluSli4dK1TzEP\nj0ak/VTiJb2RILeugkeKcaSIhT/+5ptvrny99DtUqQaSYh6pmk66Bmk+lfeuvxbxDAA4WrjbAwAA\nABP40AwAAABM2Ip4hrT3Kgpp2bxSgSAtffdGFSoRjlTJoHd5eHkpuHfJPm1TiRz0xhgqFQv2Q2X/\nlSX1dN57Y0CVc5jiD70Rn0pUoxohSu+Jyn7TtU+/H378XqGiEtWo/P5Vfs96X2sRQaG5CQAcDXzT\nDAAAAEzgQzMAAAAwYWviGYtlz7REWlk67Y1krKtKMfXc3qhG2k/FuioRvfPuHVdeq7Lc3Xuuk0rU\noaK3UUvlfZkiHL2xIVeJP/RWz6jMeXm7yvwqDX/S78dUAxHpxnNX2f+c6jvp8VWVNKieAQBHA3d7\nAAAAYAIfmgEAAIAJWxHPaK11LbVXlo1dpenEnOYblahGbyQjvda6/VQaeVT223t+5zQ06W3IkrbZ\nlHTNUhxiTtWVVDGicl16q2qk92X1fd8b5ak0g0lzunbt2jj28+LjVBkjNT3xbe68886V86nEP1ah\negYAHA180wwAAABM4EMzAAAAMGEr4hnS20ucqWJBZRnYpSXk3mYic6pqVKopVJa918UlKk035rxG\nbxRhTpRiU9tsSqVaSO95cKlKRIpqVKpT+H4qVV3WRTXS70Hv9e5tJFOJkvQ+nqIafq6PHz++cv5T\n9yGqZwDA0bDnu31r7eHW2udba19prX25tfazu4+fb639Vmvta7v/fW5z0wUA7AX3bACYZ85XJG9J\n+gfDMLxH0nsl/Uxr7T2SPirpc8MwvFvS53Z/BgDcWtyzAWCGPcczhmF4TtJzu+NXW2tPSXpQ0gck\n/fDuZp+U9AVJH5na32IpdU4Vi0rVh1R1YM44qTRX6I1qLOuNT2wq8uLScfZWeJjTeKXXpioeVPZT\niQQlvdeudz4ptrDq51Wv7WOvPuEqsZKkEpFxc2IbHtXwChupwcpi/gelesam79kAcNRsJIzXWntU\n0vdJ+qKk+3dvzpL0TUn3b+I1AACbwT0bAPrN/tDcWjsj6V9L+rvDMLzi/zbsfBWz8uuk1tqHW2tP\ntNaeuHLlytxpAAAKNnHPvnTp0k2YKQBsl1nVM1prd2rn5vsrwzD8xu7D32qtXRyG4bnW2kVJz696\n7jAMj0t6XJIeeuihYWqJs7dxR6WhQuW1XO/SbyWe4SpL18tL4L1L/JUl9DlL//uht1pDb9WLit5j\n741JVMyJx6SKGR5PWJ5z2ldlfqlRSKWByJxoTuX3LzU38XiGz+2wxDOkzd2zH3vssZtXxgYAtsSc\n6hlN0i9JemoYhn9i//QZSR/cHX9Q0qf3Pj0AwCZwzwaAeeZ80/xDkv6GpN9vrf3u7mP/naR/JOnX\nW2sfkvTHkn5i3hQBABvAPRsAZphTPeP/lJTWJd+31/32VmJIy7e+TWVpuSItcfvrpuXuSlSjtypB\n1ZzmJnPiLPu9bN0b1djvyhu952pTlVk8PpDeW+n9t656Rjp36f1YiWdUmrXMqbbhUmWM9Li/lm/j\ncY5Vx3VQ4hn7dc8GgKOCVlYAAADABD40AwAAABNmVc/Yb3OiGr0qS/1padmXeCuRjLScW4lLLD/e\nW1mitxpBZd6uEl3orfiRHq8cy5yl896KHHPG6bUq5y39bqR9evRgXTzDpehFOgaPjLgU7Uhxjkq0\nKh2bxyp87L+vlaoiabzYz0GJZwAA5uGbZgAAAGACH5oBAACACVsTz9hUZYNV+6vEIXqX/X0p15ei\nK1Uy0ja9c5ZWN1tYHvdWD0lzSnojKXNiHm5O7KSyz6QSn0jL/pXtfQ6VhjqVaEMlblCNZ6ToRWpi\nUolkpPdrb4QoxTOOHz8+jo8dO7ZyG5ciHx7tmFvVBgBwsPBNMwAAADCBD80AAADAhK2LZ/QurW9q\nWb6yz8pr+ZJt7xJ9bwOU5Z8rDSWS3oYdldhA77GlqiiVZjZzmmBU4iuV6EyKCbg51UUqlR5SZKAS\nN1h+3VSVo3L9UsOVSsOUSiQqxTCuXbu2cvzmm2+unFv6fa287mJM9QwAOBr4phkAAACYwIdmAAAA\nYAIfmgEAAIAJBybTnHKnvR3xejsIzulAlzKolTxwZfvleaRyY3M651XKz1VyupXOgr2vNafE3n50\nHOwtj5Z4brbSNTCVqEuP+9gzzcs5bH+NSodK31fab+V9kErXeS7Z95lyzD6+evXqOD5x4sQ49vJz\nlRx6Oo8AgMOPuz4AAAAwgQ/NAAAAwIStiGcMwzAuJVeW1ivRg94owfJ8erapRCTSuNI1sFrSqjKP\nit5l+fTc3jJ2vftJ86mUn9tUPMNV4iWpfFk1jrNqm1SqL8U5Kt0Bl59TKYGYohSVqEaS3tP+Wl5C\nzl83lZlLj687Fwurzgkl5wDgaOCbZgAAAGACH5oBAACACVsRz5BWL/f3dn+bE8+oPF5Z0k9LyHP+\n6n4vUY3e6hlpub9SlaI3GtG7nJ22770evc+dU5GjEo1I5y1Vz+jtJliJ0Kx7X1YqdKRIg3fpS1Uv\nUhWPyjWrRDVS9Qwf+zwr8ZpNdR0FABw8fNMMAAAATOBDMwAAADBha+IZq5Y9KzGB9Nf7SaUywZyq\nD5UKFpV5VmIOe9EbafBxqjSQluv9OFOEIEVVKtUhKo1Oeitg9J7r9P5LFVLSNr3NctI2lfOzl2oP\nlUhHam7iEQhvJtJb5SSd61QZw2MYf/qnf7pyPikK4/NM78XFmMgGABwNfNMMAAAATOBDMwAAADBh\na+IZC3OahlSWSdNf5leaGcyp4pAiGWnZfE7EoDq/yjwqMQN/3JfK07J2pUpBMic64+YsqVeuTeWc\npMoT+9H8JkVc9qIS1UjHliIc/n5KvzeVRiqVZjBpGz9HJ06cWDnPVdsTzwCAo4FvmgEAAIAJfGgG\nAAAAJmx1PCM9vqnmJikm0NtQorcZg0tL8dUGI5uqslGZa6VKQzq/vefUpf2kaEAl/jEnolB5/6U4\nTopqpKhCOq5NVX5Zd91740iVqhoptuFjP0fOz0uqQlKpTpL24zEPH6cGKKv2DQA4vPimGQAAAJjA\nh2YAAABgwtbFMyqxhzkq1TnmxAcq+69UqnCpWsi615sj7TMtm1f0xjmSVKGhUnEiHVclqtEbVahE\nXFIkITWOmRN36W0esk5lu8o1rsRNUpQixTD83HlDkzT2BihvvPHGyvHx48fH8aqoRqVZEQDg4OOb\nZgAAAGACH5oBAACACVsTz1gsz1aqWFSqTFRUluh7q2pUluvnNOJYXgruXSqvvIZL8/Y4QSW2Umnw\n4Sr7TBUa3LpoS49KQ4wkVXfwc+LVGlJViUoVkTTn3qjG8s+VxjuV1+79HfJz5+fo2rVr4zhFNdL7\nwyMWp06dWjk+ffr0OD558uQ49qjGYp/EMwDgaOCbZgAAAGACH5oBAACACVsTz+jRW93CVeIMc6pQ\nVJaxK41Ekr1Uz+iNg1SatThfNvfXqlQ7SJUPnD/u+/El97TsPyee0ducJi3Tp4hLOj+pksacihm9\nTYDWvYZL57fyGpXfCT8vHsnwqhc+9nOXXtfjGf4e8niGRzL88RMnTozjRVTD3/8AgJtjTpOyveKb\nZgAAAGACH5oBAACACVsXz+itmJGW7tMy9ZzKFb3RjsryfqVCQVWlokIlolBZ4q9EDnyp3JfBKxVP\nKhUh0hwq1VV6r2UleuHvxd79p5iDv256r7s5jXaq0nuo0oikMvb3TaowkpqVeITDn5vm7OfUYxvH\njh0bxx7V8HjG4nF/TQA4ym5FZOJm4ptmAAAAYAIfmgEAAIAJWxfPcJUGFyneMKdqQlr2760C0Lt9\n2mbdckclkuH7SueuEm1Jeo+nojdqUqm+UJlPOpZ0TnpjJ5UKGJWoxpzmOtV4RuUc+b5SrMLjC5Vx\nimSksW/vlTRSM5T0vk/NYzy24c1NFlEN4hkAjoLDHr2o4JtmAAAAYAIfmgEAAIAJWx3PcL3NHNIy\neG9jkUrFCLeXZfBV0vznLo9UqihssqLHlBTD8KoGqelJpTpEqmhRiR5U4hDpuamiSJpbJW6RohqV\n+E3lui//PlS282iEzylFIzw+keIZKXrR+351vo3v3+eTKnik9+iiwgbxDAAHHdGLGr5pBgAAACbw\noRkAAACYsHXxjMoSQWUJtreKQ4pqpMfnNA+pxEjSay1v07ukUqkMko6hEpHp3SYtfXtVCo8xVBqX\nVCIylaV+f60U1Ujj1Iik0sylUgUlzb9SLSTFPJaf29t8pLcCRnpuOl+V90qKwqQ5O3/cG6akfS7m\nkPYHANuA6MXm8E0zAAAAMIEPzQAAAMCErYlnLJY6KxUq9rrvdftP2yS9MQxXiSek8fI5SUv5aR5p\naX7VsvO657rK8VSOM1XMWFQpqM4txQoq0ZRKtZR0XD7nVFViTgOUyrWoHEs6V8sxg0pjkd6qFyk+\n4tJ7wt8HLlUhqfxuVGIu/ni6rgBwqxHD2H+zv2lurd3eWvud1tpnd39+V2vti621p1tr/6q1tvp/\n6QAANx33bADYm03EM35W0lP2889L+oVhGL5H0ouSPrSB1wAAbAb3bADYg1nxjNbaQ5L+S0n/k6S/\n33bWBn5E0n+9u8knJf0Pkj4+sZ+VS6mVCMTyfnq2qTTuqDT02FQDkEpUYbnRR+V4KtUV/PFKnCXp\njWd45YM777xzHPtSfIpnpPmnxhSpAkZaoq9UafH5VyIiKapRiW30VghJEYM0n+UmHSmGkcZpv5U4\nS7quJ06cWLnPyty8Aoa/t3zs18/fZ75N2v/iffbGG2+snPs22tQ9G8CtQQTj1pr7TfM/lfQPJS3+\nV/uCpJeGYVh8anlG0oOrntha+3Br7YnW2hNXrlyZOQ0AQMFG7tmXLl3a/5kCwJbZ84fm1tpflfT8\nMAxP7uX5wzA8PgzDY8MwPHb69Om9TgMAULDJe/Z999234dkBwPabE8/4IUl/rbX2Y5JOSLpb0i9K\nOttau2P3m4uHJD1b2VnlL92nVKIEm/rretcbyagsUfvjvlS8HM+oHEOKJVRiBmneaQ5zKoOk2EZq\ndNIbY0iRld73SiW2kaIaqcJEb2wjbVMZV+Ii656T3h9+bdL1SzGJFEFKx1yJZHhswlezPIbh8Y+r\nV6+O43SdfJvF49/4xjd0QGz0ng1g/xDD2E57/qQ6DMPPDcPw0DAMj0r6SUn/YRiGvy7p85J+fHez\nD0r69OxZAgBm4Z4NAPPsR3OTj2jnD0ye1k5e7pf24TUAAJvBPRsACjbS3GQYhi9I+sLu+A8l/UDP\n81P1jKXXWDl2c5qYpFjB8jyn5pC2T/NMkYy0vO3j5eenihCVbdL2/nrLzS9W7bN3nI6/Ukmkcoyu\nEtVwvfES5+eqtwFNZdwbyai8X5fnufxeW/BYhe83RYp8fPz48XHsMYkUwXF+Tj2S4ZEJj2F4POPU\nqVPj2CMc/txVlTGWx6siK5cvX1453202954NYDOIYRwstNEGAAAAJvChGQAAAJiwkXjGJiyWKCox\nCTenckVvxY5UhaJXpSpDtbmJ/5yiF6nJRaqY4Y9XogK9MYzeCEevOfGGyhx6q4VUKmCk5iyVmEBv\nDMPnmRp9LG/nUozGoxcphpEiGSnyUqlCkipmvP766ysf93FvPGPV++nLX/6yAGAdYhiHA980AwAA\nABP40AwAAABM2Jp4xlRUIi1Bp4oWvY1LUswhjdPyeJKWtHsbnayLZ7jeBhwpqtEbz+jlr5WafaTl\n8fTcNE77TPGMdG5dep95fCBFCVKDjtRYoxLD6K34kSq2LP+cIhYpkuHjVP2l8h5N18zPkTco8SoZ\n3mnUYxhzqmes+h3wiAuAo40YxuHGN80AAADABD40AwAAABO2Jp6xWNJIy92VSMbUvpf50nRlubsy\nnlNVIo3XVfyoxEfSfitVMhJfNncp5lKJVaQYg7+Wz9/3mfaTxr7PFK+pRmRW7SdFL1IcwB/3uaV5\nVuaWrrvHCVLsQsqxh5MnT64cr9vXKpUYRtrepWogPodUeSONU6xnVUSGeAZwNBC9AN80AwAAABP4\n0AwAAABM2Ip4Rmtt5bJHiiX0RgnSPl2luUJvPKN3DntZ+qnsq3IelysnTO0zVRSoVETw56Zz59ts\nKvJRiT24SqOT1HzDoxceNemNA6T5pKoXHklI5y1FO5YjFV4Bw2MYKarhMYUUfapUS6mco1RJJDVb\ncen+MRXDSGPiGcDBR/QCFXzTDAAAAEzgQzMAAAAwYSviGa63WsWcJZVUoSJtkxqaVJb60z4rTVjW\nqUQj1lXfWLVNpbpHqtSR4ikpzuHL773XOC37+/VI21SatqTXSjGP3qodKYZRqZLh0nt07rFXzq8f\nW5p3+r3x5/Y2eknv+1RJpDKuNLZZ9V4kngFsN6IX2BS+aQYAAAAm8KEZAAAAmLAV8YxhGCarTmwq\nkjFn/5WqGika0Ptaybol9OpzFlLcwpemU2MRH1cqHKTzkrZPS/EpClNpUJJiJ5X4R2q+kcbpWFJV\nicp8khSxqEQq1sU/0jz8+aliRqpykq59ml+lokX6vXSVRi9p7NVJVh1jinIA2B/ELXCr8E0zAAAA\nMIEPzQAAAMCErYhnSG8vq/Yuu1SWgSv7rFSMcKlSgI/T0nJaiq800Fheft7UMlWlikCad1py9/HV\nq1fHsVdHeOONN1Zu4w1BfPu0pJ+utzfsSMvvvk1q/lKplpKusUvnc87j6dqlOSfL7y2PSfj1SHGF\nynul8n6tVDOZU2Wn0tyl8r5Z7HNuBRzgqCNugYOCuz0AAAAwgQ/NAAAAwIQDH8/YlMryrUtL0Wmc\n/vK/UrkhxQSWpWXiOdUzXFr6T5EGj1VcuXJlHL/22mvj+NVXX1059u1ThMOjGj4Hjw+cOHFiHJ86\ndWrl2LdJUY1KRZVKJYZUlcHHlYYySWWbVNljXTyjMqdKA5F0nSrbV8b+XN//nOuRxotjZ2kZyPj9\nwGHCN80AAADABD40AwAAABO2Ip4xDMP41/2Vv0SvNPSobF+ptlGppFFZNk4VFypzXlf5oBrdWDWn\ndMzp+F2KcPhcPUrhkYwXXnhhHL/44ovj+KWXXhrHHtV4/fXXx3FqfOHz9IiFxzBOnz49ju++++6V\nj3tUI8U2fHz8+PFx7Ev9/lzfJi31p0hCkuI+6fFKFYrlbVL1jUpUJR2nn6MUq/D9V2ISKdpRmUPv\nNVj1u9h7PwIOI2IYOAr4phkAAACYwIdmAAAAYMJWxDOkt5eCe5uS9FaZSPGEpNLoI0UpfJyacqTm\nGGn+y3OuVDVIVS/WLc33SNUYvOqFxzM8huFRDX/cIxneWCNd71R9IjVb8coeKW7hfBuPc5w8eXIc\nexQk7bPSlKTSsKfyvknPTdd6XbxnvyMI6fesUgEjbVOp5rGqGoaUf6f9PbTYhngGjhJiGDjK+KYZ\nAAAAmMCHZgAAAGDCVsQzhmFYudS5H8tAlaYcrtL0JP21f2q+4RUgUnMJXxJed07SnCoVPSrL92mc\nlqw99uCxCo9beOMSPxd+/H4sHoFI1Q58Wd7jEKkahu8zVclI2/s4RTV8Pz63SmWSit7oReXx5XhG\neg+miE+l6kzavjKuNDSpvO9d+v1LcapV52FddRvgoCKGAfxZfNMMAAAATOBDMwAAADBhK+IZUq0x\nx6b1LnGnv/CvNHtIy8PpuNNz9KU+AAAgAElEQVSy8brXSFUBUiOSVC0gVWDwOXmsIkUyvLlJiqp4\nlCLFXFJjEY9PeATCt6k0x0jP9bmlOEeq2uF6q1WkeELaJr0Xe5ukLMcMKtGhZE4kI6lUEklRivT4\nJqqT3Ip7F7AfiGQA6/FNMwAAADCBD80AAADAhK2JZ6yyH5U0KkvWack2LSen6gipyoA/7jGHtDzs\n2ywvjacKEq6yZF9pppJiGN7ExCMZPlePMdx1113j+J577lm5jTcKSeMUz0hxhUpMolKhIcVdKnGG\ndC0qFSMqkYxK85Q052UphrGpah29MYk0n3T9krTPVDFjKo5C9QwcZEQygDq+aQYAAAAm8KEZAAAA\nmLA18YzFsmqKNPTsY91ze/9iv/JaaRk/VaHwuEWKbaSGIdUGFGnJviLNw6MXHsnwcTo2j1V4JMMf\nP3PmzMqxxzlSI5JKJKOyFF9pPFO5rv6eSJVDKs1yKrGQSgMQl+IPy1GNdC4qlV38tT12k+adfhfT\n9UvnK137VAWmMk5Rk8UxEs/AQUMkA9gbvmkGAAAAJvChGQAAAJiwFfGM1tq4XOTLupWl395qBCnC\nUIl2LM95apyWytN80vJwtXpGag6SlpeTFFdIFTP8cb9mHqXwRiF33333yvHZs2fH8enTp1eOU4OS\nJMUqPPLix+gRFN/GH69EOFylakelQUllnPZfidz48S7/nN6DqXKFH0/l/VeJjPT+flealaSYTqXx\nzGI+vb9fwK1AJAOYj2+aAQAAgAl8aAYAAAAmbEU8Q1q91FlZjt2PiEVlP3OWnFNzhbRsnMbL0pKy\nqzQ6SRUhfCnfxz4nj0x4JMMrZpw/f37l4x7VqDQuSSrNMSqNQiqVLtLyflKpklFpqpKuXXo/edSi\nEjtZ/jlVaXGVaJVLlTEqMZTK73d6H6Rtkql7APEMbCsiGcBm8U0zAAAAMIEPzQAAAMCErYlnLJaR\n5lSi6F2+XfX61f2kZf9KFQBf9k7jaiSjUg0kLetXqnikSIbP1ffvUYoUyTh37tw49iYm3ujEYx6V\nGEmKRvjj6Tqlc5iqc/jxVmILLr2fKtUwKk1b/Lp4DMMrnKSqGMvvs/ReThGTJM21UqGi0gBlUxV3\nUhRmaj4sgWOb8H4E9s+sb5pba2dba59qrf1Ba+2p1toPttbOt9Z+q7X2td3/Pje9JwDAfuOeDQB7\nNzee8YuS/u0wDH9e0l+U9JSkj0r63DAM75b0ud2fAQC3HvdsANijPcczWmv3SPrPJf1NSRqG4Zqk\na621D0j64d3NPinpC5I+UtjfDf8t1SoHVJa150hL4r4MvFx1YMGXoj3a4EvlqQpFpRKD1H+O/Hj8\nNfy1r1y5Mo5ff/31cewNTfy5HmPwuEWqjOHNSrzChs8tVRtxaZtKFZIU2/Dn+vWuLN1XpAhHerxS\nXSU1oEnvM99+XZWLSsSn8p5zlSjTplSqn1RiGKliy0GrmrHpeza2B5EM4OaY8ynzXZIuSfqXrbXf\naa39i9baaUn3D8Pw3O4235R0/9xJAgBm454NADPM+dB8h6Tvl/TxYRi+T9IVLS3rDTtfxaz8Oqa1\n9uHW2hOttSf8m00AwL7Y2D370qVL+z5ZANg2c6pnPCPpmWEYvrj786e0cwP+Vmvt4jAMz7XWLkp6\nftWTh2F4XNLjkvTwww8Pi+WltIzqEYDe5dWl1105TttUKkxUYhu+PO4xB19C9+0r0QBJOnbs2OQ4\nVRfwY/AYxiuvvDKOX3311ZXH4PPwRiR33XXXOE6RjDS3dG3SOFUwSdUkUjyjUsWh8p6rxINS/CM1\nEqk0JalEMtL5WVctpDfekI6/UmmmUtmkV5pzZf89UacDFNPY2D37scceOzAHfVgRyQBuvj1/0zwM\nwzcl/Ulr7c/tPvQ+SV+R9BlJH9x97IOSPj1rhgCA2bhnA8A8c+s0/7eSfqW1dkzSH0r6ae18EP/1\n1tqHJP2xpJ+Y+RoAgM3gng0AezTrQ/MwDL8r6bEV//S+ve4zLYX60rE30KjEMyrL+71xgBTDqDQG\nSY0m/Llp2dyPXboxGuFjf47vy1/Ps+Qvv/zyOH7ppZdWztV5DOPkyZPjODUr8UhGpfpEbyQjVcmo\nVM+oNIipNENJ83cpJpFiOv54ivWk56b3k0vvE6m/WVA6R5XqJHN+R5N0/XyflUYqU1GNaqWbbbAf\n92zcPEQygFuLNtoAAADABD40AwAAABPmZpo3Zqq5SYoorFteXkhLvClu0dtQIkUvfDndYxGpUkKK\nZHi0wSMYyz97oxBfRvZ5v/baa+P4hRdeGMcvvvjiym2cxzD8dT2GkSIZlevk5kQy0vlNkYz0upXq\nDpV4RqrmUXkPpXGqquH8vKXqM+lxqf/YkkqUIkUjUpRiTnWV3gYzU5VD9qMxC7BAJAPYHnzTDAAA\nAEzgQzMAAAAwYWviGYsl0EpDhRTVqMQz0nJypdqBL4P7Urk3BvFximf4fPwYPV7hx+iPr4tn+HN8\n6d/n5JEM7+rlTUz8ud6UxKMX3rjknnvuWblNamJSWfbvrVTi5zdFMirL6P4+S9GASoOOFCPpbVaS\n4hzp/Ph7oDJOv2/L0rlwlccr4xR/qTRAqURqKrEsN9XMhXgGNo1IBrCd+KYZAAAAmMCHZgAAAGDC\nVsQzWmvjUmdqLjH1F+zL27jKMq0/npbTfdncK0z42BuG+Pa+T59nqozhsZN18Qxfavdj8GiIV8a4\nfPnyOPYmJj4/f42zZ8+O43e84x3j+L777lu5jVfYSNGZSrWDFEtI8YZUMSMtnVeamKQ5pyX9ypxT\nxYz03EpTjhTrSZUxUlRmOaJUiUD0Ri96YzqVa1DZT2psk+4BbirCQTwDm0AkA9h+fNMMAAAATOBD\nMwAAADBhK+IZ0urqGb3LvSmekZZPU4UDXzb3mIPHMLzaxCuvvLJye9+P80hGagCStlluQOHH1hvJ\n8PmdOXNmHN97773j+MEHHxzHFy9eHMfnzp0bx15ho3IN0rJ5ii6kiEwlnpGW+lPEx8eVaECK8lSi\nF7592r+fT4+7VKrJpGNJln9PeiMZlQjVnMop6Xe90jwlWVcxpLoNy+rYK947wMHCN80AAADABD40\nAwAAABO2Ip7RWhuXcHv/uj4tzfZWO0jNSlIMwx/32Ibvx183LVH7cnqKZPg5Wf7rfY9kePTCG5d4\nQxM/Zm9E4pUxHn744XH8wAMPjGOPbXiVDI8HpHOdojApbuHXwKMOKbbh+6ws6ft5T++hFM9Ix5Lm\nkOIiadm/Eh1J8YwUQUl8bsvzSZGMylyrTVMWUnynUtnEpeNPv3OuN0ayGLPEjh68X4CDi2+aAQAA\ngAl8aAYAAAAmbEU8Q3p7yaqyJJ6Wx1OVjFSVobcyRopneMTAXyvFAVJDk9Skwo/LX0u6sUrG888/\nP46//e1vj2OPOlQiGT6+cOHCOL7rrrvGcVo2T7GESsMYvx4+9m18XKmSkWICqfGHj3urMqTXTRUt\neudciR5Uln79dddFOHoblFTm7dL1qzQgSvNMc6iMe6uNLOZTicEAAA4+vmkGAAAAJvChGQAAAJiw\nNfGMxVJnZTnW+bJ/WvpOVRk8kuHRi5dffnnl4x7J8PiAz8GlGIZHJLwKRfqrfn8tn5t0YyTDK2Z4\nDMX36xUwPIbhTUx8G5+rL2X3NvhI0Qu/Hj6uRDJ8DilukeIv6xrGLKR4UIXvM8WGXKWRT+9f3Veq\nzKQ5SLnqRSV6keaRGpekcdpPmk9vHKfy+FT1D+IZWIdqGcDhwTfNAAAAwAQ+NAMAAAATtiKeMQzD\nuMSflmC9KoVHANJfvPt+PCbgEYBUGSONPVbgc/DXTZGM06dPj+MzZ86MY48/+LH4nD2S4XEMSbp8\n+fI49riJxz68AoY3K/FIxvnz51fOO8VcfOzRhdSIpBLJSOfXr71LMQw/p37efRuPrFRiJz6HVK0h\nRTJ6q3DcTOviH+nfKpUuUowmPV6JcFTmVmkA4+NU2STFNlYttVeat+BoIZIBHE7c7QEAAIAJfGgG\nAAAAJmxFPOP69evj0nxapnXpL+SX97mQqmdUGpf4OMUEvCqDjz0a4I1BPD7gy8O+dO2v641KXnjh\nhRte2yMNvi+PZHiVDI9n+DYeXUgRhTRO0ZnUuCRVyUiRD5fiL3ffffc4TvEXvzZp+TTFbvycVBqU\nVCpAVKpbpP27SrORvVThSPOrNBpK749KbKW30keKyKSIRbpnpHtP5ZwCvB+Aw49vmgEAAIAJfGgG\nAAAAJmxFPOM73/nOWCEiLZGmJdu0JObP9eXh1NzE4xBXrlwZx14BwvfpMQEfp0iGRwY8JuDH5a/7\n4osvjuOXXnpp5fylGyMZ586dG8deGeOhhx4ax964xOdRiWT4efRleX88Vc/wsUcgfP9+Lnw53c+v\nxy38/KZ4RqqOkI4xVXpI26T3aHq/Vp6bVJp4pOoRvU1IpHkxjEqsp2LOMacoRYrOpGufXnexz22u\njoL9RSQDOFr4phkAAACYwIdmAAAAYMLWxDMWcYTU/CAtZaflMd/Gl4S9WoPHIby6g2/jr+tL/R5t\n8DhAigmkKIS/lscwPJ6RKmRINzYluXjx4jhOkQxveuLSEnqKYaT4S2pK4uO0nJ2aTvic07n2WIyf\na+fHkqp8+DhFSnobdCSVbSrVGvZSGWPVHJYrlqTr6u+PdF7SuLdZSapaUmloUqmSkWI3lTjYYpwq\nveBwIpIBHF180wwAAABM4EMzAAAAMGEr4hlvvfWWLl++LKm2rJuWTn05NjVjSEvOvhTvz/V9pioZ\nHhPwsccKfD8et/BIRqqS4c/1/Us3RjK8iYlHMrzihC8tVqodpGvg564yTkvYHsPweIY3LvFIRhov\nx1ZWzaE3muPvibSMn6S4QW+DkhQ3qEQP0jlPlVL8XK37t1RFxce9DUrS45XqGb3npVIppidSUnk/\n4GAjkgFA4ptmAAAAYBIfmgEAAIAJWxPP+Pa3vy0pV2ioVM+oVBpIS8j+eIoJeDONs2fPjuNUxcH3\n40v9r7zyyjhe17hk1Wvdf//9N/ybNzG57777Vs7Dz0VqRpGqW6Tlaz+eVH0iLXc7P0cef/Hz7jEX\nr4zh1ztFCVIzG3/c4xmpYkZlCd6jFH5c6fE0TttXYh7pd6Zy3ZfjGWm7SnQhNR/pfdyPM0V5fJwi\nWpX7RyUuQiOTo4NIBoBlfNMMAAAATOBDMwAAADBhK+IZ3/nOd8bIQuUv85O0xF1piuDP9TiARzLO\nnTu3cnzPPfeMY48Y+LG8+uqr4/jll18ex17FweeWIhkex5BujGR4NYlUJaOy5J6iDj5OFScqFTNS\nE5N0PXzJPTWGSZEMP7/+eKqSkSqKJD5nl96L/v7wqImfh3ROUkyg0oCmt4LM8nZ+LirVa3ze6djS\ncVZiLnMqiaTnptf1/aw6dpbxDzauH4AqvmkGAAAAJvChGQAAAJjAh2YAAABgwlZkmq9fvz7mKVOO\nMuVjU97V85KeWUslzrxrnueYvZzc+fPnVz7u2VSfv+dpPdPseVqfm7+ud/R74IEHxvFyyTnPMXsm\ns1JWrLKNz9VzzKlMWyrpl0qnufR4pXOhz6dSTi7tM5Vsq+Rg/f2UyuelcXpuKqmYysmlDHTaPu1/\neV+VHHP63UrZ7fR4b8m9VFouZbr98Up2eWqccu3YXuSYAewF3zQDAAAAE/jQDAAAAEzYinhGa21c\nJk1Lquueu+BLxb7cm7rLeRzCO+h5ubfU+c/378vdHmdIkQyfp+/fy8ddvHhxHHtUw8vbSTcefyob\nl6IXKYbhY486+HhdJ7mFSpe3OZGMNOdUii6VTUsxjEonv/Q+8+hBetwjDJUOdymeUSnFln5P/LWW\nr2Ol5GM6F5UYRjr+VH4uSdGTSkfRXqveN8QzDgYiGQDm4ptmAAAAYAIfmgEAAIAJs+IZrbW/J+lv\nSRok/b6kn5Z0UdKvSbog6UlJf2MYhtXr94tJ3HHH2GEvdZpLS+u+NJpiGF5hwscedfCxxzA8wuFL\nyx4fSBEGX+72JXGfg3cW9CoZ73jHO1Zu73NYnkeKIlQqY6RjSLGHtAyeltYry/J+XVM8wytgpHPt\n80wxjBQRSdEFjxikiEVvDKHS4c/HKeKS5py2SXNejmD4+XK9HfVShCNVtUnzTrGK1O2vEsmoRFhS\nfOcgxjM2dc8+KIhkANikPX/T3Fp7UNLfkfTYMAx/QdLtkn5S0s9L+oVhGL5H0ouSPrSJiQIA9o57\nNgDMMzeecYekk621OySdkvScpB+R9Kndf/+kpP9q5msAADaDezYA7NGe4xnDMDzbWvvHkr4u6Q1J\n/147S3svDcOwWE9/RtKDU/u688479eCDO5t5Q5DUmML50qhHMrwahkcsUiTDx97oJFUXSI0+PBqQ\n5ubVMLxZiVfP8Pn4fpaX0NNSfmpc4udxU9UnKlVLUiOP1EAjzTmd68o8XYo0pGYlqRpGakqSKlr4\nfHyeSYoMpP2n2EmqbOHHsk6lKkelKkplubzSrKSyjUtzTttUKr9M7W/bbPKevc0OyvUAcPDMiWec\nk/QBSe+S9ICk05Le3/H8D7fWnmitPZE+EAMANmOT9+xLly7t0ywBYHvNiWf8ZUl/NAzDpWEY3pT0\nG5J+SNLZ3aU/SXpI0rOrnjwMw+PDMDw2DMNj/i0eAGBfbOye7atiAHBUzKme8XVJ722tndLOUt/7\nJD0h6fOSflw7f439QUmfntrR8ePH9d3f/d2SpNdee2183KMa/m10+mt2j1WkihneTMQf9+c6X/ZP\nlRtS4xJf+j5//vw49kiGV8nwGIkv9afmHlKOMaR5p8d9P2m5Oy1T++OVGEOqmNHbeCVtnyIZKerQ\nWwEiRSNcpRqGb5PGLkUMPG5RiZ2k5in++LrnVJa/Kw1H/FxUHq9ENSpxkXQee6urLMYHKA6wsXv2\ntjlA1wDAAbbnb5qHYfiidv545P/RTumi2yQ9Lukjkv5+a+1p7ZQw+qUNzBMAMAP3bACYZ1ad5mEY\nPibpY0sP/6GkH5izXwDA5nHPBoC9m/WheVNOnDih7/3e75WU4xm+LJ+aGXgcwKtnpHFacvY5eAzj\nlVdeGcevvvrqOPZlXa+S4Y1LPJJx4cKFcexVMnw+vs8UVVj+uRLJSDEMlxphpG1SI4/UyMKX6/1a\nVip7pKog6VhSjCRFMtLYpehFRW81iEr0IB1Lui6pOcty1CQ1JUnVQCrHlqJG6T1RGbtKZY8Uzam8\nJ1Y1VkpxGmweMQwAtxJttAEAAIAJfGgGAAAAJmx1PMPHvkTvS7mpioDHJFIVAd+nxzBefPHFcXz5\n8uVx/PLLL49jjxJ4LMTjFt7ExKtneJWM1LgkVerw5h7Lx5CqYaTqBS5FEVyqtJDOr0tVMlIMI8VL\nKsfSW0HC3zeVyhipAkYlqpGqZPRWiUiRgBTP8PdoJf6xbt6+XTqGFKNJ496oRjqGpFJVI0Uypt7r\nvREd9CGSAWBb8E0zAAAAMIEPzQAAAMCErYhnHDt2TI888oikG6MIKZ7hy7qVZeoUB/BqGB7D+Na3\nvjWOParhy8ZedcArcngMw6tn+DY+N9+nz9NjGCnCsPycOTEGV2l+Uaky4XPwuIWP/Tj92qdl/Mr1\n9uXcFMNIVT4qTTx6qzik81+JZ1Qafayq6CDl90AaLzfOSbGVpNLQJUUvUlSjt9FJmk+lCkmKZKTI\nzmKcXh97RyQDwDbim2YAAABgAh+aAQAAgAlbEc+44447xoYfp06dGh/3SIPHEnxJP1Wc8KiCN0nx\nGMZzzz03jp9//vlx7FUy/HV9bmfOnBnHKZLh2/hSd6oykCIMqTmJlJfgU4xhTpOHtFyfGpekmEEl\nOpLmnJZtfTndoxdeNSI93ls9I0nxhErFjEoTj+X4xKp9+vwrzVP8/eTncHlflWtQkc5Rqp6RzlE6\np5UKI86vcZrP1PFSPWMziGQA2HZ80wwAAABM4EMzAAAAMGEr4hnS20vBx48fHx9Ly7Hpr+s9tvHt\nb397HHsM4xvf+MY4vnTp0jj2SIa/li/pnz17dhzfd99949ibmPg23mDFlx4rzR7SEv3yknNlaTpF\nINJyaKookOIKlaoGPk4VOfzap6YvzveTKmN4DMP3PyeSUTnPaZtKJKFSPcKlZiOJ79+Pt7o8nqIa\nKeKTtqnEUyoVQ3rn7HqjFatel+oZe0ckA8BBwjfNAAAAwAQ+NAMAAAATtiKecf369bGRiS8dpwYf\nHqXwBiXelMRjGM8888w49ioZvk9fdr3nnnvGsUcvHnjggXF8//33j2OvmOGRDF+K9uOa89f+yyoN\nMtL2Fan5RaUKRKr24HEIj1J4VKNyXlI8o7eJSYoSpNetnOcUMUgxjEpzj0pFFD+utB+3LsZTaYqT\nxnMao/RGXlJcpDJ2lWojq84J8Yw+RDIAHFR80wwAAABM4EMzAAAAMGEr4hnXrl3Ts88+K+nGZWqP\nT7z++uvj+IUXXhjHXiXDIxmL/S1v441OvHmKRzIuXrw4jh966KFx7JEMb2jiFRp8KTotuVciEmlJ\neHmZvVKBIS07pyXrSrWHSpWMFAnwc1RZuk/xibSfFMPwcWrc4SoVMFJ8ore5SSWOkq6d663gsS5O\nU4mDpBiG76tyriuVWeaoRHAqlTr2EqECkQwAhwPfNAMAAAAT+NAMAAAATNiKeMbVq1f1ta99TdKN\nkQaPUrz66qvj2OMWly9fXjn2bXyp1RtceNWLBx98cBw/8sgj49grZniE49SpU+PYlx5T1YS0DO6P\npzjH1atXx7FHVpZ/Ts1RKpEMX75OS9CVKEKSlscr47S8n6IBKZLRWzEjVb1wlchEks5/Ot7eRiSV\nY0nvuepc0+ulZkSp2kYlwpGk37NK9ZP0eCWSsZgn1TNWI5IB4LDhm2YAAABgAh+aAQAAgAlbEc94\n44039NRTT43jhUXDE+nGJiY+fvHFF8exxxh82dljGF4Bw2MY3/Vd3zWO3/nOd47jCxcujGNvlOFL\ny/5a165dWzkfj1H44z5OzVy8cshyPMOfnyp09MYekrSNxx7S9pXmEi4t3VeqYVSqZ1SqT6T59Dbc\n6I1epCYvSaUChL830uum2MXyc3ord6ToT6WSRtqmEhVKsY20TeVausXjVNR4G5EMAIcZ3zQDAAAA\nE/jQDAAAAEzYinjG1atX9dWvflXSjZEMjyt49YwUgfAmI3fdddc49goYHsN4+OGHV25z9913j2OP\nZDifg8/Txx6rSNGLFMNIkQw/XikvO3sMIMUDXFpO31TEolKhIj03HcucCIdLS/S9y/tp/qlqR2VZ\nv3Ke0zxTbMjnkCq5LM+v0qCl8txkKgKxbj8pblK5fpWoxtQ8j3o8g0gGgKOCb5oBAACACXxoBgAA\nACZsTTzj61//uqQbG5r4krIvNftytzcrOX/+/DhOkQyvmHHfffeN4zNnzoxjX8b31/WxxyRSrCLF\nNlJUI22zlwYUlcfTNilWkWIGvU03XKUxRCWGkSpmpGoVlcYz6dqnJf10rpJKo5neiEuKZHjMyI8x\njZf3W4k3pJhCOoZUraO3+Uh6rfS+mRMvIZ6x48knnySWAeDI4ZtmAAAAYAIfmgEAAIAJWxHPuH79\n+tiwxGMPvrzqy+9eGePs2bPj+MEHHxzHqTLGvffeO45Pnjw5jn2J1SMTvmSdGpH0xjBSxQzfvy+t\nr1uW9mXnNK5Uckgxhkrlikq1jSQt0VfiCqlKRtpnihWkGEaKxfQ2MUnnMMU50rWoxEtSjCkdS9rP\n8nPSa/RWEumN8lTiH73vVz8vqXrI8rlYZ11TGADA4cHdHgAAAJjAh2YAAABgwlbEM6S3l1i9QYnH\nJ06fPj2OvUrGO97xjnH8zne+cxxfvHhxHKdmJb6c7JGJ1DwlxTPmPJ5e15eH0zKzlCtIVOIBvcvm\nKSZSWTavxDYqc6tEMlKMIVWK8POetqlEMtLcKs1W0jhJFT9cii34OdlLPKPy2lMVJ9a9to8rFWHW\n/X4s+O9Ginyk9/fUHCrXCwBw8PFNMwAAADCBD80AAADAhK2IZ9x2221jRQyPZ3jDEa+SceHChXHs\n8Yxz586NY49k+NJs+mv5ShOTFKuoPF6JZFSqDyw3zZiz9J+WnX1puqeKwLJKVY1UcaJ3P64SJeht\nVpKiDmlcuS6VZjEuxSoqjT78tVK0Zvn958+pvHaaR3o/pevh8+5tYlLhDZEqTX2mXqvSyAYAcPDx\nTTMAAAAwgQ/NAAAAwIStWFe84447xmiFNy7xiIVXzPCoho+9wobzpd9UKSFtkyIWvePUMCVVH6g0\nIVn+ube5hkvL7OuW71dJlSvSNqnBh/M5p8oKlYoQaZwqJcxpXOJ6z2flWFLMqBLxSa+1vI0fW6VC\nStqmEsnw10qRoN7GOZV4Tao+42PfZtU+iWcAwNHAN80AAADABD40AwAAABO2Yl3x9ttvH2MWHsnw\n8T333DOOPYbhzUp8ediXfitL3Kl6hscqUlWNSsWMVK3B51xpQrK8LN27ZJ2W0FMjj95IRlquT2Pf\n3udQqeyR5paqNVQqQFSqJqRjTPPxOfhSfoohpHnOmX/SW3li3fMrlTSSFAXpbZCTnluJZHjlnhTV\nWPU+IJ4BAEcD3zQDAAAAE/jQDAAAAEzYinXF2267bYxcePTi5MmT4zgtgXqli7TcnZbrU3MTj1X4\n/nuravg+U/yhUq2h2sghLY9Xzktlub/SfMTNaYKR4jV+HudUAqlcg3WVJVZtX+HHVYl5zImR3AyV\na1xpHlNp9LIuprRKpdmMRy+86Yk/PtUQ6GafcwDArcHdHgAAAJjAh2YAAABgwtbEM06dOiXpxmoY\nqalFijpUlklTJQ2PVfQ2PUkxjEoDjdQow61bik7/ll47xQAqDUfWNVlZtX/fT2+lCFeJZKQ5VB7v\nrdCQ9G7vUswh7d/PQ6ruUImg9Fa5WH7Opqp7pGYiPk4xifS+rEQy0vs77X/ONQYAHGyTn0Baa7/c\nWnu+tfYle+x8a+23Wq+Y/J0AAAcMSURBVGtf2/3vc7uPt9baP2utPd1a+73W2vfv5+QBAH8W920A\n2LxKPOMTkt6/9NhHJX1uGIZ3S/rc7s+S9KOS3r37nw9L+vhmpgkA6PAJcd8GgI2ajGcMw/B/tNYe\nXXr4A5J+eHf8SUlfkPSR3cf/l2FnPfb/aq2dba1dHIbhuXWvcdttt42xjKm/VJdy9KCyjJoqMaTH\nK9GLNB+XqgBU4g97qZ6RYiiVpX+fU29DiVQ1oTK3SlSjN4JzM1Wu037EGSrRn73ETnqrYfTGkVJM\nolIZJMWaUlOSVA3D91lpTuO2OapxM+7bAHDU7PUPAe+3G+o3Jd2/O35Q0p/Yds/sPvZntNY+3Fp7\norX2xJUrV/Y4DQBA0az7tt+z93eaALCdZlfP2P12ovuviYZheHwYhseGYXjMazMDAPbXXu7bfs/e\np2kBwFbba/WMby2W71prFyU9v/v4s5Ietu0e2n1srW984xuXP/axj/2xpHslXd7jnA4ijvdwO2rH\nKx29Y75X0kH5f/2bvG9flsQ9+/A7ascrHb1jPqrH+117efJePzR/RtIHJf2j3f/+tD3+t1trvybp\nL0l6uZKLG4bhPklqrT1xlL7F4HgPt6N2vNLRO+bd4330Vs+jaGP3be7ZR8NRO17p6B0zx9tn8kNz\na+1XtfPHI/e21p6R9DHt3HR/vbX2Ie182/ATu5v/pqQfk/S0pNcl/fReJwYA2Bvu2wCweZXqGT8V\n/ul9K7YdJP3M3EkBAPaO+zYAbN62tdF+/FZP4CbjeA+3o3a80tE75qN2vMuO2vFzvIffUTtmjrdD\n20sbXQAAAOAo2bZvmgEAAICtsxUfmltr72+tfbW19nRr7aPTzzhYWmsPt9Y+31r7Smvty621n919\n/Hxr7bdaa1/b/e9zt3qum9Rau7219juttc/u/vyu1toXd6/zv2qtHbvVc9yk3U5qn2qt/UFr7anW\n2g8e5mvcWvt7u+/nL7XWfrW1duKwXePW2i+31p5vrX3JHlt5TduOf7Z77L/XWvv+Wzfz/XXY79kS\n9+2jcN/mns09u/eefcs/NLfWbpf0zyX9qKT3SPqp1tp7bu2sNu4tSf9gGIb3SHqvpJ/ZPcaPSvrc\nMAzvlvS53Z8Pk5+V9JT9/POSfmEYhu+R9KKkD92SWe2fX5T0b4dh+POS/qJ2jv1QXuPW2oOS/o6k\nx4Zh+AuSbpf0kzp81/gTkt6/9Fi6pj8q6d27//mwpI/fpDneVEfkni1x3144bL/Tjnv24bu+n9B+\n3rOHYbil/5H0g5L+nf38c5J+7lbPa5+P+dOS/oqkr0q6uPvYRUlfvdVz2+AxPrT75vwRSZ+V1LRT\nUPyOVdf9oP9H0j2S/ki7fydgjx/Ka6y3Wy+f104Vns9K+i8O4zWW9KikL01dU0n/s6SfWrXdYfrP\nUbxn7x4n9+1D8ju9eyzcs7lnd9+zb/k3zXr7Qi48s/vYodRae1TS90n6oqT7h7ebCHxT0v23aFr7\n4Z9K+oeSru/+fEHSS8MwvLX782G7zu+SdEnSv9xd2vwXrbXTOqTXeBiGZyX9Y0lfl/ScpJclPanD\nfY0X0jU9Kveyo3KcI+7bh/J3mns29+zue9k2fGg+MlprZyT9a0l/dxiGV/zfhp3/m3MoSpm01v6q\npOeHYXjyVs/lJrpD0vdL+vgwDN8n6YqWlvUO2TU+J+kD2vkfnge000p6eUns0DtM1xSrcd8+tLhn\nc8/utg0fmp+V9LD9/NDuY4dKa+1O7dx4f2UYht/YffhbrbWLu/9+UdLzt2p+G/ZDkv5aa+3/k/Rr\n2lnq+0VJZ1tri4Y6h+06PyPpmWEYvrj786e0c0M+rNf4L0v6o2EYLg3D8Kak39DOdT/M13ghXdMj\ncS/T0TlO7tuH+77NPZt7dve9bBs+NP+2pHfv/gXnMe0E0z9zi+e0Ua21JumXJD01DMM/sX/6jKQP\n7o4/qJ3M3IE3DMPPDcPw0DAMj2rnev6HYRj+uqTPS/rx3c0OzfFK0jAM35T0J621P7f70PskfUWH\n9BprZ4nvva21U7vv78XxHtprbNI1/Yyk/2b3L7LfK+llWxI8TA79PVvivq1Dft/mns09W3u5Z9/q\nwPZu+PrHJP1HSf+vpP/+Vs9nH47vP9POcsDvSfrd3f/8mHbyYp+T9DVJ/7uk87d6rvtw7D8s6bO7\n4/9E0v8t6WlJ/5uk47d6fhs+1v9U0hO71/nfSDp3mK+xpP9R0h9I+pKk/1XS8cN2jSX9qnbyf29q\n55upD6Vrqp0/mvrnu/ex39fOX6nf8mPYp/NyqO/Zu8fIfXs43Pdt7tncs3vv2XQEBAAAACZsQzwD\nAAAA2Gp8aAYAAAAm8KEZAAAAmMCHZgAAAGACH5oBAACACXxoBgAAACbwoRkAAACYwIdmAAAAYML/\nDxcfDYmAtq4QAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SopL3BCimIwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DIPOJCmIzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5764a9af-9fbe-443d-dd68-1ebfee51a97b"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "# チャネル特徴量を追加している\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "#ResNETイメージのデフォルトサイズである(224,224)にリサイズ\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xVF6y7AmI1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orzM3W3Omlw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "# 畳み込み、BN、PRELU活性化関数を用いている基本的なデコーダーブロック\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "# ボトルネック構造を用いたデコーダーブロックであり、表現を圧出するためにはミドル畳み込み層は最初と最後のサイズの半分になる。\n",
        "# このタイプの構造は最も有用な情報を保持している。\n",
        "\n",
        "\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhBPhEbQnYPE",
        "colab_type": "text"
      },
      "source": [
        "## RESNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9auKdM5mlzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# デコーダーブロックタイプの容易な変更を可能にできるようにモデルはパラメータ設定されており、\n",
        "# デコーダーブロックシンプルのように、関数を与えられるような議論のものである。\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    # ベースとなるエンコーダーモデル\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights) #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # エンコーダーパートにおける特徴抽出の層\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    # センターブロック\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    # デコーダーパート\n",
        "    # どのデコーダーブロックも、エンコーダーとデコーダー部分からの結合されたアウトプットを前に進めている。\n",
        "    # そして、デコーダーのアウトプットはエンコーダのアウトプット部分と同じディメンションにアップサンプルされる。\n",
        "    \n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9dUYE7x6XC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f02e54f8-94bd-43f7-d922-487d6d197cbd"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet') #事前学習されたメージネットの重みを読み込んでいる。\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 02:45:44.281504 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0731 02:45:44.284043 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0731 02:45:44.343395 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0731 02:45:44.345165 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 02:45:44.358032 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0731 02:45:47.595210 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0731 02:45:47.679141 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0731 02:45:56.148567 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0731 02:45:56.572777 139963874293632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0731 02:45:56.600522 139963874293632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0731 02:45:56.620597 139963874293632 deprecation.py:323] From <ipython-input-19-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skz0FCgFml12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e71f8f6-12a1-4d74-b69d-5fb1851099b2"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet', #事前学習されたメージネットの重みを読み込んでいる。\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "# 最適な学習ポイントで結果を保存する\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0731 02:46:04.744761 139963874293632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 140s 44ms/step - loss: 0.7423 - my_iou_metric: 0.3245 - val_loss: 1.7581 - val_my_iou_metric: 0.2740\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.27400, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 112s 35ms/step - loss: 0.5565 - my_iou_metric: 0.4806 - val_loss: 0.6692 - val_my_iou_metric: 0.5047\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.27400 to 0.50473, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJPnzFD7ml4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8_O0w75ml7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bESJ0NFur1_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10367205-c287-40d7-e9a1-9c4919c6b846"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:36<00:00,  1.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAZvStsMml9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "bebc3c0e-5c55-4b16-c936-6f7724876d1d"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.5688 at threshold: 0.760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.533522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.034341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.445647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.510510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.547264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.562687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.568781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.533522\n",
              "std     0.204939   0.034341\n",
              "min     0.200000   0.445647\n",
              "25%     0.370000   0.510510\n",
              "50%     0.540000   0.547264\n",
              "75%     0.710000   0.562687\n",
              "max     0.880000   0.568781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x50z5rxm78z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "beec9a16-c9f1-48e6-e731-4a522b01532c"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b1e5eb5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI7tmHBjnBSx",
        "colab_type": "text"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtTuN4-Im_rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_vgg(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    #Base_model エンコーダー\n",
        "    base_model = VGG16(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    #エンコーダー部分(VGG16)\n",
        "    encoder1 = base_model.get_layer('block1_conv2').output\n",
        "    encoder2 = base_model.get_layer('block2_conv2').output\n",
        "    encoder3 = base_model.get_layer('block3_conv3').output\n",
        "    encoder4 = base_model.get_layer('block4_conv3').output\n",
        "    encoder5 = base_model.get_layer('block5_conv3').output\n",
        "    encoder6 = base_model.get_layer('block5_pool').output\n",
        "\n",
        "    #中間部分\n",
        "    center = decoder_block(\n",
        "        encoder6, 'center', num_filters=512)\n",
        "    concat6 = concatenate([center, encoder6], axis=-1)\n",
        "\n",
        "    #デコーダー部分\n",
        "    #エンコーダー部分を結合\n",
        "    decoder5 = decoder_block(\n",
        "        concat6, 'decoder5', num_filters=512)\n",
        "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
        "\n",
        "    \n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=512)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=256)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=128)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    #出力\n",
        "    #output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        concat1, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nU375k3m8Br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "515d6dd7-c5ba-42a3-a56f-ae46730b19d4"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "#モデル\n",
        "model_depth = unet_vgg(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "#チェックポイント\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  \n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv1 (Conv2D)         (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation1 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv2 (Conv2D)         (None, 7, 7, 256)    1179904     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder5_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation2 (PReLU)    (None, 7, 7, 256)    12544       decoder5_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 256)    0           decoder5_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_conv3 (Conv2D)         (None, 7, 7, 512)    1180160     dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder5_activation3 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 512)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 14, 14, 256)  1179904     dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 14, 14, 512)  1180160     dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 512)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 28, 28, 128)  295040      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 128)  0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 28, 28, 256)  295168      dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 256)  0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 56, 56, 64)   73792       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 56, 56, 128)  73856       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 56, 56, 128)  0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 112, 112, 64) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 224, 224, 32) 0           dropout_19[0][0]                 \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 45,433,809\n",
            "Trainable params: 45,423,729\n",
            "Non-trainable params: 10,080\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 177s 55ms/step - loss: 0.9708 - my_iou_metric: 0.1565 - val_loss: 1.5759 - val_my_iou_metric: 0.1498\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.14975, saving model to unet_vgg.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 153s 48ms/step - loss: 0.7527 - my_iou_metric: 0.2456 - val_loss: 0.7428 - val_my_iou_metric: 0.3517\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.14975 to 0.35174, saving model to unet_vgg.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CVQUFH6m8GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qf2P5EUm8JC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc591b7b-8369-4aed-9b5d-dc7e4117ea45"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:36<00:00,  1.04s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZI5efVm8EP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "ff8d94e4-de41-4bd9-e385-16863734ddf5"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.4575 at threshold: 0.860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.382701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.063709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.260821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.404353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.439552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.457463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.382701\n",
              "std     0.204939   0.063709\n",
              "min     0.200000   0.260821\n",
              "25%     0.370000   0.330100\n",
              "50%     0.540000   0.404353\n",
              "75%     0.710000   0.439552\n",
              "max     0.880000   0.457463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFsSl0KHm7_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "9413a0ff-4e3e-40e1-8df7-7ab417b4f020"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f46e22f3ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlmlJkiSpQpZpSZIkqUL/A4NB987orGk7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWdPt8yr8kwx",
        "colab_type": "text"
      },
      "source": [
        "### 比較"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5y3ev5q8nFm",
        "colab_type": "text"
      },
      "source": [
        "* 基本的にどちらのモデルも基本的にthresholdが高いほどIoUスコアは高まっている。\n",
        "* 最終的により高いスコアを出していたのはResNETで最大IoUは0.569まで到達し、一方でVGGのモデルにおける最大IoUは0.457であった。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fYsICt4oBWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}