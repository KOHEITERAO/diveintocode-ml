{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】スクラッチを振り返る\n",
    "ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n",
    "\n",
    "（例）  \n",
    "* 重みを初期化する必要があった  \n",
    "* エポックのループが必要だった \n",
    "\n",
    "<白須さん>\n",
    "* 変数、パラメータの定義\n",
    "-- tf.placehoder\n",
    "* 目的関数の定義\n",
    "* ニューラルネットワークの定義\n",
    "* メソッドの確認\n",
    "\n",
    "\n",
    "\n",
    "*　隠れ層が複数のモデルを構築するためにクラスで層の情報をまとめる必要があった。\n",
    "\n",
    "それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】スクラッチとTensorFlowの対応を考える\n",
    "以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」が  \n",
    "TensorFlowではどう実装されているかを確認してください。\n",
    "\n",
    "それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 5.8545, val_loss : 14.2928, acc : 0.750, val_acc : 0.375\n",
      "Epoch 1, loss : 5.2289, val_loss : 13.2057, acc : 0.750, val_acc : 0.375\n",
      "Epoch 2, loss : 10.4459, val_loss : 7.0227, acc : 0.500, val_acc : 0.688\n",
      "Epoch 3, loss : 0.0000, val_loss : 1.9767, acc : 1.000, val_acc : 0.750\n",
      "Epoch 4, loss : 0.0076, val_loss : 2.4601, acc : 1.000, val_acc : 0.812\n",
      "Epoch 5, loss : 0.0000, val_loss : 0.6478, acc : 1.000, val_acc : 0.938\n",
      "Epoch 6, loss : 0.0000, val_loss : 2.7985, acc : 1.000, val_acc : 0.812\n",
      "Epoch 7, loss : 0.0000, val_loss : 1.4324, acc : 1.000, val_acc : 0.812\n",
      "Epoch 8, loss : 0.0012, val_loss : 4.5965, acc : 1.000, val_acc : 0.750\n",
      "Epoch 9, loss : 0.0026, val_loss : 5.7552, acc : 1.000, val_acc : 0.625\n",
      "test_acc : 0.800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成\n",
    "Iris Species  \n",
    "サンプルコードと同じくこの中のtrain.csvを使用してください。目的変数はSpeciesに含まれる3種類全てを使います。  \n",
    "2クラスの分類と3クラス以上の分類の違いを考慮してください。  \n",
    "それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.iloc[:,5].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "\n",
    "#y = y.astype(np.int)[:, np.newaxis]　必要ないので失敗。\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################\n",
    "#ワンホットエンコーディングを実施\n",
    "########################\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "y_train = y_train_one_hot\n",
    "y_test = y_test_one_hot \n",
    "\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 50\n",
    "\n",
    "n_hidden1 = 50 #50→\n",
    "n_hidden2 = 100 #100→\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3 #何列のデータかを表すという仮説\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数 ソフトマックスに変形\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
    "\n",
    "# 目的関数　２値分類のまま\n",
    "#loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果 #ソフトマックス関数用に書き換え\n",
    "correct_pred = tf.equal(tf.argmax(Y), tf.argmax(tf.nn.softmax(logits)))\n",
    "\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "                        \n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 48.0882, val_loss : 125.7790, acc : 0.333, val_acc : 0.333\n",
      "Epoch 1, loss : 14.5201, val_loss : 40.3705, acc : 0.333, val_acc : 0.333\n",
      "Epoch 2, loss : 7.2523, val_loss : 1.1171, acc : 0.667, val_acc : 0.333\n",
      "Epoch 3, loss : 0.0000, val_loss : 0.2873, acc : 1.000, val_acc : 0.667\n",
      "Epoch 4, loss : 0.0000, val_loss : 1.7519, acc : 1.000, val_acc : 0.667\n",
      "Epoch 5, loss : 0.0143, val_loss : 8.2238, acc : 1.000, val_acc : 0.333\n",
      "Epoch 6, loss : 0.0000, val_loss : 0.5419, acc : 1.000, val_acc : 0.667\n",
      "Epoch 7, loss : 0.0000, val_loss : 6.4781, acc : 1.000, val_acc : 0.667\n",
      "Epoch 8, loss : 0.0000, val_loss : 1.4966, acc : 1.000, val_acc : 0.667\n",
      "Epoch 9, loss : 0.0000, val_loss : 0.8048, acc : 1.000, val_acc : 1.000\n",
      "Epoch 10, loss : 0.0000, val_loss : 4.1037, acc : 1.000, val_acc : 1.000\n",
      "Epoch 11, loss : 0.3398, val_loss : 6.7229, acc : 1.000, val_acc : 0.667\n",
      "Epoch 12, loss : 0.0000, val_loss : 6.2777, acc : 1.000, val_acc : 0.667\n",
      "Epoch 13, loss : 0.0000, val_loss : 2.4892, acc : 1.000, val_acc : 1.000\n",
      "Epoch 14, loss : 0.0265, val_loss : 6.7108, acc : 1.000, val_acc : 0.667\n",
      "Epoch 15, loss : 0.0000, val_loss : 1.6644, acc : 1.000, val_acc : 1.000\n",
      "Epoch 16, loss : 0.0000, val_loss : 4.7392, acc : 1.000, val_acc : 1.000\n",
      "Epoch 17, loss : 0.0000, val_loss : 4.6283, acc : 1.000, val_acc : 1.000\n",
      "Epoch 18, loss : 0.0000, val_loss : 1.2792, acc : 1.000, val_acc : 1.000\n",
      "Epoch 19, loss : 0.0000, val_loss : 2.9808, acc : 1.000, val_acc : 1.000\n",
      "Epoch 20, loss : 0.0000, val_loss : 5.7055, acc : 1.000, val_acc : 1.000\n",
      "Epoch 21, loss : 0.0000, val_loss : 1.0438, acc : 1.000, val_acc : 1.000\n",
      "Epoch 22, loss : 0.0000, val_loss : 2.3841, acc : 1.000, val_acc : 1.000\n",
      "Epoch 23, loss : 0.0000, val_loss : 1.2558, acc : 1.000, val_acc : 1.000\n",
      "Epoch 24, loss : 0.0000, val_loss : 3.5935, acc : 1.000, val_acc : 1.000\n",
      "Epoch 25, loss : 0.0005, val_loss : 6.3106, acc : 1.000, val_acc : 1.000\n",
      "Epoch 26, loss : 0.0000, val_loss : 1.3421, acc : 1.000, val_acc : 1.000\n",
      "Epoch 27, loss : 0.0000, val_loss : 1.5409, acc : 1.000, val_acc : 1.000\n",
      "Epoch 28, loss : 0.0000, val_loss : 2.7589, acc : 1.000, val_acc : 1.000\n",
      "Epoch 29, loss : 0.0000, val_loss : 3.7474, acc : 1.000, val_acc : 1.000\n",
      "Epoch 30, loss : 0.0000, val_loss : 5.8190, acc : 1.000, val_acc : 1.000\n",
      "Epoch 31, loss : 0.0000, val_loss : 2.8282, acc : 1.000, val_acc : 0.667\n",
      "Epoch 32, loss : 0.0000, val_loss : 5.5076, acc : 1.000, val_acc : 0.667\n",
      "Epoch 33, loss : 0.0000, val_loss : 1.2607, acc : 1.000, val_acc : 1.000\n",
      "Epoch 34, loss : 0.0000, val_loss : 2.2525, acc : 1.000, val_acc : 1.000\n",
      "Epoch 35, loss : 0.0000, val_loss : 4.5229, acc : 1.000, val_acc : 1.000\n",
      "Epoch 36, loss : 0.0000, val_loss : 4.1359, acc : 1.000, val_acc : 1.000\n",
      "Epoch 37, loss : 0.0000, val_loss : 6.8722, acc : 1.000, val_acc : 1.000\n",
      "Epoch 38, loss : 0.0000, val_loss : 5.9727, acc : 1.000, val_acc : 0.667\n",
      "Epoch 39, loss : 0.0000, val_loss : 4.0333, acc : 1.000, val_acc : 1.000\n",
      "Epoch 40, loss : 0.0000, val_loss : 6.2385, acc : 1.000, val_acc : 1.000\n",
      "Epoch 41, loss : 0.0000, val_loss : 1.9064, acc : 1.000, val_acc : 1.000\n",
      "Epoch 42, loss : 0.0000, val_loss : 2.1252, acc : 1.000, val_acc : 1.000\n",
      "Epoch 43, loss : 0.0000, val_loss : 4.9171, acc : 1.000, val_acc : 1.000\n",
      "Epoch 44, loss : 0.0000, val_loss : 8.1099, acc : 1.000, val_acc : 1.000\n",
      "Epoch 45, loss : 0.0000, val_loss : 4.8790, acc : 1.000, val_acc : 0.667\n",
      "Epoch 46, loss : 0.0000, val_loss : 1.8298, acc : 1.000, val_acc : 1.000\n",
      "Epoch 47, loss : 0.0000, val_loss : 2.3519, acc : 1.000, val_acc : 1.000\n",
      "Epoch 48, loss : 0.0000, val_loss : 1.6121, acc : 1.000, val_acc : 1.000\n",
      "Epoch 49, loss : 0.0000, val_loss : 2.3181, acc : 1.000, val_acc : 1.000\n",
      "test_acc : 1.000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】House Pricesのモデルを作成\n",
    "回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n",
    "\n",
    "分類問題と回帰問題の違いを考慮してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path_hp =\"datasets/house_price_dataset_train.csv\"\n",
    "df_house_price = pd.read_csv(dataset_path_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  208500\n",
       "1  181500\n",
       "2  223500\n",
       "3  140000\n",
       "4  250000\n",
       "5  143000\n",
       "6  307000\n",
       "7  200000\n",
       "8  129900\n",
       "9  118000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データフレームから条件抽出\n",
    "y = df_house_price[\"SalePrice\"]\n",
    "X = df_house_price.loc[:, ['GrLivArea','YearBuilt','LotArea']]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "pd.DataFrame(y).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class nnet:\n",
    "\n",
    "    def __init__(self, X, random_state=3):\n",
    "        self.sess = tf.Session()\n",
    "        seed = random_state\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        self.x_data = tf.placeholder(shape=[None, X.shape[1]], dtype=tf.float32)\n",
    "        self.y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "    def init_weight(self, shape, st_dev):\n",
    "        return tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "\n",
    "    def init_bias(self, shape, st_dev):\n",
    "        return tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "\n",
    "    def fully_connected(self, input_layer, weights, biases):\n",
    "        return tf.nn.relu(tf.add(tf.matmul(input_layer, weights), biases))\n",
    "\n",
    "    def fit(self, X, y, hidden_size, batch_size=100, iter_size=200):\n",
    "\n",
    "        x_data = self.x_data\n",
    "        y_target = self.y_target\n",
    "\n",
    "        final_output = self.build_hidden_layer(hidden_size, X.shape[1])\n",
    "\n",
    "        self.loss = tf.reduce_mean(tf.abs(y_target - final_output))\n",
    "        self.opt = tf.train.AdamOptimizer(0.01)\n",
    "        self.train_step = self.opt.minimize(self.loss)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "        loss_vec = self.train(X, y, iter_size, batch_size)\n",
    "        plt.plot(loss_vec)\n",
    "        return final_output\n",
    "\n",
    "    def predict(self, final_output, X):\n",
    "        x_data = self.x_data\n",
    "        return [val[0] for val in self.sess.run(final_output, feed_dict={x_data: X})]\n",
    "\n",
    "\n",
    "    def train(self, X, y, iter_size, batch_size):\n",
    "        loss_vec = []\n",
    "        x_data = self.x_data\n",
    "        y_target = self.y_target\n",
    "        for i in range(iter_size):\n",
    "            rand_index = np.random.choice(len(X), size=batch_size)\n",
    "            rand_x = X[rand_index]\n",
    "            rand_y = np.transpose([y[rand_index]])\n",
    "            self.sess.run(self.train_step, feed_dict={x_data:rand_x, y_target: rand_y})\n",
    "            loss_vec.append(self.sess.run(self.loss, feed_dict={x_data:rand_x, y_target: rand_y}))\n",
    "\n",
    "            if (i+1)%25==0:\n",
    "                print('Generation:'+str(i+1)+', Loss = '+str(loss_vec[-1]))\n",
    "\n",
    "        return loss_vec\n",
    "\n",
    "\n",
    "    def build_hidden_layer(self, hidden_size, col_size):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        layers = []\n",
    "        tmp_size = col_size\n",
    "        x_data = self.x_data\n",
    "        last_layer = x_data\n",
    "\n",
    "        for hsize in hidden_size:\n",
    "            weights.append(self.init_weight(shape=[tmp_size, hsize], st_dev=10.0))\n",
    "            biases.append(self.init_bias(shape=[hsize], st_dev=10.0))\n",
    "            layers.append(self.fully_connected(last_layer, weights[-1], biases[-1]))\n",
    "            tmp_size = hsize\n",
    "            last_layer = layers[-1]\n",
    "\n",
    "        weights.append(self.init_weight(shape=[tmp_size, 1], st_dev=10.0))\n",
    "        biases.append(self.init_bias(shape=[1], st_dev=10.0))\n",
    "        layers.append(self.fully_connected(last_layer, weights[-1], biases[-1]))\n",
    "        final_output = layers[-1]\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:25, Loss = 128183.52\n",
      "Generation:50, Loss = 101715.26\n",
      "Generation:75, Loss = 71300.97\n",
      "Generation:100, Loss = 75144.445\n",
      "Generation:125, Loss = 61094.637\n",
      "Generation:150, Loss = 57051.19\n",
      "Generation:175, Loss = 64049.43\n",
      "Generation:200, Loss = 57693.273\n",
      "Generation:225, Loss = 49541.39\n",
      "Generation:250, Loss = 67562.47\n",
      "Generation:275, Loss = 52250.01\n",
      "Generation:300, Loss = 53447.31\n",
      "Generation:325, Loss = 49268.48\n",
      "Generation:350, Loss = 53326.074\n",
      "Generation:375, Loss = 49414.74\n",
      "Generation:400, Loss = 47547.57\n",
      "Generation:425, Loss = 46349.86\n",
      "Generation:450, Loss = 55993.84\n",
      "Generation:475, Loss = 45962.17\n",
      "Generation:500, Loss = 47348.84\n",
      "Generation:525, Loss = 45712.004\n",
      "Generation:550, Loss = 42399.65\n",
      "Generation:575, Loss = 43461.824\n",
      "Generation:600, Loss = 40182.164\n",
      "Generation:625, Loss = 44256.297\n",
      "Generation:650, Loss = 47561.555\n",
      "Generation:675, Loss = 36113.19\n",
      "Generation:700, Loss = 37541.977\n",
      "Generation:725, Loss = 38424.562\n",
      "Generation:750, Loss = 47224.16\n",
      "Generation:775, Loss = 37480.35\n",
      "Generation:800, Loss = 37372.87\n",
      "Generation:825, Loss = 35985.06\n",
      "Generation:850, Loss = 36763.6\n",
      "Generation:875, Loss = 40675.996\n",
      "Generation:900, Loss = 39320.184\n",
      "Generation:925, Loss = 41454.332\n",
      "Generation:950, Loss = 44145.98\n",
      "Generation:975, Loss = 39354.73\n",
      "Generation:1000, Loss = 37477.016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "nnetc = nnet(X)\n",
    "model = nnetc.fit(X, y.ravel(), hidden_size=[2], iter_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<予測結果>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186098.562500</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153313.718750</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194508.625000</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185486.812500</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228097.453125</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       0\n",
       "0  186098.562500  208500\n",
       "1  153313.718750  181500\n",
       "2  194508.625000  223500\n",
       "3  185486.812500  140000\n",
       "4  228097.453125  250000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model = nnetc.predict(model,X)\n",
    "pd.concat([pd.DataFrame(predict_model),pd.DataFrame(y)],axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】MNISTのモデルを作成\n",
    "ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n",
    "\n",
    "3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n",
    "\n",
    "スクラッチで実装したモデルの再現を目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train =  X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#ワンホットエンコーディングを実施\n",
    "########################\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "y_train = y_train_one_hot\n",
    "y_test = y_test_one_hot \n",
    "\n",
    "\n",
    "#########################\n",
    "#　画像データの正規化\n",
    "#########################\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 400 #50→\n",
    "n_hidden2 = 200 #100→\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10 #何列のデータかを表すという仮説\n",
    "\n",
    "\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数 ソフトマックスに変形\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
    "\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果 #ソフトマックス関数用に書き換え\n",
    "correct_pred = tf.equal(tf.argmax(Y), tf.argmax(tf.nn.softmax(logits)))\n",
    "\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "                        \n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 13.1528, val_loss : 12.7131, acc : 0.800, val_acc : 0.800\n",
      "Epoch 1, loss : 0.3920, val_loss : 8.9358, acc : 1.000, val_acc : 0.900\n",
      "Epoch 2, loss : 0.8939, val_loss : 6.9012, acc : 0.900, val_acc : 0.900\n",
      "Epoch 3, loss : 0.0367, val_loss : 6.6402, acc : 1.000, val_acc : 0.900\n",
      "Epoch 4, loss : 0.3825, val_loss : 6.3165, acc : 1.000, val_acc : 0.800\n",
      "Epoch 5, loss : 0.0000, val_loss : 5.9335, acc : 1.000, val_acc : 1.000\n",
      "Epoch 6, loss : 1.1829, val_loss : 5.0616, acc : 1.000, val_acc : 0.900\n",
      "Epoch 7, loss : 0.4174, val_loss : 6.5753, acc : 1.000, val_acc : 0.800\n",
      "Epoch 8, loss : 0.0002, val_loss : 4.9376, acc : 1.000, val_acc : 1.000\n",
      "Epoch 9, loss : 0.4715, val_loss : 4.7389, acc : 1.000, val_acc : 0.900\n",
      "test_acc : 1.000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
