{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ymXkjeiXcqf"
   },
   "source": [
    "# Sprint18課題 公開されている実装を動かす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m62im9-VXcqh"
   },
   "source": [
    "## Faster R-CNN\n",
    "\n",
    "Sprint16で読んだFaster R-CNN\\[1\\]の実装を動かします。\n",
    "\n",
    "\\[1\\]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "[https://arxiv.org/pdf/1506.01497.pdf](https://arxiv.org/pdf/1506.01497.pdf)\n",
    "\n",
    "以下のものを使用してください。Kerasを使用した実装です。\n",
    "\n",
    "[duckrabbits/ObjectDetection at master](https://github.com/duckrabbits/ObjectDetection/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eORiwP3WtdLd"
   },
   "source": [
    "マウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "pC9ebt0RXiES",
    "outputId": "87ebd276-8bf8-4357-9f89-4cfd3828d7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfgjjg-_Xcqh"
   },
   "source": [
    "## 【問題1】学習と推定\n",
    "\n",
    "READMEを参考に上記実装を動かしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5XAu4bUStw6f"
   },
   "source": [
    "ディレクトリの移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8vrkLIN3Xkzd",
    "outputId": "da99006e-42fa-4018-d790-56bfeffaa3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/ObjectDetection\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/ObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGvs3Tx4t2O7"
   },
   "source": [
    "学習開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "mejtgz2VXcqi",
    "outputId": "28fa4398-9e49-4634-800c-14b3cfb2d7b3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "Training images per class (19 classes) :\n",
      "{'abraham_grampa_simpson': 687,\n",
      " 'apu_nahasapeemapetilon': 206,\n",
      " 'bart_simpson': 650,\n",
      " 'bg': 0,\n",
      " 'charles_montgomery_burns': 650,\n",
      " 'chief_wiggum': 209,\n",
      " 'comic_book_guy': 208,\n",
      " 'edna_krabappel': 212,\n",
      " 'homer_simpson': 718,\n",
      " 'kent_brockman': 213,\n",
      " 'krusty_the_clown': 429,\n",
      " 'lisa_simpson': 756,\n",
      " 'marge_simpson': 629,\n",
      " 'milhouse_van_houten': 210,\n",
      " 'moe_szyslak': 403,\n",
      " 'ned_flanders': 675,\n",
      " 'nelson_muntz': 219,\n",
      " 'principal_skinner': 614,\n",
      " 'sideshow_bob': 201}\n",
      "-------------------------------\n",
      "path to config file : ./save/train_20190725-093454_config.pickle\n",
      "-------------------------------\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 103s 1s/step - rpn_cls: 2.8040 - rpn_regr: 0.1547 - detector_cls: 4.3754 - detector_regr: 1.4128\n",
      "Average number of overlapping bounding boxes from RPN = 18.53 for 100 previous iterations\n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 18.623762376237625\n",
      "Classifier accuracy for bounding boxes from RPN: 0.5075\n",
      "Loss RPN classifier: 2.0385469954782103\n",
      "Loss RPN regression: 0.13134824737906456\n",
      "Loss Detector classifier: 2.985366961956024\n",
      "Loss Detector regression: 0.8294179241359234\n",
      "Elapsed time: 104.03874635696411[s]\n",
      "Total loss decreased from inf to 5.984680128949223, saving weights\n",
      "training is done\n",
      "-------------------------------\n",
      "path to config file : ./save/train_20190725-093454_config.pickle\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run train.py -p annotation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WQsE1xCt6CW"
   },
   "source": [
    "推定実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zcsUZt3LXcqn",
    "outputId": "9321f38d-b381-4aae-a673-c825351458b9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 09:58:13.836994 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0725 09:58:13.849046 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0725 09:58:13.855283 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0725 09:58:13.892409 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0725 09:58:15.572480 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0725 09:58:15.625079 139661392590720 deprecation_wrapper.py:119] From /content/drive/My Drive/ObjectDetection/model/RoiPoolingConv.py:105: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0725 09:58:16.156149 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0725 09:58:31.509810 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-07-25 09:58:31.514961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-07-25 09:58:31.515347: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9fb7d40 executing computations on platform Host. Devices:\n",
      "2019-07-25 09:58:31.515387: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-25 09:58:31.517484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-25 09:58:31.596837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.597331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x99601c0 executing computations on platform CUDA. Devices:\n",
      "2019-07-25 09:58:31.597381: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-07-25 09:58:31.597644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.597962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-07-25 09:58:31.598346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-25 09:58:31.599712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-25 09:58:31.600929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-25 09:58:31.601330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-25 09:58:31.602927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-25 09:58:31.604084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-25 09:58:31.607571: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-25 09:58:31.607708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.608087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.608423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-25 09:58:31.608497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-25 09:58:31.609513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-25 09:58:31.609550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-25 09:58:31.609581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-25 09:58:31.609840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.610244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 09:58:31.610562: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-07-25 09:58:31.610624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5224 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "W0725 09:58:34.450114 139661392590720 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "abraham_grampa_simpson_21.jpg\n",
      "2019-07-25 09:58:35.226590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-25 09:58:37.522395: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "[]\n",
      "Elapsed time = 4.408304214477539[s]\n",
      "apu_nahasapeemapetilon_11.jpg\n",
      "[]\n",
      "Elapsed time = 1.1721925735473633[s]\n",
      "bart_simpson_0.jpg\n",
      "[]\n",
      "Elapsed time = 2.1062567234039307[s]\n",
      "charles_montgomery_burns_20.jpg\n",
      "[]\n",
      "Elapsed time = 1.1527860164642334[s]\n",
      "charles_montgomery_burns_31.jpg\n",
      "[]\n",
      "Elapsed time = 2.2365403175354004[s]\n",
      "chief_wiggum_12.jpg\n",
      "[]\n",
      "Elapsed time = 2.5330708026885986[s]\n",
      "chief_wiggum_9.jpg\n",
      "[]\n",
      "Elapsed time = 1.6003735065460205[s]\n",
      "comic_book_guy_46.jpg\n",
      "[]\n",
      "Elapsed time = 2.2060155868530273[s]\n",
      "kent_brockman_18.jpg\n",
      "[]\n",
      "Elapsed time = 1.1592676639556885[s]\n",
      "kent_brockman_39.jpg\n",
      "[]\n",
      "Elapsed time = 1.1568470001220703[s]\n",
      "lisa_simpson_18.jpg\n",
      "[]\n",
      "Elapsed time = 1.5821378231048584[s]\n",
      "lisa_simpson_39.jpg\n",
      "[]\n",
      "Elapsed time = 1.153337001800537[s]\n",
      "marge_simpson_22.jpg\n",
      "[]\n",
      "Elapsed time = 1.1794071197509766[s]\n",
      "marge_simpson_26.jpg\n",
      "[]\n",
      "Elapsed time = 1.1596910953521729[s]\n",
      "marge_simpson_32.jpg\n",
      "[]\n",
      "Elapsed time = 1.1556801795959473[s]\n",
      "milhouse_van_houten_15.jpg\n",
      "[]\n",
      "Elapsed time = 1.2601571083068848[s]\n",
      "milhouse_van_houten_3.jpg\n",
      "[]\n",
      "Elapsed time = 1.2292416095733643[s]\n",
      "moe_szyslak_43.jpg\n",
      "[]\n",
      "Elapsed time = 2.206507921218872[s]\n",
      "moe_szyslak_5.jpg\n",
      "[]\n",
      "Elapsed time = 1.1523914337158203[s]\n",
      "nelson_muntz_6.jpg\n",
      "[]\n",
      "Elapsed time = 1.162362813949585[s]\n",
      "principal_skinner_22.jpg\n",
      "[]\n",
      "Elapsed time = 1.1199688911437988[s]\n",
      "principal_skinner_25.jpg\n",
      "[]\n",
      "Elapsed time = 1.155144453048706[s]\n",
      "principal_skinner_40.jpg\n",
      "[]\n",
      "Elapsed time = 1.1134133338928223[s]\n",
      "principal_skinner_8.jpg\n",
      "[]\n",
      "Elapsed time = 1.1529982089996338[s]\n",
      "sideshow_bob_1.jpg\n",
      "[]\n",
      "Elapsed time = 1.1805989742279053[s]\n"
     ]
    }
   ],
   "source": [
    "!python predict.py -i simpsons_testset -c save/train_20190725-093454_config.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvIsK2Z9Xcqr"
   },
   "source": [
    "## 【問題2】論文と実装の対応\n",
    "\n",
    "コードリーディングを行ってください。\n",
    "\n",
    "まず、Faster R-CNN\\[1\\]において重要だと考えた部分を列挙してください。そして、それに対応するコードを見つけてください。\n",
    "\n",
    "（例）\n",
    "\n",
    "- RPNを実現しているコードはどこか\n",
    "- RoIプーリングを実現しているコードはどこか\n",
    "\n",
    "フレームワークには畳み込み層など一般的なものはクラスが用意されていますが、RoIプーリングなど特定の手法限定のものは用意されていません。オリジナルのレイヤーを作成することが可能であり、Kerasであれば以下のページに情報がまとまっています。\n",
    "\n",
    "[オリジナルのKerasレイヤーを作成する - Keras Documentation](https://keras.io/ja/layers/writing-your-own-keras-layers/)\n",
    "\n",
    "参考\n",
    "\n",
    "KerasではVGG16のクラスが用意されているため、簡単に利用ができます。include_top=Falseの引数を与えることで、出力のための全結合層部分が除かれます。weights='imagenet'でImageNetを利用した学習済みモデルも手に入り、転移学習が行えます。weights='None'とすればランダムな初期化となります。\n",
    "\n",
    "[Applications - Keras Documentation](https://keras.io/ja/applications/#vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rg-z2--gXcqs"
   },
   "source": [
    "### ・RPNを実現しているコードはどこか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT2VT40juMaN"
   },
   "outputs": [],
   "source": [
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn_layers = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "from . import data_generators\n",
    "import copy\n",
    "\n",
    "\n",
    "def calc_iou(R, img_data, C, class_mapping):\n",
    "\n",
    "    bboxes = img_data['bboxes']\n",
    "    (width, height) = (img_data['width'], img_data['height'])\n",
    "    # get image dimensions for resizing\n",
    "    resized_width, resized_height, _ = data_generators.get_new_img_size(width, height, C.im_size)\n",
    "\n",
    "    gta = np.zeros((len(bboxes), 4))\n",
    "\n",
    "    for bbox_num, bbox in enumerate(bboxes):\n",
    "        # get the GT box coordinates, and resize to account for image resizing\n",
    "        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
    "        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
    "        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
    "        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
    "\n",
    "    x_roi = []\n",
    "    y_class_num = []\n",
    "    y_class_regr_coords = []\n",
    "    y_class_regr_label = []\n",
    "\n",
    "    for ix in range(R.shape[0]):\n",
    "        (x1, y1, x2, y2) = R[ix, :]\n",
    "        x1 = int(round(x1))\n",
    "        y1 = int(round(y1))\n",
    "        x2 = int(round(x2))\n",
    "        y2 = int(round(y2))\n",
    "\n",
    "        best_iou = 0.0\n",
    "        best_bbox = -1\n",
    "        for bbox_num in range(len(bboxes)):\n",
    "            curr_iou = data_generators.iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
    "            if curr_iou > best_iou:\n",
    "                best_iou = curr_iou\n",
    "                best_bbox = bbox_num\n",
    "\n",
    "        if best_iou < C.classifier_min_overlap:\n",
    "                continue\n",
    "        else:\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            x_roi.append([x1, y1, w, h])\n",
    "\n",
    "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
    "                # hard negative example\n",
    "                cls_name = 'bg'\n",
    "            elif C.classifier_max_overlap <= best_iou:\n",
    "                cls_name = bboxes[best_bbox]['class']\n",
    "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
    "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
    "\n",
    "                cx = x1 + w / 2.0\n",
    "                cy = y1 + h / 2.0\n",
    "\n",
    "                tx = (cxg - cx) / float(w)\n",
    "                ty = (cyg - cy) / float(h)\n",
    "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
    "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
    "            else:\n",
    "                print('roi = {}'.format(best_iou))\n",
    "                raise RuntimeError\n",
    "\n",
    "        class_num = class_mapping[cls_name]\n",
    "        class_label = len(class_mapping) * [0]\n",
    "        class_label[class_num] = 1\n",
    "        y_class_num.append(copy.deepcopy(class_label))\n",
    "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
    "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
    "        if cls_name != 'bg':\n",
    "            label_pos = 4 * class_num\n",
    "            sx, sy, sw, sh = C.classifier_regr_std\n",
    "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
    "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
    "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
    "            y_class_regr_label.append(copy.deepcopy(labels))\n",
    "        else:\n",
    "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
    "            y_class_regr_label.append(copy.deepcopy(labels))\n",
    "\n",
    "    if len(x_roi) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    X = np.array(x_roi)\n",
    "    Y1 = np.array(y_class_num)\n",
    "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
    "\n",
    "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0)\n",
    "\n",
    "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
    "    try:\n",
    "        cx = x + w/2.\n",
    "        cy = y + h/2.\n",
    "        cx1 = tx * w + cx\n",
    "        cy1 = ty * h + cy\n",
    "        w1 = math.exp(tw) * w\n",
    "        h1 = math.exp(th) * h\n",
    "        x1 = cx1 - w1/2.\n",
    "        y1 = cy1 - h1/2.\n",
    "        x1 = int(round(x1))\n",
    "        y1 = int(round(y1))\n",
    "        w1 = int(round(w1))\n",
    "        h1 = int(round(h1))\n",
    "\n",
    "        return x1, y1, w1, h1\n",
    "\n",
    "    except ValueError:\n",
    "        return x, y, w, h\n",
    "    except OverflowError:\n",
    "        return x, y, w, h\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return x, y, w, h\n",
    "\n",
    "def apply_regr_np(X, T):\n",
    "    try:\n",
    "        x = X[0, :, :]\n",
    "        y = X[1, :, :]\n",
    "        w = X[2, :, :]\n",
    "        h = X[3, :, :]\n",
    "\n",
    "        tx = T[0, :, :]\n",
    "        ty = T[1, :, :]\n",
    "        tw = T[2, :, :]\n",
    "        th = T[3, :, :]\n",
    "\n",
    "        cx = x + w/2.\n",
    "        cy = y + h/2.\n",
    "        cx1 = tx * w + cx\n",
    "        cy1 = ty * h + cy\n",
    "\n",
    "        w1 = np.exp(tw.astype(np.float64)) * w\n",
    "        h1 = np.exp(th.astype(np.float64)) * h\n",
    "        x1 = cx1 - w1/2.\n",
    "        y1 = cy1 - h1/2.\n",
    "\n",
    "        x1 = np.round(x1)\n",
    "        y1 = np.round(y1)\n",
    "        w1 = np.round(w1)\n",
    "        h1 = np.round(h1)\n",
    "        return np.stack([x1, y1, w1, h1])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return X\n",
    "\n",
    "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
    "    \"\"\"\n",
    "    Eliminating redundant object detection windows with a faster non maximum suppression method\n",
    "    Greedily select high-scoring detections and skip detections that are significantly covered by \n",
    "    a previously selected detection.\n",
    "    :param boxes: list of boxes \n",
    "    :param probs: list of probabilities relatives to the boxes\n",
    "    \"\"\"\n",
    "\n",
    "    # code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    np.testing.assert_array_less(x1, x2)\n",
    "    np.testing.assert_array_less(y1, y2)\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes \n",
    "    pick = []\n",
    "\n",
    "    # calculate the areas\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    \n",
    "    # sort the bounding boxes \n",
    "    idxs = np.argsort(probs)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the intersection\n",
    "\n",
    "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        ww_int = np.maximum(0, xx2_int - xx1_int + 0.5)\n",
    "        hh_int = np.maximum(0, yy2_int - yy1_int + 0.5)\n",
    "\n",
    "        area_int = ww_int * hh_int\n",
    "\n",
    "        # find the union\n",
    "        area_union = area[i] + area[idxs[:last]] - area_int\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = area_int / (area_union + 1e-6)\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlap_thresh)[0])))\n",
    "\n",
    "        if len(pick) >= max_boxes:\n",
    "            break\n",
    "\n",
    "    # return only the bounding boxes that were picked using the integer data type\n",
    "    boxes = boxes[pick].astype(\"int\")\n",
    "    probs = probs[pick]\n",
    "    return boxes, probs\n",
    "\n",
    "import time\n",
    "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
    "\n",
    "    regr_layer = regr_layer / C.std_scaling\n",
    "\n",
    "    anchor_sizes = C.anchor_box_scales\n",
    "    anchor_ratios = C.anchor_box_ratios\n",
    "\n",
    "    assert rpn_layer.shape[0] == 1\n",
    "\n",
    "    if dim_ordering == 'th':\n",
    "        (rows,cols) = rpn_layer.shape[2:]\n",
    "\n",
    "    elif dim_ordering == 'tf':\n",
    "        (rows, cols) = rpn_layer.shape[1:3]\n",
    "\n",
    "    curr_layer = 0\n",
    "    if dim_ordering == 'tf':\n",
    "        A = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
    "    elif dim_ordering == 'th':\n",
    "        A = np.zeros((4, rpn_layer.shape[2], rpn_layer.shape[3], rpn_layer.shape[1]))\n",
    "\n",
    "    for anchor_size in anchor_sizes:\n",
    "        for anchor_ratio in anchor_ratios:\n",
    "\n",
    "            anchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
    "            anchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
    "            if dim_ordering == 'th':\n",
    "                regr = regr_layer[0, 4 * curr_layer:4 * curr_layer + 4, :, :]\n",
    "            else:\n",
    "                regr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4]\n",
    "                regr = np.transpose(regr, (2, 0, 1))\n",
    "\n",
    "            X, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
    "\n",
    "            A[0, :, :, curr_layer] = X - anchor_x/2\n",
    "            A[1, :, :, curr_layer] = Y - anchor_y/2\n",
    "            A[2, :, :, curr_layer] = anchor_x\n",
    "            A[3, :, :, curr_layer] = anchor_y\n",
    "\n",
    "            if use_regr:\n",
    "                A[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
    "\n",
    "            A[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
    "            A[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
    "            A[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
    "            A[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
    "\n",
    "            A[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
    "            A[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
    "            A[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
    "            A[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
    "\n",
    "            curr_layer += 1\n",
    "\n",
    "    all_boxes = np.reshape(A.transpose((0, 3, 1,2)), (4, -1)).transpose((1, 0))\n",
    "    all_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))\n",
    "\n",
    "    x1 = all_boxes[:, 0]\n",
    "    y1 = all_boxes[:, 1]\n",
    "    x2 = all_boxes[:, 2]\n",
    "    y2 = all_boxes[:, 3]\n",
    "\n",
    "    idxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
    "\n",
    "    all_boxes = np.delete(all_boxes, idxs, 0)\n",
    "    all_probs = np.delete(all_probs, idxs, 0)\n",
    "\n",
    "    result = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhtUuyvZXcqu"
   },
   "source": [
    "### ・RoIプーリングを実現しているコードはどこか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5axfUUPqucNa"
   },
   "outputs": [],
   "source": [
    "class RoiPoolingConv(Layer):\n",
    "    '''ROI pooling layer for 2D inputs.\n",
    "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
    "    K. He, X. Zhang, S. Ren, J. Sun\n",
    "    # Arguments\n",
    "        pool_size: int\n",
    "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
    "        num_rois: number of regions of interest to be used\n",
    "    # Input shape\n",
    "        list of two 4D tensors [X_img,X_roi] with shape:\n",
    "        X_img:\n",
    "        `(1, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(1, rows, cols, channels)` if dim_ordering='tf'.\n",
    "        X_roi:\n",
    "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
    "    # Output shape\n",
    "        3D tensor with shape:\n",
    "        `(1, num_rois, channels, pool_size, pool_size)`\n",
    "    '''\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "\n",
    "        self.dim_ordering = K.image_dim_ordering()\n",
    "        assert self.dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
    "\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            self.nb_channels = input_shape[0][1]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            self.nb_channels = input_shape[0][3]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            return None, self.num_rois, self.nb_channels, self.pool_size, self.pool_size\n",
    "        else:\n",
    "            return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "\n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        img = x[0]\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = K.shape(img)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for roi_idx in range(self.num_rois):\n",
    "\n",
    "            x = rois[0, roi_idx, 0]\n",
    "            y = rois[0, roi_idx, 1]\n",
    "            w = rois[0, roi_idx, 2]\n",
    "            h = rois[0, roi_idx, 3]\n",
    "            \n",
    "            row_length = w / float(self.pool_size)\n",
    "            col_length = h / float(self.pool_size)\n",
    "\n",
    "            num_pool_regions = self.pool_size\n",
    "\n",
    "            #NOTE: the RoiPooling implementation differs between theano and tensorflow due to the lack of a resize op\n",
    "            # in theano. The theano implementation is much less efficient and leads to long compile times\n",
    "\n",
    "            if self.dim_ordering == 'th':\n",
    "                for jy in range(num_pool_regions):\n",
    "                    for ix in range(num_pool_regions):\n",
    "                        x1 = x + ix * row_length\n",
    "                        x2 = x1 + row_length\n",
    "                        y1 = y + jy * col_length\n",
    "                        y2 = y1 + col_length\n",
    "\n",
    "                        x1 = K.cast(x1, 'int32')\n",
    "                        x2 = K.cast(x2, 'int32')\n",
    "                        y1 = K.cast(y1, 'int32')\n",
    "                        y2 = K.cast(y2, 'int32')\n",
    "\n",
    "                        x2 = x1 + K.maximum(1,x2-x1)\n",
    "                        y2 = y1 + K.maximum(1,y2-y1)\n",
    "                        \n",
    "                        new_shape = [input_shape[0], input_shape[1],\n",
    "                                     y2 - y1, x2 - x1]\n",
    "\n",
    "                        x_crop = img[:, :, y1:y2, x1:x2]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(2, 3))\n",
    "                        outputs.append(pooled_val)\n",
    "\n",
    "            elif self.dim_ordering == 'tf':\n",
    "                x = K.cast(x, 'int32')\n",
    "                y = K.cast(y, 'int32')\n",
    "                w = K.cast(w, 'int32')\n",
    "                h = K.cast(h, 'int32')\n",
    "\n",
    "                rs = tf.image.resize_images(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "                outputs.append(rs)\n",
    "\n",
    "        final_output = K.concatenate(outputs, axis=0)\n",
    "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            final_output = K.permute_dimensions(final_output, (0, 1, 4, 2, 3))\n",
    "        else:\n",
    "            final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPBz3BlzXcqx"
   },
   "source": [
    "## YOLOv3\n",
    "\n",
    "シンプソンズのデータセットをFaster R-CNN以外の手法で学習・推定を行います。YOLOv3\\[2\\]のKeras実装を使います。\n",
    "\n",
    "[qqwweee/keras-yolo3: A Keras implementation of YOLOv3 (Tensorflow backend)](https://github.com/qqwweee/keras-yolo3)\n",
    "\n",
    "\\[2\\]Jeseph Redmon, Ali Farhadi. YOLOv3: An Incremental Improvement\n",
    "\n",
    "[https://pjreddie.com/media/files/papers/YOLOv3.pdf](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "\n",
    "Sprint18で使用した実装（再掲）\n",
    "\n",
    "[lasershow/SimpsonRecognition: Detect and recognize The Simpsons characters using Keras and Faster R-CNN](https://github.com/lasershow/SimpsonRecognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZUuL04YXcqy"
   },
   "source": [
    "## 【問題3】学習済みの重みによる推定\n",
    "\n",
    "学習済みの重みを使い推定を行う方法がREADME.mdのQuick Startに記載されています。\n",
    "\n",
    "まずはこの通りにして各自何かしらの画像や動画に対して検出を行ってください。\n",
    "\n",
    "出力結果を課題の一部として提出してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Z9iyq_KXcqy"
   },
   "source": [
    "<img src=\"./../images/aiueo.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kmfhTrYXcqz"
   },
   "source": [
    "## 【問題4】学習のためのファイルを作成\n",
    "\n",
    "新しいデータ（シンプソンズデータセット）を学習します。README.mdのTrainingを読み、シンプソンズデータセットを学習するために必要なファイルを作成してください。\n",
    "\n",
    "アノテーションファイルの形式がSprint18で扱った実装のものとは異なっているので、変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1K05L2uXcq0"
   },
   "outputs": [],
   "source": [
    "#ファイルの読み込み\n",
    "with open('annotation.txt') as f:\n",
    "    txt = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1ecAIhHXcq2"
   },
   "outputs": [],
   "source": [
    "class_dic = {}\n",
    "class_num = 0\n",
    "\n",
    "\n",
    "for i in txt:\n",
    "    data = i.split(',')\n",
    "    path = data[0] \n",
    "    annotation = data[1: -1]\n",
    "    classes = data[-1] \n",
    "    \n",
    "  \n",
    "    if classes not in class_dic:\n",
    "        class_dic[classes] = class_num\n",
    "        class_num += 1\n",
    "        \n",
    "    #アノテーションファイルを作成\n",
    "    with open('train.txt', 'a') as f_train:\n",
    "        f_train.write(path + ' ' + ','.join(annotation)  + ',' + str(class_dic[classes]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG0HkF3XXcq4"
   },
   "outputs": [],
   "source": [
    "#クラスファイル作成\n",
    "for i in class_dic.keys():\n",
    "    with open('class_label.txt', 'a') as f_class: \n",
    "        f_class.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTolS8o4Xcq7"
   },
   "source": [
    "## 【問題5】学習\n",
    "\n",
    "問題4で作成したファイルを使用して学習してください。実行環境で学習に時間がかかる場合は、学習が行えることを確認するのみで終えて構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DLveevY3nWTb",
    "outputId": "dc17874d-a569-4cdc-daa5-f29be2e8edc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Loading weights.\n",
      "Weights Header:  0 2 0 [32013312]\n",
      "Parsing Darknet config.\n",
      "Creating Keras model.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 10:28:41.537910 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0725 10:28:41.549187 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Parsing section net_0\n",
      "Parsing section convolutional_0\n",
      "conv2d bn leaky (3, 3, 3, 32)\n",
      "W0725 10:28:41.551608 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0725 10:28:41.564751 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0725 10:28:41.564948 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2019-07-25 10:28:41.569733: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-07-25 10:28:41.570021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20e5480 executing computations on platform Host. Devices:\n",
      "2019-07-25 10:28:41.570059: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-25 10:28:41.572162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-25 10:28:41.642160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.642813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x599a300 executing computations on platform CUDA. Devices:\n",
      "2019-07-25 10:28:41.642860: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-07-25 10:28:41.643171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.644020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-07-25 10:28:41.644655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-25 10:28:41.646372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-25 10:28:41.647887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-25 10:28:41.648468: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-25 10:28:41.650971: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-25 10:28:41.653473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-25 10:28:41.657932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-25 10:28:41.658049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.658474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.658813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-25 10:28:41.658888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-25 10:28:41.660182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-25 10:28:41.660231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-25 10:28:41.660249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-25 10:28:41.660500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.660863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-25 10:28:41.661165: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-07-25 10:28:41.661255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5224 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "W0725 10:28:42.188083 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Parsing section convolutional_1\n",
      "conv2d bn leaky (3, 3, 32, 64)\n",
      "Parsing section convolutional_2\n",
      "conv2d bn leaky (1, 1, 64, 32)\n",
      "Parsing section convolutional_3\n",
      "conv2d bn leaky (3, 3, 32, 64)\n",
      "Parsing section shortcut_0\n",
      "Parsing section convolutional_4\n",
      "conv2d bn leaky (3, 3, 64, 128)\n",
      "Parsing section convolutional_5\n",
      "conv2d bn leaky (1, 1, 128, 64)\n",
      "Parsing section convolutional_6\n",
      "conv2d bn leaky (3, 3, 64, 128)\n",
      "Parsing section shortcut_1\n",
      "Parsing section convolutional_7\n",
      "conv2d bn leaky (1, 1, 128, 64)\n",
      "Parsing section convolutional_8\n",
      "conv2d bn leaky (3, 3, 64, 128)\n",
      "Parsing section shortcut_2\n",
      "Parsing section convolutional_9\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section convolutional_10\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_11\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_3\n",
      "Parsing section convolutional_12\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_13\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_4\n",
      "Parsing section convolutional_14\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_15\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_5\n",
      "Parsing section convolutional_16\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_17\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_6\n",
      "Parsing section convolutional_18\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_19\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_7\n",
      "Parsing section convolutional_20\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_21\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_8\n",
      "Parsing section convolutional_22\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_23\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_9\n",
      "Parsing section convolutional_24\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_25\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section shortcut_10\n",
      "Parsing section convolutional_26\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section convolutional_27\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_28\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_11\n",
      "Parsing section convolutional_29\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_30\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_12\n",
      "Parsing section convolutional_31\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_32\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_13\n",
      "Parsing section convolutional_33\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_34\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_14\n",
      "Parsing section convolutional_35\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_36\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_15\n",
      "Parsing section convolutional_37\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_38\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_16\n",
      "Parsing section convolutional_39\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_40\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_17\n",
      "Parsing section convolutional_41\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_42\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section shortcut_18\n",
      "Parsing section convolutional_43\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section convolutional_44\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_45\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section shortcut_19\n",
      "Parsing section convolutional_46\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_47\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section shortcut_20\n",
      "Parsing section convolutional_48\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_49\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section shortcut_21\n",
      "Parsing section convolutional_50\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_51\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section shortcut_22\n",
      "Parsing section convolutional_52\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_53\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section convolutional_54\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_55\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section convolutional_56\n",
      "conv2d bn leaky (1, 1, 1024, 512)\n",
      "Parsing section convolutional_57\n",
      "conv2d bn leaky (3, 3, 512, 1024)\n",
      "Parsing section convolutional_58\n",
      "conv2d    linear (1, 1, 1024, 255)\n",
      "Parsing section yolo_0\n",
      "Parsing section route_0\n",
      "Parsing section convolutional_59\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section upsample_0\n",
      "W0725 10:29:43.123937 140536730949504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "Parsing section route_1\n",
      "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n",
      "Parsing section convolutional_60\n",
      "conv2d bn leaky (1, 1, 768, 256)\n",
      "Parsing section convolutional_61\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section convolutional_62\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_63\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section convolutional_64\n",
      "conv2d bn leaky (1, 1, 512, 256)\n",
      "Parsing section convolutional_65\n",
      "conv2d bn leaky (3, 3, 256, 512)\n",
      "Parsing section convolutional_66\n",
      "conv2d    linear (1, 1, 512, 255)\n",
      "Parsing section yolo_1\n",
      "Parsing section route_2\n",
      "Parsing section convolutional_67\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section upsample_1\n",
      "Parsing section route_3\n",
      "Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
      "Parsing section convolutional_68\n",
      "conv2d bn leaky (1, 1, 384, 128)\n",
      "Parsing section convolutional_69\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section convolutional_70\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_71\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section convolutional_72\n",
      "conv2d bn leaky (1, 1, 256, 128)\n",
      "Parsing section convolutional_73\n",
      "conv2d bn leaky (3, 3, 128, 256)\n",
      "Parsing section convolutional_74\n",
      "conv2d    linear (1, 1, 256, 255)\n",
      "Parsing section yolo_2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
      "                                                                 leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
      "                                                                 leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
      "                                                                 leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
      "                                                                 leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
      "                                                                 leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
      "                                                                 leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
      "                                                                 leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 62,001,757\n",
      "Trainable params: 61,949,149\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Saved Keras model to model_data/yolo_weights.h5\n",
      "Read 62001757 of 62001757.0 from Darknet weights.\n"
     ]
    }
   ],
   "source": [
    "!python convert.py yolov3.cfg yolov3.weights model_data/yolo_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "colab_type": "code",
    "id": "1C0gMOjWXcrA",
    "outputId": "8455051d-7a9f-48de-c55b-e48f8d24abf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((75,) vs (255,)).\n",
      "  weight_values[i].shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 7101 samples, val on 788 samples, with batch size 32.\n",
      "Epoch 1/50\n",
      "221/221 [==============================] - 672s 3s/step - loss: 577.9155 - val_loss: 66.3055\n",
      "Epoch 2/50\n",
      " 16/221 [=>............................] - ETA: 5:28 - loss: 68.5856"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/content/drive/My Drive/ObjectDetection/keras-yolo3/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/drive/My Drive/ObjectDetection/keras-yolo3/train.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 callbacks=[logging, checkpoint])\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'trained_weights_stage_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3ckEfAfvXaO"
   },
   "source": [
    "学習できていることを確認し、interruputした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4X_BFSAkvbfu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sprint18-run-implementation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
